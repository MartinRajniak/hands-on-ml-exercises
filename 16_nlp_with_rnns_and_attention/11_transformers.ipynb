{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8olG4anT0Rs"
      },
      "source": [
        "# Shakespearean text with Transformers\n",
        "\n",
        "_Exercise: Use the Transformers library to download a pretrained language model capable of generating text (e.g., GPT), and try generating more convincing Shakespearean text. You will need to use the model's `generate()` method—see Hugging Face's documentation for more details._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTfh3pqnT0Ru"
      },
      "source": [
        "## Prepare environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aQeinQIWT0Rv"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from transformers import TFGPT2LMHeadModel, GPT2Tokenizer\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyuyLVSFT0Rw"
      },
      "source": [
        "## Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "i-W7y5wbT0Rw"
      },
      "outputs": [],
      "source": [
        "shakespeare_url = \"https://homl.info/shakespeare\"  # shortcut URL\n",
        "filepath = tf.keras.utils.get_file(\"shakespeare.txt\", shakespeare_url)\n",
        "with open(filepath) as f:\n",
        "    shakespeare_text = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzCdf7aoT0Rw",
        "outputId": "4742ecb0-5b99-4ff1-ce90-be3850975705"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n"
          ]
        }
      ],
      "source": [
        "# extra code – shows a short text sample\n",
        "print(shakespeare_text[:80])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFm6TRkeT0Rx",
        "outputId": "094abde5-1429-47d4-d443-b144dfec4cc8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "# Load pretrained model and tokenizer\n",
        "model_name = \"gpt2\"  # You could also try \"gpt2-medium\" for better results\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = TFGPT2LMHeadModel.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NJuFF-OCT0Ry"
      },
      "outputs": [],
      "source": [
        "# Add padding token (GPT2 doesn't have one by default)\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Od6XlKsST0Ry"
      },
      "outputs": [],
      "source": [
        "# Shakespeare prompt to condition the generation\n",
        "prompt = \"\"\"\n",
        "In faith, I do not love thee with mine eyes,\n",
        "For they in thee a thousand errors note;\n",
        "But 'tis my heart that loves what they despise,\n",
        "Who, in despite of view, is pleased to dote.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "yWkeB-85T0Ry"
      },
      "outputs": [],
      "source": [
        "# Encode the prompt\n",
        "input_ids = tokenizer.encode(prompt, return_tensors=\"tf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "5Jf8TXZIT0Ry"
      },
      "outputs": [],
      "source": [
        "# Generate text\n",
        "output = model.generate(\n",
        "    input_ids,\n",
        "    max_length=200,\n",
        "    num_return_sequences=3,\n",
        "    temperature=0.8,\n",
        "    top_k=50,\n",
        "    top_p=0.95,\n",
        "    do_sample=True,\n",
        "    no_repeat_ngram_size=3,\n",
        "    pad_token_id=tokenizer.eos_token_id\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CK7j2qetT0Rz",
        "outputId": "f490558d-b852-4013-b02b-8e3e27bc3f65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Generated Shakespearean Texts ===\n",
            "\n",
            "Sample 1:\n",
            "\n",
            "In faith, I do not love thee with mine eyes,\n",
            "For they in thee a thousand errors note;\n",
            "But 'tis my heart that loves what they despise,\n",
            "Who, in despite of view, is pleased to dote.\n",
            "\n",
            "Thou shalt not, I say, make of thee the one,\n",
            "\n",
            "For the other is to the one; to be, to think.\n",
            " (N. 6:9)\n",
            "\n",
            "Of to say.\n",
            ", 'It is to be the saying, 'Tis the beginning of many things,\n",
            " (Tis, and to be a part of; to come, to be of.)\n",
            "\n",
            "To be in, to look; to pray; to know.\n",
            ". . . to say, to answer.\n",
            "— And to be to answer (O.T.) 'The in, in the time of the Lord.\n",
            " I have seen to my mind, I have asked, I ask not.\n",
            " The\n",
            "\n",
            "--------------------------------------------------\n",
            "Sample 2:\n",
            "\n",
            "In faith, I do not love thee with mine eyes,\n",
            "For they in thee a thousand errors note;\n",
            "But 'tis my heart that loves what they despise,\n",
            "Who, in despite of view, is pleased to dote.\n",
            "\n",
            "In love I believe, in love, I believe in love;\n",
            "\n",
            "I love in the love of my heart, in my heart love.\n",
            " (Cf. 1 Corinthians 8.5,7.)\n",
            "\n",
            "As the heart does not hold the law of the Lord, He is not the law, but the law; for it does not be the law but the flesh,\n",
            "\n",
            "But the law does not take, but follow, I have not seen. For it is the law and not of what was, to speak of this, by an act of Christ, it, by the law in a man,\n",
            " (Romans 15.15.2.)\n",
            " (I do not like your work, but to make it.\n",
            "\n",
            "--------------------------------------------------\n",
            "Sample 3:\n",
            "\n",
            "In faith, I do not love thee with mine eyes,\n",
            "For they in thee a thousand errors note;\n",
            "But 'tis my heart that loves what they despise,\n",
            "Who, in despite of view, is pleased to dote.\n",
            "\n",
            "For for him is, if thou be, my love to thee.\n",
            "\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Print the generated Shakespeare-like texts\n",
        "print(\"\\n=== Generated Shakespearean Texts ===\\n\")\n",
        "for i, sequence in enumerate(output):\n",
        "    text = tokenizer.decode(sequence.numpy(), skip_special_tokens=True)\n",
        "    print(f\"Sample {i+1}:\\n{text}\\n\")\n",
        "    print(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwXdW7j1T0Rz",
        "outputId": "94a933d4-d347-49c3-cc0b-f0ba3b68ef9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "974/974 [==============================] - 692s 670ms/step - loss: 10.8249\n",
            "Epoch 2/3\n",
            "974/974 [==============================] - 653s 670ms/step - loss: 10.8249\n",
            "Epoch 3/3\n",
            "974/974 [==============================] - 653s 670ms/step - loss: 10.8249\n"
          ]
        }
      ],
      "source": [
        "# Fine-tuning example with TensorFlow/Keras\n",
        "def fine_tune_on_shakespeare(model, tokenizer, shakespeare_texts, epochs=3):\n",
        "    \"\"\"\n",
        "    Function to fine-tune the model on Shakespeare's works using Keras/TensorFlow.\n",
        "    You would need a dataset of Shakespeare's texts.\n",
        "    \"\"\"\n",
        "    # Prepare dataset\n",
        "    def encode_texts(texts):\n",
        "        encodings = tokenizer(texts, truncation=True, padding=\"max_length\",\n",
        "                              max_length=512, return_tensors=\"tf\")\n",
        "        input_ids = encodings[\"input_ids\"]\n",
        "        attention_mask = encodings[\"attention_mask\"]\n",
        "        # For language modeling, the labels are the input_ids\n",
        "        labels = tf.identity(input_ids)\n",
        "        return input_ids, attention_mask, labels\n",
        "\n",
        "    # Create TensorFlow Dataset\n",
        "    def create_dataset(texts, batch_size=4):\n",
        "        input_ids, attention_mask, labels = encode_texts(texts)\n",
        "        dataset = tf.data.Dataset.from_tensor_slices((\n",
        "            {\"input_ids\": input_ids, \"attention_mask\": attention_mask},\n",
        "            labels\n",
        "        ))\n",
        "        dataset = dataset.shuffle(buffer_size=len(texts)).batch(batch_size)\n",
        "        return dataset\n",
        "\n",
        "    # Example training code\n",
        "    train_dataset = create_dataset(shakespeare_texts)\n",
        "\n",
        "    # Define optimizer\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\")\n",
        "    # Train the model\n",
        "    model.fit(train_dataset, epochs=epochs)\n",
        "\n",
        "    return model\n",
        "\n",
        "# For a more complete fine-tuning approach, you could use the official Shakespeare dataset:\n",
        "def download_shakespeare_dataset():\n",
        "    \"\"\"\n",
        "    Downloads and prepares the TinyShakespeare dataset for fine-tuning.\n",
        "    Returns a list of text chunks suitable for training.\n",
        "    \"\"\"\n",
        "    import tensorflow_datasets as tfds\n",
        "    import re\n",
        "\n",
        "    # Download the Shakespeare dataset\n",
        "    shakespeare_ds = tfds.load('tiny_shakespeare', split='train')\n",
        "\n",
        "    # Extract text and preprocess\n",
        "    shakespeare_text = \"\"\n",
        "    for example in shakespeare_ds:\n",
        "        shakespeare_text += example['text'].numpy().decode('utf-8')\n",
        "\n",
        "    # Clean and chunk the text\n",
        "    shakespeare_text = re.sub(r'\\s+', ' ', shakespeare_text).strip()\n",
        "    chunk_size = 512  # GPT-2 context window\n",
        "    stride = 256      # Overlap between chunks\n",
        "\n",
        "    chunks = []\n",
        "    for i in range(0, len(shakespeare_text) - chunk_size, stride):\n",
        "        chunks.append(shakespeare_text[i:i + chunk_size])\n",
        "\n",
        "    return chunks\n",
        "\n",
        "shakespeare_chunks = download_shakespeare_dataset()\n",
        "fine_tuned_model = fine_tune_on_shakespeare(model, tokenizer, shakespeare_chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pn-OY_1Drz5n"
      },
      "outputs": [],
      "source": [
        "# Generate text\n",
        "output = fine_tuned_model.generate(\n",
        "    input_ids,\n",
        "    max_length=200,\n",
        "    num_return_sequences=3,\n",
        "    temperature=0.8,\n",
        "    top_k=50,\n",
        "    top_p=0.95,\n",
        "    do_sample=True,\n",
        "    no_repeat_ngram_size=3,\n",
        "    pad_token_id=tokenizer.eos_token_id\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spiTZ4GVr2Ti"
      },
      "outputs": [],
      "source": [
        "# Print the generated Shakespeare-like texts\n",
        "print(\"\\n=== Generated Shakespearean Texts ===\\n\")\n",
        "for i, sequence in enumerate(output):\n",
        "    text = tokenizer.decode(sequence.numpy(), skip_special_tokens=True)\n",
        "    print(f\"Sample {i+1}:\\n{text}\\n\")\n",
        "    print(\"-\" * 50)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
