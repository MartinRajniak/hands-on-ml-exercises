{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. MNIST with MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-07 09:31:18.426691: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1738917078.445490   13573 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1738917078.451833   13573 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import keras_tuner as kt\n",
    "from keras_tuner import HyperParameters, RandomSearch, HyperModel, BayesianOptimization\n",
    "\n",
    "from keras.api.datasets import mnist\n",
    "from keras import Sequential\n",
    "from keras.api.layers import Input, Dense, Flatten, Normalization\n",
    "from keras.api.optimizers import Adam, SGD\n",
    "from keras.api.callbacks import EarlyStopping, Callback, TensorBoard, ModelCheckpoint\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from time import strftime\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Exercise: Train a deep MLP on the MNIST dataset (you can load it using `tf.keras.datasets.mnist.load_data()`. See if you can get over 98% accuracy by manually tuning the hyperparameters. Try searching for the optimal learning rate by using the approach presented in this chapter (i.e., by growing the learning rate exponentially, plotting the loss, and finding the point where the loss shoots up). Next, try tuning the hyperparameters using Keras Tuner with all the bells and whistlesâ€”save checkpoints, use early stopping, and plot learning curves using TensorBoard.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit's MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "    x_train, y_train, test_size=10_000, random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert x_train.shape == (50000, 28, 28)\n",
    "assert x_valid.shape == (10000, 28, 28)\n",
    "assert x_test.shape == (10000, 28, 28)\n",
    "assert y_train.shape == (50000,)\n",
    "assert y_valid.shape == (10000,)\n",
    "assert y_test.shape == (10000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.reshape(x_train, (x_train.shape[0], -1))\n",
    "x_valid = np.reshape(x_valid, (x_valid.shape[0], -1))\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape\n",
    "x_valid.shape\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(random_state=RANDOM_STATE, max_iter=300).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9586"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale data (0-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255.0\n",
    "x_valid = x_valid / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:697: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9638"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(random_state=RANDOM_STATE, max_iter=300).fit(x_train, y_train)\n",
    "y_pred_test = clf.predict(x_test)\n",
    "accuracy_score(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=MLPClassifier(max_iter=300, random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;activation&#x27;: [&#x27;tanh&#x27;, &#x27;relu&#x27;],\n",
       "                         &#x27;alpha&#x27;: [0.0001, 0.001, 0.05, 0.1],\n",
       "                         &#x27;hidden_layer_sizes&#x27;: [(50, 50, 50), (50, 100, 50),\n",
       "                                                (100,), (100, 50)],\n",
       "                         &#x27;learning_rate&#x27;: [&#x27;constant&#x27;, &#x27;adaptive&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;sgd&#x27;, &#x27;adam&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=3, estimator=MLPClassifier(max_iter=300, random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;activation&#x27;: [&#x27;tanh&#x27;, &#x27;relu&#x27;],\n",
       "                         &#x27;alpha&#x27;: [0.0001, 0.001, 0.05, 0.1],\n",
       "                         &#x27;hidden_layer_sizes&#x27;: [(50, 50, 50), (50, 100, 50),\n",
       "                                                (100,), (100, 50)],\n",
       "                         &#x27;learning_rate&#x27;: [&#x27;constant&#x27;, &#x27;adaptive&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;sgd&#x27;, &#x27;adam&#x27;]})</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: MLPClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>MLPClassifier(alpha=0.05, max_iter=300, random_state=42)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;MLPClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.neural_network.MLPClassifier.html\">?<span>Documentation for MLPClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>MLPClassifier(alpha=0.05, max_iter=300, random_state=42)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=MLPClassifier(max_iter=300, random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'activation': ['tanh', 'relu'],\n",
       "                         'alpha': [0.0001, 0.001, 0.05, 0.1],\n",
       "                         'hidden_layer_sizes': [(50, 50, 50), (50, 100, 50),\n",
       "                                                (100,), (100, 50)],\n",
       "                         'learning_rate': ['constant', 'adaptive'],\n",
       "                         'solver': ['sgd', 'adam']})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter_space = {\n",
    "    \"hidden_layer_sizes\": [(50, 50, 50), (50, 100, 50), (100,), (100, 50)],\n",
    "    \"activation\": [\"tanh\", \"relu\"],\n",
    "    \"solver\": [\"sgd\", \"adam\"],\n",
    "    \"alpha\": [0.0001, 0.001, 0.05, 0.10],\n",
    "    \"learning_rate\": [\"constant\", \"adaptive\"],\n",
    "}\n",
    "\n",
    "mlp = MLPClassifier(random_state=RANDOM_STATE, max_iter=300)\n",
    "\n",
    "clf = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=3)\n",
    "clf.fit(x_train[:15000], y_train[:15000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:\n",
      " {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters found:\\n\", clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.942 (+/-0.008) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.945 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.942 (+/-0.008) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.945 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.941 (+/-0.004) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.947 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.941 (+/-0.004) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.947 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.927 (+/-0.011) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.950 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.927 (+/-0.011) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.950 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.936 (+/-0.006) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.952 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.936 (+/-0.006) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.952 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.942 (+/-0.008) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.945 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.942 (+/-0.008) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.945 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.941 (+/-0.004) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.948 (+/-0.006) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.941 (+/-0.004) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.948 (+/-0.006) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.927 (+/-0.011) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.951 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.927 (+/-0.011) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.951 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.936 (+/-0.006) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.951 (+/-0.006) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.936 (+/-0.006) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.951 (+/-0.006) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.942 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.952 (+/-0.004) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.942 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.952 (+/-0.004) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.941 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.955 (+/-0.006) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.941 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.955 (+/-0.006) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.927 (+/-0.011) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.958 (+/-0.004) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.927 (+/-0.011) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.958 (+/-0.004) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.936 (+/-0.006) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.953 (+/-0.011) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.936 (+/-0.006) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.953 (+/-0.011) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.942 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.1, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.953 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.1, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.942 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.1, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.953 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.1, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.941 (+/-0.004) for {'activation': 'tanh', 'alpha': 0.1, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.953 (+/-0.012) for {'activation': 'tanh', 'alpha': 0.1, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.941 (+/-0.004) for {'activation': 'tanh', 'alpha': 0.1, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.953 (+/-0.012) for {'activation': 'tanh', 'alpha': 0.1, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.926 (+/-0.010) for {'activation': 'tanh', 'alpha': 0.1, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.958 (+/-0.002) for {'activation': 'tanh', 'alpha': 0.1, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.926 (+/-0.010) for {'activation': 'tanh', 'alpha': 0.1, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.958 (+/-0.002) for {'activation': 'tanh', 'alpha': 0.1, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.936 (+/-0.006) for {'activation': 'tanh', 'alpha': 0.1, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.960 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.1, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.936 (+/-0.006) for {'activation': 'tanh', 'alpha': 0.1, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.960 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.1, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.937 (+/-0.004) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.948 (+/-0.008) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.937 (+/-0.004) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.948 (+/-0.008) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.942 (+/-0.004) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.949 (+/-0.004) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.942 (+/-0.004) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.949 (+/-0.004) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.931 (+/-0.011) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.951 (+/-0.007) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.931 (+/-0.011) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.951 (+/-0.007) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.942 (+/-0.007) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.954 (+/-0.002) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.942 (+/-0.007) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.954 (+/-0.002) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.937 (+/-0.005) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.947 (+/-0.008) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.937 (+/-0.005) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.947 (+/-0.008) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.942 (+/-0.004) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.948 (+/-0.003) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.942 (+/-0.004) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.948 (+/-0.003) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.931 (+/-0.011) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.950 (+/-0.007) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.931 (+/-0.011) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.950 (+/-0.007) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.942 (+/-0.007) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.953 (+/-0.002) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.942 (+/-0.007) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.953 (+/-0.002) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.938 (+/-0.004) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.948 (+/-0.002) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.938 (+/-0.004) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.948 (+/-0.002) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.943 (+/-0.003) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.955 (+/-0.001) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.943 (+/-0.003) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.955 (+/-0.001) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.931 (+/-0.011) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.961 (+/-0.005) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.931 (+/-0.011) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.961 (+/-0.005) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.942 (+/-0.007) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.960 (+/-0.002) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.942 (+/-0.007) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.960 (+/-0.002) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.938 (+/-0.005) for {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.952 (+/-0.001) for {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.938 (+/-0.005) for {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.952 (+/-0.001) for {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.943 (+/-0.002) for {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.958 (+/-0.001) for {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.943 (+/-0.002) for {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.958 (+/-0.001) for {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.931 (+/-0.011) for {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.961 (+/-0.004) for {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.931 (+/-0.011) for {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.961 (+/-0.004) for {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.942 (+/-0.007) for {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.959 (+/-0.008) for {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.942 (+/-0.007) for {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.959 (+/-0.008) for {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "means = clf.cv_results_[\"mean_test_score\"]\n",
    "stds = clf.cv_results_[\"std_test_score\"]\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_[\"params\"]):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results on the test set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       984\n",
      "           1       0.98      0.99      0.98      1093\n",
      "           2       0.97      0.96      0.97       994\n",
      "           3       0.97      0.96      0.96      1000\n",
      "           4       0.96      0.98      0.97       980\n",
      "           5       0.96      0.96      0.96       919\n",
      "           6       0.97      0.98      0.98       981\n",
      "           7       0.97      0.98      0.98      1060\n",
      "           8       0.97      0.93      0.95       979\n",
      "           9       0.95      0.96      0.96      1010\n",
      "\n",
      "    accuracy                           0.97     10000\n",
      "   macro avg       0.97      0.97      0.97     10000\n",
      "weighted avg       0.97      0.97      0.97     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true, y_pred = y_valid, clf.predict(x_valid)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"Results on the test set:\")\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9669"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test = clf.predict(x_test)\n",
    "accuracy_score(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9808"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_mlp = MLPClassifier(**clf.best_params_)\n",
    "best_mlp.fit(x_train, y_train)\n",
    "y_pred_test = best_mlp.predict(x_test)\n",
    "accuracy_score(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow / Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "np.random.seed(RANDOM_STATE)\n",
    "tf.random.set_seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_full, y_train_full), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "    x_train_full, y_train_full, test_size=10_000, random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize so we work with range of 0 to 1 and convert to float\n",
    "x_train_full, x_train, x_valid, x_test = map(\n",
    "    lambda x: x / 255.0, (x_train_full, x_train, x_valid, x_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract input shape of input data (shape of each instance)\n",
    "input_shape = np.shape(x_train_full)[1:]\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1738915161.468226    1003 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2874 MB memory:  -> device: 0, name: Quadro P600, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">235,500</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">90,300</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">90,300</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">90,300</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,010</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ flatten (\u001b[38;5;33mFlatten\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            â”‚       \u001b[38;5;34m235,500\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            â”‚        \u001b[38;5;34m90,300\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            â”‚        \u001b[38;5;34m90,300\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            â”‚        \u001b[38;5;34m90,300\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             â”‚         \u001b[38;5;34m3,010\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">509,410</span> (1.94 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m509,410\u001b[0m (1.94 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">509,410</span> (1.94 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m509,410\u001b[0m (1.94 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=input_shape))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(300, activation=\"relu\"))\n",
    "model.add(Dense(300, activation=\"relu\"))\n",
    "model.add(Dense(300, activation=\"relu\"))\n",
    "model.add(Dense(300, activation=\"relu\"))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExponentialLearningRate(Callback):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        self.rates = []\n",
    "        self.losses = []\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        lr = self.model.optimizer.learning_rate.numpy() * self.factor\n",
    "        self.model.optimizer.learning_rate = lr\n",
    "        self.rates.append(lr)\n",
    "        self.losses.append(logs[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1738915174.373794    2274 service.cc:148] XLA service 0x7feadc007930 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1738915174.374322    2274 service.cc:156]   StreamExecutor device (0): Quadro P600, Compute Capability 6.1\n",
      "2025-02-07 08:59:34.433945: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1738915174.621628    2274 cuda_dnn.cc:529] Loaded cuDNN version 90700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  36/1563\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.4489 - loss: 1.7006"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1738915176.142125    2274 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - accuracy: 0.6351 - loss: 1.1486 - val_accuracy: 0.0984 - val_loss: 2.5051\n"
     ]
    }
   ],
   "source": [
    "expon_lr = ExponentialLearningRate(factor=1.005)\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=1,\n",
    "    validation_data=(x_valid, y_valid),\n",
    "    callbacks=[expon_lr],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(expon_lr.rates, expon_lr.losses)\n",
    "plt.gca().set_xscale(\"log\")\n",
    "plt.hlines(min(expon_lr.losses), min(expon_lr.rates), max(expon_lr.rates))\n",
    "plt.axis([min(expon_lr.rates), max(expon_lr.rates), 0, expon_lr.losses[0]])\n",
    "plt.grid()\n",
    "plt.xlabel(\"Learning rate\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1738872771.262450    4664 service.cc:148] XLA service 0x7f36fc0067c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1738872771.262507    4664 service.cc:156]   StreamExecutor device (0): Quadro P600, Compute Capability 6.1\n",
      "2025-02-06 21:12:51.294251: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1738872771.473339    4664 cuda_dnn.cc:529] Loaded cuDNN version 90700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  70/1563\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5824 - loss: 1.3090"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1738872772.999749    4664 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8885 - loss: 0.3627 - val_accuracy: 0.9595 - val_loss: 0.1332\n",
      "Epoch 2/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9670 - loss: 0.1089 - val_accuracy: 0.9648 - val_loss: 0.1176\n",
      "Epoch 3/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9764 - loss: 0.0743 - val_accuracy: 0.9700 - val_loss: 0.1120\n",
      "Epoch 4/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9828 - loss: 0.0551 - val_accuracy: 0.9732 - val_loss: 0.1026\n",
      "Epoch 5/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9859 - loss: 0.0470 - val_accuracy: 0.9732 - val_loss: 0.1056\n",
      "Epoch 6/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9874 - loss: 0.0402 - val_accuracy: 0.9742 - val_loss: 0.1060\n",
      "Epoch 7/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9896 - loss: 0.0308 - val_accuracy: 0.9776 - val_loss: 0.1033\n",
      "Epoch 8/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9922 - loss: 0.0286 - val_accuracy: 0.9776 - val_loss: 0.0988\n",
      "Epoch 9/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9920 - loss: 0.0282 - val_accuracy: 0.9773 - val_loss: 0.1148\n",
      "Epoch 10/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9922 - loss: 0.0238 - val_accuracy: 0.9732 - val_loss: 0.1300\n",
      "Epoch 11/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9933 - loss: 0.0209 - val_accuracy: 0.9764 - val_loss: 0.1237\n",
      "Epoch 12/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9946 - loss: 0.0170 - val_accuracy: 0.9779 - val_loss: 0.1204\n",
      "Epoch 13/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9940 - loss: 0.0175 - val_accuracy: 0.9775 - val_loss: 0.1211\n",
      "Epoch 14/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9930 - loss: 0.0231 - val_accuracy: 0.9779 - val_loss: 0.1341\n",
      "Epoch 15/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9948 - loss: 0.0181 - val_accuracy: 0.9737 - val_loss: 0.1374\n",
      "Epoch 16/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9950 - loss: 0.0157 - val_accuracy: 0.9786 - val_loss: 0.1354\n",
      "Epoch 17/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9960 - loss: 0.0146 - val_accuracy: 0.9812 - val_loss: 0.1383\n",
      "Epoch 18/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9962 - loss: 0.0150 - val_accuracy: 0.9784 - val_loss: 0.1382\n",
      "Epoch 19/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9952 - loss: 0.0183 - val_accuracy: 0.9798 - val_loss: 0.1263\n",
      "Epoch 20/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9964 - loss: 0.0126 - val_accuracy: 0.9804 - val_loss: 0.1289\n",
      "Epoch 21/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9969 - loss: 0.0109 - val_accuracy: 0.9796 - val_loss: 0.1463\n",
      "Epoch 22/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9968 - loss: 0.0119 - val_accuracy: 0.9780 - val_loss: 0.1428\n",
      "Epoch 23/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9964 - loss: 0.0141 - val_accuracy: 0.9787 - val_loss: 0.1608\n",
      "Epoch 24/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9968 - loss: 0.0138 - val_accuracy: 0.9799 - val_loss: 0.1508\n",
      "Epoch 25/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9969 - loss: 0.0107 - val_accuracy: 0.9753 - val_loss: 0.2108\n",
      "Epoch 26/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9945 - loss: 0.0259 - val_accuracy: 0.9827 - val_loss: 0.1455\n",
      "Epoch 27/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9980 - loss: 0.0075 - val_accuracy: 0.9790 - val_loss: 0.1923\n",
      "Epoch 28/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9961 - loss: 0.0160 - val_accuracy: 0.9822 - val_loss: 0.1624\n",
      "Epoch 29/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0069 - val_accuracy: 0.9789 - val_loss: 0.1930\n",
      "Epoch 30/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9972 - loss: 0.0108 - val_accuracy: 0.9794 - val_loss: 0.1866\n",
      "Epoch 31/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9972 - loss: 0.0154 - val_accuracy: 0.9794 - val_loss: 0.1865\n",
      "Epoch 32/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9975 - loss: 0.0100 - val_accuracy: 0.9804 - val_loss: 0.1722\n",
      "Epoch 33/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9971 - loss: 0.0098 - val_accuracy: 0.9812 - val_loss: 0.2016\n",
      "Epoch 34/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9974 - loss: 0.0129 - val_accuracy: 0.9789 - val_loss: 0.2046\n",
      "Epoch 35/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9973 - loss: 0.0126 - val_accuracy: 0.9795 - val_loss: 0.1765\n",
      "Epoch 36/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9975 - loss: 0.0118 - val_accuracy: 0.9808 - val_loss: 0.2112\n",
      "Epoch 37/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9979 - loss: 0.0096 - val_accuracy: 0.9810 - val_loss: 0.1864\n",
      "Epoch 38/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0044 - val_accuracy: 0.9816 - val_loss: 0.1687\n",
      "Epoch 39/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9973 - loss: 0.0107 - val_accuracy: 0.9813 - val_loss: 0.1747\n",
      "Epoch 40/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0053 - val_accuracy: 0.9744 - val_loss: 0.2895\n",
      "Epoch 41/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9969 - loss: 0.0167 - val_accuracy: 0.9805 - val_loss: 0.1956\n",
      "Epoch 42/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9979 - loss: 0.0095 - val_accuracy: 0.9813 - val_loss: 0.2154\n",
      "Epoch 43/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9979 - loss: 0.0111 - val_accuracy: 0.9776 - val_loss: 0.2004\n",
      "Epoch 44/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9981 - loss: 0.0099 - val_accuracy: 0.9806 - val_loss: 0.2443\n",
      "Epoch 45/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9966 - loss: 0.0211 - val_accuracy: 0.9823 - val_loss: 0.2024\n",
      "Epoch 46/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0083 - val_accuracy: 0.9797 - val_loss: 0.1926\n",
      "Epoch 47/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9978 - loss: 0.0104 - val_accuracy: 0.9811 - val_loss: 0.2140\n",
      "Epoch 48/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9973 - loss: 0.0122 - val_accuracy: 0.9815 - val_loss: 0.2345\n",
      "Epoch 49/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9973 - loss: 0.0151 - val_accuracy: 0.9836 - val_loss: 0.1929\n",
      "Epoch 50/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0042 - val_accuracy: 0.9812 - val_loss: 0.2155\n",
      "Epoch 51/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0106 - val_accuracy: 0.9825 - val_loss: 0.2166\n",
      "Epoch 52/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9979 - loss: 0.0117 - val_accuracy: 0.9835 - val_loss: 0.2126\n",
      "Epoch 53/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0084 - val_accuracy: 0.9806 - val_loss: 0.2389\n",
      "Epoch 54/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0123 - val_accuracy: 0.9796 - val_loss: 0.2498\n",
      "Epoch 55/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0091 - val_accuracy: 0.9804 - val_loss: 0.2285\n",
      "Epoch 56/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0054 - val_accuracy: 0.9794 - val_loss: 0.2952\n",
      "Epoch 57/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9975 - loss: 0.0168 - val_accuracy: 0.9800 - val_loss: 0.2664\n",
      "Epoch 58/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9971 - loss: 0.0179 - val_accuracy: 0.9802 - val_loss: 0.2792\n",
      "Epoch 59/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0105 - val_accuracy: 0.9819 - val_loss: 0.2249\n",
      "Epoch 60/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0074 - val_accuracy: 0.9842 - val_loss: 0.2533\n",
      "Epoch 61/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0029 - val_accuracy: 0.9809 - val_loss: 0.2704\n",
      "Epoch 62/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0103 - val_accuracy: 0.9808 - val_loss: 0.2826\n",
      "Epoch 63/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0091 - val_accuracy: 0.9825 - val_loss: 0.2696\n",
      "Epoch 64/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0091 - val_accuracy: 0.9770 - val_loss: 0.3500\n",
      "Epoch 65/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9977 - loss: 0.0133 - val_accuracy: 0.9818 - val_loss: 0.3053\n",
      "Epoch 66/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0085 - val_accuracy: 0.9815 - val_loss: 0.3059\n",
      "Epoch 67/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0065 - val_accuracy: 0.9811 - val_loss: 0.3300\n",
      "Epoch 68/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0105 - val_accuracy: 0.9804 - val_loss: 0.3056\n",
      "Epoch 69/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0133 - val_accuracy: 0.9817 - val_loss: 0.2780\n",
      "Epoch 70/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0079 - val_accuracy: 0.9820 - val_loss: 0.3175\n",
      "Epoch 71/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0083 - val_accuracy: 0.9797 - val_loss: 0.3677\n",
      "Epoch 72/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0158 - val_accuracy: 0.9810 - val_loss: 0.3622\n",
      "Epoch 73/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0074 - val_accuracy: 0.9801 - val_loss: 0.3321\n",
      "Epoch 74/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0118 - val_accuracy: 0.9816 - val_loss: 0.2508\n",
      "Epoch 75/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0026 - val_accuracy: 0.9821 - val_loss: 0.2971\n",
      "Epoch 76/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0092 - val_accuracy: 0.9807 - val_loss: 0.3537\n",
      "Epoch 77/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0118 - val_accuracy: 0.9836 - val_loss: 0.2673\n",
      "Epoch 78/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0074 - val_accuracy: 0.9825 - val_loss: 0.2870\n",
      "Epoch 79/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0045 - val_accuracy: 0.9786 - val_loss: 0.3903\n",
      "Epoch 80/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0106 - val_accuracy: 0.9818 - val_loss: 0.3133\n",
      "Epoch 81/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0069 - val_accuracy: 0.9802 - val_loss: 0.2947\n",
      "Epoch 82/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0081 - val_accuracy: 0.9801 - val_loss: 0.3427\n",
      "Epoch 83/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0140 - val_accuracy: 0.9811 - val_loss: 0.3205\n",
      "Epoch 84/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0078 - val_accuracy: 0.9799 - val_loss: 0.3454\n",
      "Epoch 85/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9984 - loss: 0.0148 - val_accuracy: 0.9827 - val_loss: 0.2967\n",
      "Epoch 86/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0077 - val_accuracy: 0.9805 - val_loss: 0.3266\n",
      "Epoch 87/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0116 - val_accuracy: 0.9800 - val_loss: 0.3460\n",
      "Epoch 88/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9980 - loss: 0.0127 - val_accuracy: 0.9826 - val_loss: 0.3658\n",
      "Epoch 89/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0140 - val_accuracy: 0.9839 - val_loss: 0.3526\n",
      "Epoch 90/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0091 - val_accuracy: 0.9822 - val_loss: 0.2904\n",
      "Epoch 91/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0095 - val_accuracy: 0.9823 - val_loss: 0.3408\n",
      "Epoch 92/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0074 - val_accuracy: 0.9789 - val_loss: 0.4420\n",
      "Epoch 93/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0125 - val_accuracy: 0.9797 - val_loss: 0.3385\n",
      "Epoch 94/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0055 - val_accuracy: 0.9831 - val_loss: 0.3160\n",
      "Epoch 95/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0043 - val_accuracy: 0.9782 - val_loss: 0.4313\n",
      "Epoch 96/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0131 - val_accuracy: 0.9826 - val_loss: 0.3649\n",
      "Epoch 97/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0055 - val_accuracy: 0.9804 - val_loss: 0.4524\n",
      "Epoch 98/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0089 - val_accuracy: 0.9798 - val_loss: 0.4785\n",
      "Epoch 99/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9977 - loss: 0.0294 - val_accuracy: 0.9803 - val_loss: 0.3626\n",
      "Epoch 100/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0070 - val_accuracy: 0.9833 - val_loss: 0.3032\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_train, y_train, batch_size=32, epochs=100, validation_data=(x_valid, y_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(\n",
    "    figsize=(8, 5),\n",
    "    xlim=[0, 59],\n",
    "    ylim=[0, 1],\n",
    "    grid=True,\n",
    "    xlabel=\"Epoch\",\n",
    "    style=[\"r--\", \"r--.\", \"b-\", \"b-*\"],\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difference between train and validation accurracy points to overfitting. Constant increase in validation loss is another sign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9791 - loss: 0.4660\n",
      "test loss, test acc: [0.3696935474872589, 0.9822999835014343]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test, y_test)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual DNN hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('my_logs/run_2025_02_07_09_31_48')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_run_logdir(root_logdir=\"my_logs\"):\n",
    "    return Path(root_logdir) / strftime(\"run_%Y_%m_%d_%H_%M_%S\")\n",
    "\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">235,500</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">90,300</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">90,300</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">90,300</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,010</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            â”‚       \u001b[38;5;34m235,500\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            â”‚        \u001b[38;5;34m90,300\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            â”‚        \u001b[38;5;34m90,300\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            â”‚        \u001b[38;5;34m90,300\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             â”‚         \u001b[38;5;34m3,010\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">509,410</span> (1.94 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m509,410\u001b[0m (1.94 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">509,410</span> (1.94 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m509,410\u001b[0m (1.94 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=input_shape))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(300, activation=\"relu\"))\n",
    "model.add(Dense(300, activation=\"relu\"))\n",
    "model.add(Dense(300, activation=\"relu\"))\n",
    "model.add(Dense(300, activation=\"relu\"))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintValTrainRatioCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        ratio = logs[\"val_loss\"] / logs[\"loss\"]\n",
    "        print(f\"Epoch={epoch}, val/train={ratio:.2f}\")\n",
    "        return super().on_epoch_end(epoch, logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8799 - loss: 0.3829Epoch=0, val/train=0.61\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8800 - loss: 0.3828 - val_accuracy: 0.9591 - val_loss: 0.1372\n",
      "Epoch 2/100\n",
      "\u001b[1m1557/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9650 - loss: 0.1171Epoch=1, val/train=1.06\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9650 - loss: 0.1171 - val_accuracy: 0.9683 - val_loss: 0.1132\n",
      "Epoch 3/100\n",
      "\u001b[1m1557/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9767 - loss: 0.0806Epoch=2, val/train=1.63\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9767 - loss: 0.0806 - val_accuracy: 0.9677 - val_loss: 0.1210\n",
      "Epoch 4/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9805 - loss: 0.0652Epoch=3, val/train=1.69\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9805 - loss: 0.0652 - val_accuracy: 0.9722 - val_loss: 0.1011\n",
      "Epoch 5/100\n",
      "\u001b[1m1560/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9831 - loss: 0.0575Epoch=4, val/train=2.06\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9831 - loss: 0.0575 - val_accuracy: 0.9746 - val_loss: 0.1083\n",
      "Epoch 6/100\n",
      "\u001b[1m1562/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9871 - loss: 0.0420Epoch=5, val/train=2.91\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9872 - loss: 0.0420 - val_accuracy: 0.9714 - val_loss: 0.1172\n",
      "Epoch 7/100\n",
      "\u001b[1m1562/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9880 - loss: 0.0387Epoch=6, val/train=3.51\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9880 - loss: 0.0387 - val_accuracy: 0.9722 - val_loss: 0.1270\n",
      "Epoch 8/100\n",
      "\u001b[1m1557/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9887 - loss: 0.0371Epoch=7, val/train=2.80\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9887 - loss: 0.0371 - val_accuracy: 0.9773 - val_loss: 0.0994\n",
      "Epoch 9/100\n",
      "\u001b[1m1559/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9913 - loss: 0.0300Epoch=8, val/train=4.16\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9913 - loss: 0.0300 - val_accuracy: 0.9746 - val_loss: 0.1227\n",
      "Epoch 10/100\n",
      "\u001b[1m1556/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9922 - loss: 0.0283Epoch=9, val/train=4.13\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9922 - loss: 0.0283 - val_accuracy: 0.9764 - val_loss: 0.1154\n",
      "Epoch 11/100\n",
      "\u001b[1m1559/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9919 - loss: 0.0289Epoch=10, val/train=4.57\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9919 - loss: 0.0289 - val_accuracy: 0.9776 - val_loss: 0.1168\n",
      "Epoch 12/100\n",
      "\u001b[1m1560/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9936 - loss: 0.0227Epoch=11, val/train=5.16\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9936 - loss: 0.0227 - val_accuracy: 0.9770 - val_loss: 0.1174\n",
      "Epoch 13/100\n",
      "\u001b[1m1560/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9926 - loss: 0.0232Epoch=12, val/train=6.28\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9926 - loss: 0.0232 - val_accuracy: 0.9807 - val_loss: 0.1254\n",
      "Epoch 14/100\n",
      "\u001b[1m1561/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9940 - loss: 0.0209Epoch=13, val/train=5.20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9939 - loss: 0.0209 - val_accuracy: 0.9809 - val_loss: 0.1189\n",
      "Epoch 15/100\n",
      "\u001b[1m1556/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9942 - loss: 0.0205Epoch=14, val/train=6.54\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9942 - loss: 0.0205 - val_accuracy: 0.9768 - val_loss: 0.1336\n",
      "Epoch 16/100\n",
      "\u001b[1m1556/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9938 - loss: 0.0211Epoch=15, val/train=6.13\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9938 - loss: 0.0211 - val_accuracy: 0.9785 - val_loss: 0.1308\n",
      "Epoch 17/100\n",
      "\u001b[1m1559/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9953 - loss: 0.0171Epoch=16, val/train=8.11\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9953 - loss: 0.0171 - val_accuracy: 0.9822 - val_loss: 0.1330\n",
      "Epoch 18/100\n",
      "\u001b[1m1556/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9952 - loss: 0.0186Epoch=17, val/train=6.41\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9952 - loss: 0.0186 - val_accuracy: 0.9798 - val_loss: 0.1173\n",
      "Epoch 19/100\n",
      "\u001b[1m1557/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9951 - loss: 0.0183Epoch=18, val/train=6.69\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9951 - loss: 0.0183 - val_accuracy: 0.9814 - val_loss: 0.1174\n",
      "Epoch 20/100\n",
      "\u001b[1m1557/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9955 - loss: 0.0172Epoch=19, val/train=7.38\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9955 - loss: 0.0172 - val_accuracy: 0.9802 - val_loss: 0.1302\n",
      "Epoch 21/100\n",
      "\u001b[1m1561/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9968 - loss: 0.0123Epoch=20, val/train=9.06\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9968 - loss: 0.0123 - val_accuracy: 0.9802 - val_loss: 0.1352\n",
      "Epoch 22/100\n",
      "\u001b[1m1558/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9968 - loss: 0.0158Epoch=21, val/train=7.86\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9968 - loss: 0.0158 - val_accuracy: 0.9816 - val_loss: 0.1275\n",
      "Epoch 23/100\n",
      "\u001b[1m1562/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9961 - loss: 0.0154Epoch=22, val/train=9.49\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9961 - loss: 0.0154 - val_accuracy: 0.9811 - val_loss: 0.1438\n",
      "Epoch 24/100\n",
      "\u001b[1m1557/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9965 - loss: 0.0140Epoch=23, val/train=13.58\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9965 - loss: 0.0140 - val_accuracy: 0.9710 - val_loss: 0.2002\n",
      "Epoch 25/100\n",
      "\u001b[1m1559/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9950 - loss: 0.0187Epoch=24, val/train=11.22\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9950 - loss: 0.0187 - val_accuracy: 0.9796 - val_loss: 0.1736\n",
      "Epoch 26/100\n",
      "\u001b[1m1562/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9967 - loss: 0.0144Epoch=25, val/train=7.87\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9967 - loss: 0.0144 - val_accuracy: 0.9836 - val_loss: 0.1170\n",
      "Epoch 27/100\n",
      "\u001b[1m1561/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9965 - loss: 0.0166Epoch=26, val/train=8.29\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9965 - loss: 0.0166 - val_accuracy: 0.9808 - val_loss: 0.1444\n",
      "Epoch 28/100\n",
      "\u001b[1m1562/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9965 - loss: 0.0163Epoch=27, val/train=10.09\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9965 - loss: 0.0163 - val_accuracy: 0.9823 - val_loss: 0.1393\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=32,\n",
    "    epochs=100,\n",
    "    validation_data=(x_valid, y_valid),\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=20, restore_best_weights=True),\n",
    "        PrintValTrainRatioCallback(),\n",
    "        TensorBoard(get_run_logdir()),\n",
    "        ModelCheckpoint(\"my_checkpoints/checkpoint.weights.h5\", save_weights_only=True),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9735 - loss: 0.1167\n",
      "test loss, test acc: [0.09471593052148819, 0.9782999753952026]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test, y_test)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test loss is smaller but accuracy dropped as well.\n",
    "\n",
    "Higher learning rate (0.002) performs worse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More neurons and layers seems to be better (higher accuracy).\n",
    "\n",
    "Less neurons and layers doesn't lower overfitting.\n",
    "\n",
    "98% accuracy on test set achieved by adding another hidden layer (4)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp: HyperParameters) -> Sequential:\n",
    "    n_hidden = hp.Int(\"n_hidden\", min_value=2, max_value=8, default=4)\n",
    "    n_neurons = hp.Int(\"n_neurons\", min_value=128, max_value=512)\n",
    "    learning_rate = hp.Float(\n",
    "        \"learning_rate\", min_value=1e-3, max_value=1e-2, sampling=\"log\"\n",
    "    )\n",
    "    optimizer = hp.Choice(\"optimizer\", values=[\"sgd\", \"adam\"])\n",
    "    if optimizer == \"sgd\":\n",
    "        optimizer = SGD(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Flatten())\n",
    "    for _ in range(n_hidden):\n",
    "        model.add(Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        optimizer=optimizer,\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyClassificationHyperModel(HyperModel):\n",
    "\n",
    "    def build(self, hp):\n",
    "        return build_model(hp)\n",
    "\n",
    "    def fit(self, hp, model, X, y, **kwargs):\n",
    "        if hp.Boolean(\"normalize\"):\n",
    "            norm_layer = Normalization()\n",
    "            X = norm_layer(X)\n",
    "        batch_size = hp.Int(\"batch_size\", min_value=16, max_value=128, default=32, step=16)\n",
    "        return model.fit(X, y, batch_size=batch_size, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "5                 |5                 |n_hidden\n",
      "25                |25                |n_neurons\n",
      "0.00065625        |0.00065625        |learning_rate\n",
      "sgd               |sgd               |optimizer\n",
      "\n",
      "Epoch 1/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.1098 - loss: 2.3106 - val_accuracy: 0.1497 - val_loss: 2.2797\n",
      "Epoch 2/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.1697 - loss: 2.2695 - val_accuracy: 0.2031 - val_loss: 2.2286\n",
      "Epoch 3/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.2077 - loss: 2.2095 - val_accuracy: 0.2404 - val_loss: 2.1426\n",
      "Epoch 4/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.2688 - loss: 2.1172 - val_accuracy: 0.3319 - val_loss: 2.0434\n",
      "Epoch 5/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.3535 - loss: 2.0130 - val_accuracy: 0.4093 - val_loss: 1.9111\n",
      "Epoch 6/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.4393 - loss: 1.8613 - val_accuracy: 0.5092 - val_loss: 1.6845\n",
      "Epoch 7/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.5253 - loss: 1.6039 - val_accuracy: 0.5838 - val_loss: 1.3229\n",
      "Epoch 8/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.6150 - loss: 1.2312 - val_accuracy: 0.6873 - val_loss: 1.0053\n",
      "Epoch 9/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.7089 - loss: 0.9591 - val_accuracy: 0.7349 - val_loss: 0.8351\n",
      "Epoch 10/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.7518 - loss: 0.8113 - val_accuracy: 0.7759 - val_loss: 0.7274\n",
      "Epoch 11/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.7830 - loss: 0.7130 - val_accuracy: 0.8032 - val_loss: 0.6504\n",
      "Epoch 12/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8061 - loss: 0.6406 - val_accuracy: 0.8200 - val_loss: 0.5919\n",
      "Epoch 13/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8246 - loss: 0.5843 - val_accuracy: 0.8368 - val_loss: 0.5458\n",
      "Epoch 14/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8393 - loss: 0.5396 - val_accuracy: 0.8517 - val_loss: 0.5085\n",
      "Epoch 15/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8503 - loss: 0.5033 - val_accuracy: 0.8621 - val_loss: 0.4775\n",
      "Epoch 16/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8593 - loss: 0.4732 - val_accuracy: 0.8696 - val_loss: 0.4512\n",
      "Epoch 17/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8685 - loss: 0.4478 - val_accuracy: 0.8743 - val_loss: 0.4290\n",
      "Epoch 18/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8744 - loss: 0.4262 - val_accuracy: 0.8809 - val_loss: 0.4101\n",
      "Epoch 19/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8803 - loss: 0.4077 - val_accuracy: 0.8851 - val_loss: 0.3940\n",
      "Epoch 20/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8854 - loss: 0.3918 - val_accuracy: 0.8901 - val_loss: 0.3799\n",
      "Epoch 21/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8898 - loss: 0.3778 - val_accuracy: 0.8941 - val_loss: 0.3675\n",
      "Epoch 22/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8938 - loss: 0.3653 - val_accuracy: 0.8967 - val_loss: 0.3567\n",
      "Epoch 23/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8977 - loss: 0.3543 - val_accuracy: 0.8998 - val_loss: 0.3469\n",
      "Epoch 24/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9004 - loss: 0.3444 - val_accuracy: 0.9017 - val_loss: 0.3382\n",
      "Epoch 25/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9024 - loss: 0.3356 - val_accuracy: 0.9041 - val_loss: 0.3302\n",
      "Epoch 26/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9044 - loss: 0.3274 - val_accuracy: 0.9054 - val_loss: 0.3227\n",
      "Epoch 27/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9067 - loss: 0.3198 - val_accuracy: 0.9079 - val_loss: 0.3159\n",
      "Epoch 28/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9090 - loss: 0.3128 - val_accuracy: 0.9098 - val_loss: 0.3095\n",
      "Epoch 29/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9113 - loss: 0.3062 - val_accuracy: 0.9108 - val_loss: 0.3036\n",
      "Epoch 30/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9126 - loss: 0.3000 - val_accuracy: 0.9124 - val_loss: 0.2980\n",
      "Epoch 31/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9148 - loss: 0.2942 - val_accuracy: 0.9129 - val_loss: 0.2927\n",
      "Epoch 32/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9165 - loss: 0.2885 - val_accuracy: 0.9145 - val_loss: 0.2876\n",
      "Epoch 33/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9178 - loss: 0.2832 - val_accuracy: 0.9155 - val_loss: 0.2829\n",
      "Epoch 34/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9190 - loss: 0.2781 - val_accuracy: 0.9172 - val_loss: 0.2783\n",
      "Epoch 35/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9203 - loss: 0.2732 - val_accuracy: 0.9199 - val_loss: 0.2741\n",
      "Epoch 36/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9213 - loss: 0.2686 - val_accuracy: 0.9222 - val_loss: 0.2699\n",
      "Epoch 37/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9228 - loss: 0.2642 - val_accuracy: 0.9226 - val_loss: 0.2660\n",
      "Epoch 38/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9243 - loss: 0.2599 - val_accuracy: 0.9244 - val_loss: 0.2621\n",
      "Epoch 39/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9256 - loss: 0.2559 - val_accuracy: 0.9251 - val_loss: 0.2585\n",
      "Epoch 40/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9266 - loss: 0.2519 - val_accuracy: 0.9261 - val_loss: 0.2550\n",
      "Epoch 41/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9274 - loss: 0.2482 - val_accuracy: 0.9281 - val_loss: 0.2516\n",
      "Epoch 42/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9281 - loss: 0.2445 - val_accuracy: 0.9279 - val_loss: 0.2484\n",
      "Epoch 43/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9295 - loss: 0.2410 - val_accuracy: 0.9282 - val_loss: 0.2453\n",
      "Epoch 44/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9310 - loss: 0.2376 - val_accuracy: 0.9292 - val_loss: 0.2424\n",
      "Epoch 45/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9317 - loss: 0.2342 - val_accuracy: 0.9302 - val_loss: 0.2395\n",
      "Epoch 46/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9326 - loss: 0.2310 - val_accuracy: 0.9315 - val_loss: 0.2367\n",
      "Epoch 47/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9339 - loss: 0.2278 - val_accuracy: 0.9319 - val_loss: 0.2340\n",
      "Epoch 48/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9349 - loss: 0.2248 - val_accuracy: 0.9331 - val_loss: 0.2315\n",
      "Epoch 49/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9358 - loss: 0.2217 - val_accuracy: 0.9336 - val_loss: 0.2290\n",
      "Epoch 50/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9369 - loss: 0.2188 - val_accuracy: 0.9346 - val_loss: 0.2267\n",
      "Epoch 51/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9380 - loss: 0.2160 - val_accuracy: 0.9351 - val_loss: 0.2244\n",
      "Epoch 52/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9385 - loss: 0.2133 - val_accuracy: 0.9350 - val_loss: 0.2223\n",
      "Epoch 53/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9390 - loss: 0.2106 - val_accuracy: 0.9356 - val_loss: 0.2202\n",
      "Epoch 54/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9393 - loss: 0.2080 - val_accuracy: 0.9363 - val_loss: 0.2181\n",
      "Epoch 55/100\n",
      "\u001b[1m 159/1563\u001b[0m \u001b[32mâ”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.9402 - loss: 0.1977"
     ]
    }
   ],
   "source": [
    "random_search_tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=5,\n",
    "    seed=RANDOM_STATE,\n",
    "    overwrite=True,\n",
    "    directory=\"my_mnist\",\n",
    "    project_name=\"my_rnd_search\",\n",
    ")\n",
    "random_search_tuner.search(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(x_valid, y_valid),\n",
    "    callbacks=[EarlyStopping(patience=2), TensorBoard(get_run_logdir())],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperband_tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    seed=RANDOM_STATE,\n",
    "    max_epochs=10,\n",
    "    factor=3,\n",
    "    hyperband_iterations=2,\n",
    "    overwrite=True,\n",
    "    directory=\"my_mnist\",\n",
    "    project_name=\"hyperband\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Complete [00h 00m 19s]\n",
      "val_accuracy: 0.43540000915527344\n",
      "\n",
      "Best val_accuracy So Far: 0.43540000915527344\n",
      "Total elapsed time: 00h 00m 41s\n",
      "\n",
      "Search: Running Trial #3\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "5                 |8                 |n_hidden\n",
      "221               |263               |n_neurons\n",
      "0.0090513         |0.0012483         |learning_rate\n",
      "adam              |sgd               |optimizer\n",
      "2                 |2                 |tuner/epochs\n",
      "0                 |0                 |tuner/initial_epoch\n",
      "2                 |2                 |tuner/bracket\n",
      "0                 |0                 |tuner/round\n",
      "\n",
      "Epoch 1/2\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.8236 - loss: 0.6204 - val_accuracy: 0.9181 - val_loss: 0.3215\n",
      "Epoch 2/2\n",
      "\u001b[1m 852/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9298 - loss: 0.3065"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m tensorboard_cb \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mTensorBoard(root_logdir)\n\u001b[1;32m      3\u001b[0m early_stopping_cb \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mhyperband_tuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_valid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping_cb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensorboard_cb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:234\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_end(trial)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:274\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m         trial\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m trial_module\u001b[38;5;241m.\u001b[39mTrialStatus\u001b[38;5;241m.\u001b[39mCOMPLETED\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:239\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[0;32m--> 239\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_trial(trial\u001b[38;5;241m.\u001b[39mtrial_id)\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mexists(\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m    242\u001b[0m     ):\n\u001b[1;32m    243\u001b[0m         \u001b[38;5;66;03m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;66;03m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;66;03m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[1;32m    246\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe use case of calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    248\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    254\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    255\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/keras_tuner/src/tuners/hyperband.py:427\u001b[0m, in \u001b[0;36mHyperband.run_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    425\u001b[0m     fit_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m hp\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtuner/epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    426\u001b[0m     fit_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m hp\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtuner/initial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py:314\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(model_checkpoint)\n\u001b[1;32m    313\u001b[0m     copied_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m callbacks\n\u001b[0;32m--> 314\u001b[0m     obj_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_and_fit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcopied_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m     histories\u001b[38;5;241m.\u001b[39mappend(obj_value)\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py:233\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m hp \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39mhyperparameters\n\u001b[1;32m    232\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_build(hp)\n\u001b[0;32m--> 233\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhypermodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m# Save the build config for model loading later.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmulti_backend():\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/keras_tuner/src/engine/hypermodel.py:149\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    126\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:321\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    319\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m    320\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m--> 321\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/keras/src/callbacks/callback_list.py:178\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_async_dispatch(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_train_batch_end, batch, logs)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_on_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/keras/src/callbacks/callback_list.py:202\u001b[0m, in \u001b[0;36mCallbackList._on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    200\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m--> 202\u001b[0m     \u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/keras/src/callbacks/tensorboard.py:456\u001b[0m, in \u001b[0;36mTensorBoard.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(logs, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m logs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 456\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscalar\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch_\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_step\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_trace:\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/tensorflow/python/summary/tb_summary.py:303\u001b[0m, in \u001b[0;36mscalar\u001b[0;34m(name, data, step, description)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    302\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m TBNotInstalledError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.summary.scalar\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[0;32m--> 303\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mscalar_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdescription\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/tensorboard/plugins/scalar/summary_v2.py:88\u001b[0m, in \u001b[0;36mscalar\u001b[0;34m(name, data, step, description)\u001b[0m\n\u001b[1;32m     83\u001b[0m summary_scope \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28mgetattr\u001b[39m(tf\u001b[38;5;241m.\u001b[39msummary\u001b[38;5;241m.\u001b[39mexperimental, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary_scope\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m tf\u001b[38;5;241m.\u001b[39msummary\u001b[38;5;241m.\u001b[39msummary_scope\n\u001b[1;32m     86\u001b[0m )\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m summary_scope(name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscalar_summary\u001b[39m\u001b[38;5;124m\"\u001b[39m, values\u001b[38;5;241m=\u001b[39m[data, step]) \u001b[38;5;28;01mas\u001b[39;00m (tag, _):\n\u001b[0;32m---> 88\u001b[0m     \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdebugging\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_scalar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39msummary\u001b[38;5;241m.\u001b[39mwrite(\n\u001b[1;32m     90\u001b[0m         tag\u001b[38;5;241m=\u001b[39mtag,\n\u001b[1;32m     91\u001b[0m         tensor\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mcast(data, tf\u001b[38;5;241m.\u001b[39mfloat32),\n\u001b[1;32m     92\u001b[0m         step\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m     93\u001b[0m         metadata\u001b[38;5;241m=\u001b[39msummary_metadata,\n\u001b[1;32m     94\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/tensorflow/python/util/dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1262\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/tensorflow/python/ops/check_ops.py:2181\u001b[0m, in \u001b[0;36massert_scalar_v2\u001b[0;34m(tensor, message, name)\u001b[0m\n\u001b[1;32m   2161\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdebugging.assert_scalar\u001b[39m\u001b[38;5;124m'\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m   2162\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39madd_dispatch_support\n\u001b[1;32m   2163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21massert_scalar_v2\u001b[39m(tensor, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   2164\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Asserts that the given `tensor` is a scalar.\u001b[39;00m\n\u001b[1;32m   2165\u001b[0m \n\u001b[1;32m   2166\u001b[0m \u001b[38;5;124;03m  This function raises `ValueError` unless it can be certain that the given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2179\u001b[0m \u001b[38;5;124;03m      unknown.\u001b[39;00m\n\u001b[1;32m   2180\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2181\u001b[0m   \u001b[43massert_scalar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/tensorflow/python/util/dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1262\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/tensorflow/python/ops/check_ops.py:2207\u001b[0m, in \u001b[0;36massert_scalar\u001b[0;34m(tensor, name, message)\u001b[0m\n\u001b[1;32m   2188\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Asserts that the given `tensor` is a scalar (i.e. zero-dimensional).\u001b[39;00m\n\u001b[1;32m   2189\u001b[0m \n\u001b[1;32m   2190\u001b[0m \u001b[38;5;124;03mThis function raises `ValueError` unless it can be certain that the given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2204\u001b[0m \u001b[38;5;124;03m    unknown.\u001b[39;00m\n\u001b[1;32m   2205\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2206\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(name, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124massert_scalar\u001b[39m\u001b[38;5;124m'\u001b[39m, [tensor]) \u001b[38;5;28;01mas\u001b[39;00m name_scope:\n\u001b[0;32m-> 2207\u001b[0m   tensor \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname_scope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2208\u001b[0m   shape \u001b[38;5;241m=\u001b[39m tensor\u001b[38;5;241m.\u001b[39mget_shape()\n\u001b[1;32m   2209\u001b[0m   message \u001b[38;5;241m=\u001b[39m _message_prefix(message)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/tensorflow/python/framework/ops.py:732\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;66;03m# TODO(b/142518781): Fix all call-sites and remove redundant arg\u001b[39;00m\n\u001b[1;32m    731\u001b[0m preferred_dtype \u001b[38;5;241m=\u001b[39m preferred_dtype \u001b[38;5;129;01mor\u001b[39;00m dtype_hint\n\u001b[0;32m--> 732\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor_conversion_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreferred_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccepted_result_types\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:234\u001b[0m, in \u001b[0;36mconvert\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[1;32m    225\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    226\u001b[0m           _add_error_prefix(\n\u001b[1;32m    227\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversion_func\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    231\u001b[0m               name\u001b[38;5;241m=\u001b[39mname))\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 234\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m    237\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/tensorflow/python/framework/constant_tensor_conversion.py:29\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m constant_op  \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[1;32m     28\u001b[0m _ \u001b[38;5;241m=\u001b[39m as_ref\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/tensorflow/python/ops/weak_tensor_ops.py:142\u001b[0m, in \u001b[0;36mweak_tensor_binary_op_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    141\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    144\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/tensorflow/python/framework/constant_op.py:276\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(\n\u001b[1;32m    179\u001b[0m     value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    180\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[ops\u001b[38;5;241m.\u001b[39mOperation, ops\u001b[38;5;241m.\u001b[39m_EagerTensorBase]:\n\u001b[1;32m    181\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 276\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/tensorflow/python/framework/constant_op.py:289\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    288\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 289\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    291\u001b[0m const_tensor \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39m_create_graph_constant(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    292\u001b[0m     value, dtype, shape, name, verify_shape, allow_broadcast\n\u001b[1;32m    293\u001b[0m )\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m const_tensor\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/tensorflow/python/framework/constant_op.py:301\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_eager_impl\u001b[39m(\n\u001b[1;32m    298\u001b[0m     ctx, value, dtype, shape, verify_shape\n\u001b[1;32m    299\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ops\u001b[38;5;241m.\u001b[39m_EagerTensorBase:\n\u001b[1;32m    300\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 301\u001b[0m   t \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/tensorflow/python/framework/constant_op.py:108\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    106\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    107\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hyperband_tuner.search(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=10,\n",
    "    validation_data=(x_valid, y_valid),\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=2),\n",
    "        TensorBoard(Path(hyperband_tuner.project_dir) / \"tensorboard\"),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0054 summary\n",
      "Hyperparameters:\n",
      "n_hidden: 7\n",
      "n_neurons: 159\n",
      "learning_rate: 0.001989751755243559\n",
      "optimizer: adam\n",
      "tuner/epochs: 10\n",
      "tuner/initial_epoch: 4\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0052\n",
      "Score: 0.9757999777793884\n"
     ]
    }
   ],
   "source": [
    "best_trial = hyperband_tuner.oracle.get_best_trials(num_trials=1)[0]\n",
    "best_trial.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9811 - loss: 0.0855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f5d5660b350>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = hyperband_tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "best_model.fit(x_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9687 - loss: 0.1282\n",
      "test loss, test acc: [0.11546468734741211, 0.9714999794960022]\n"
     ]
    }
   ],
   "source": [
    "results = best_model.evaluate(x_test, y_test)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 Complete [00h 00m 42s]\n",
      "val_accuracy: 0.9679999947547913\n",
      "\n",
      "Best val_accuracy So Far: 0.9782000184059143\n",
      "Total elapsed time: 01h 36m 07s\n"
     ]
    }
   ],
   "source": [
    "bayesian_opt_tuner = BayesianOptimization(\n",
    "    MyClassificationHyperModel(),\n",
    "    objective=\"val_accuracy\",\n",
    "    seed=42,\n",
    "    max_trials=20,\n",
    "    alpha=1e-4,\n",
    "    beta=2.6,\n",
    "    overwrite=True,\n",
    "    directory=\"my_mnist\",\n",
    "    project_name=\"bayesian_opt\",\n",
    ")\n",
    "bayesian_opt_tuner.search(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(x_valid, y_valid),\n",
    "    callbacks=[EarlyStopping(patience=2), TensorBoard(Path(bayesian_opt_tuner.project_dir) / \"tensorboard\")],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 07 summary\n",
      "Hyperparameters:\n",
      "n_hidden: 3\n",
      "n_neurons: 319\n",
      "learning_rate: 0.005389284745949777\n",
      "optimizer: sgd\n",
      "normalize: True\n",
      "batch_size: 32\n",
      "Score: 0.9782000184059143\n"
     ]
    }
   ],
   "source": [
    "best_trial = bayesian_opt_tuner.oracle.get_best_trials(num_trials=1)[0]\n",
    "best_trial.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trial 02 summary\n",
    "Hyperparameters:\n",
    "n_hidden: 8\n",
    "n_neurons: 365\n",
    "learning_rate: 0.006718710759425462\n",
    "optimizer: sgd\n",
    "normalize: True\n",
    "batch_size: 16\n",
    "Score: 0.972599983215332"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9942 - loss: 0.0247\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9952 - loss: 0.0221\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9959 - loss: 0.0199\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9964 - loss: 0.0182\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9967 - loss: 0.0167\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9972 - loss: 0.0155\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9976 - loss: 0.0143\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9979 - loss: 0.0133\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9982 - loss: 0.0124\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9985 - loss: 0.0116\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f24bc274b90>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = bayesian_opt_tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "best_model.fit(x_train_full, y_train_full, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9744 - loss: 0.0882\n",
      "test loss, test acc: [0.07178439199924469, 0.979200005531311]\n"
     ]
    }
   ],
   "source": [
    "results = best_model.evaluate(x_test, y_test)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "313/313 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 3ms/step - accuracy: 0.9744 - loss: 0.0878\n",
    "test loss, test acc: [0.07178439199924469, 0.979200005531311]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Launching TensorBoard..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
