{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. MNIST with MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-07 09:31:18.426691: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1738917078.445490   13573 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1738917078.451833   13573 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import keras_tuner as kt\n",
    "from keras_tuner import HyperParameters, RandomSearch, HyperModel, BayesianOptimization\n",
    "\n",
    "from keras.api.datasets import mnist\n",
    "from keras import Sequential\n",
    "from keras.api.layers import Input, Dense, Flatten, Normalization\n",
    "from keras.api.optimizers import Adam, SGD\n",
    "from keras.api.callbacks import EarlyStopping, Callback, TensorBoard, ModelCheckpoint\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from time import strftime\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Exercise: Train a deep MLP on the MNIST dataset (you can load it using `tf.keras.datasets.mnist.load_data()`. See if you can get over 98% accuracy by manually tuning the hyperparameters. Try searching for the optimal learning rate by using the approach presented in this chapter (i.e., by growing the learning rate exponentially, plotting the loss, and finding the point where the loss shoots up). Next, try tuning the hyperparameters using Keras Tuner with all the bells and whistles—save checkpoints, use early stopping, and plot learning curves using TensorBoard.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit's MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "    x_train, y_train, test_size=10_000, random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert x_train.shape == (50000, 28, 28)\n",
    "assert x_valid.shape == (10000, 28, 28)\n",
    "assert x_test.shape == (10000, 28, 28)\n",
    "assert y_train.shape == (50000,)\n",
    "assert y_valid.shape == (10000,)\n",
    "assert y_test.shape == (10000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.reshape(x_train, (x_train.shape[0], -1))\n",
    "x_valid = np.reshape(x_valid, (x_valid.shape[0], -1))\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape\n",
    "x_valid.shape\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(random_state=RANDOM_STATE, max_iter=300).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9586"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale data (0-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255.0\n",
    "x_valid = x_valid / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:697: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9638"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(random_state=RANDOM_STATE, max_iter=300).fit(x_train, y_train)\n",
    "y_pred_test = clf.predict(x_test)\n",
    "accuracy_score(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=MLPClassifier(max_iter=300, random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;activation&#x27;: [&#x27;tanh&#x27;, &#x27;relu&#x27;],\n",
       "                         &#x27;alpha&#x27;: [0.0001, 0.001, 0.05, 0.1],\n",
       "                         &#x27;hidden_layer_sizes&#x27;: [(50, 50, 50), (50, 100, 50),\n",
       "                                                (100,), (100, 50)],\n",
       "                         &#x27;learning_rate&#x27;: [&#x27;constant&#x27;, &#x27;adaptive&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;sgd&#x27;, &#x27;adam&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=3, estimator=MLPClassifier(max_iter=300, random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;activation&#x27;: [&#x27;tanh&#x27;, &#x27;relu&#x27;],\n",
       "                         &#x27;alpha&#x27;: [0.0001, 0.001, 0.05, 0.1],\n",
       "                         &#x27;hidden_layer_sizes&#x27;: [(50, 50, 50), (50, 100, 50),\n",
       "                                                (100,), (100, 50)],\n",
       "                         &#x27;learning_rate&#x27;: [&#x27;constant&#x27;, &#x27;adaptive&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;sgd&#x27;, &#x27;adam&#x27;]})</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: MLPClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>MLPClassifier(alpha=0.05, max_iter=300, random_state=42)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;MLPClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.neural_network.MLPClassifier.html\">?<span>Documentation for MLPClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>MLPClassifier(alpha=0.05, max_iter=300, random_state=42)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=MLPClassifier(max_iter=300, random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'activation': ['tanh', 'relu'],\n",
       "                         'alpha': [0.0001, 0.001, 0.05, 0.1],\n",
       "                         'hidden_layer_sizes': [(50, 50, 50), (50, 100, 50),\n",
       "                                                (100,), (100, 50)],\n",
       "                         'learning_rate': ['constant', 'adaptive'],\n",
       "                         'solver': ['sgd', 'adam']})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter_space = {\n",
    "    \"hidden_layer_sizes\": [(50, 50, 50), (50, 100, 50), (100,), (100, 50)],\n",
    "    \"activation\": [\"tanh\", \"relu\"],\n",
    "    \"solver\": [\"sgd\", \"adam\"],\n",
    "    \"alpha\": [0.0001, 0.001, 0.05, 0.10],\n",
    "    \"learning_rate\": [\"constant\", \"adaptive\"],\n",
    "}\n",
    "\n",
    "mlp = MLPClassifier(random_state=RANDOM_STATE, max_iter=300)\n",
    "\n",
    "clf = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=3)\n",
    "clf.fit(x_train[:15000], y_train[:15000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:\n",
      " {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters found:\\n\", clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.942 (+/-0.008) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.945 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.942 (+/-0.008) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.945 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.941 (+/-0.004) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.947 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.941 (+/-0.004) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.947 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.927 (+/-0.011) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.950 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.927 (+/-0.011) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.950 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.936 (+/-0.006) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.952 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.936 (+/-0.006) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.952 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.942 (+/-0.008) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.945 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.942 (+/-0.008) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.945 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.941 (+/-0.004) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.948 (+/-0.006) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.941 (+/-0.004) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.948 (+/-0.006) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.927 (+/-0.011) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.951 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.927 (+/-0.011) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.951 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.936 (+/-0.006) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.951 (+/-0.006) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.936 (+/-0.006) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.951 (+/-0.006) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.942 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.952 (+/-0.004) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.942 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.952 (+/-0.004) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.941 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.955 (+/-0.006) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.941 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.955 (+/-0.006) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.927 (+/-0.011) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.958 (+/-0.004) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.927 (+/-0.011) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.958 (+/-0.004) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.936 (+/-0.006) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.953 (+/-0.011) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.936 (+/-0.006) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.953 (+/-0.011) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.942 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.1, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.953 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.1, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.942 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.1, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.953 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.1, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.941 (+/-0.004) for {'activation': 'tanh', 'alpha': 0.1, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.953 (+/-0.012) for {'activation': 'tanh', 'alpha': 0.1, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.941 (+/-0.004) for {'activation': 'tanh', 'alpha': 0.1, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.953 (+/-0.012) for {'activation': 'tanh', 'alpha': 0.1, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.926 (+/-0.010) for {'activation': 'tanh', 'alpha': 0.1, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.958 (+/-0.002) for {'activation': 'tanh', 'alpha': 0.1, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.926 (+/-0.010) for {'activation': 'tanh', 'alpha': 0.1, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.958 (+/-0.002) for {'activation': 'tanh', 'alpha': 0.1, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.936 (+/-0.006) for {'activation': 'tanh', 'alpha': 0.1, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.960 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.1, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.936 (+/-0.006) for {'activation': 'tanh', 'alpha': 0.1, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.960 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.1, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.937 (+/-0.004) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.948 (+/-0.008) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.937 (+/-0.004) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.948 (+/-0.008) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.942 (+/-0.004) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.949 (+/-0.004) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.942 (+/-0.004) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.949 (+/-0.004) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.931 (+/-0.011) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.951 (+/-0.007) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.931 (+/-0.011) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.951 (+/-0.007) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.942 (+/-0.007) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.954 (+/-0.002) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.942 (+/-0.007) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.954 (+/-0.002) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.937 (+/-0.005) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.947 (+/-0.008) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.937 (+/-0.005) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.947 (+/-0.008) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.942 (+/-0.004) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.948 (+/-0.003) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.942 (+/-0.004) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.948 (+/-0.003) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.931 (+/-0.011) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.950 (+/-0.007) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.931 (+/-0.011) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.950 (+/-0.007) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.942 (+/-0.007) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.953 (+/-0.002) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.942 (+/-0.007) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.953 (+/-0.002) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.938 (+/-0.004) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.948 (+/-0.002) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.938 (+/-0.004) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.948 (+/-0.002) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.943 (+/-0.003) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.955 (+/-0.001) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.943 (+/-0.003) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.955 (+/-0.001) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.931 (+/-0.011) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.961 (+/-0.005) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.931 (+/-0.011) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.961 (+/-0.005) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.942 (+/-0.007) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.960 (+/-0.002) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.942 (+/-0.007) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.960 (+/-0.002) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.938 (+/-0.005) for {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.952 (+/-0.001) for {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.938 (+/-0.005) for {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.952 (+/-0.001) for {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.943 (+/-0.002) for {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.958 (+/-0.001) for {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.943 (+/-0.002) for {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.958 (+/-0.001) for {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.931 (+/-0.011) for {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.961 (+/-0.004) for {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.931 (+/-0.011) for {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.961 (+/-0.004) for {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.942 (+/-0.007) for {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.959 (+/-0.008) for {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.942 (+/-0.007) for {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.959 (+/-0.008) for {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "means = clf.cv_results_[\"mean_test_score\"]\n",
    "stds = clf.cv_results_[\"std_test_score\"]\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_[\"params\"]):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results on the test set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       984\n",
      "           1       0.98      0.99      0.98      1093\n",
      "           2       0.97      0.96      0.97       994\n",
      "           3       0.97      0.96      0.96      1000\n",
      "           4       0.96      0.98      0.97       980\n",
      "           5       0.96      0.96      0.96       919\n",
      "           6       0.97      0.98      0.98       981\n",
      "           7       0.97      0.98      0.98      1060\n",
      "           8       0.97      0.93      0.95       979\n",
      "           9       0.95      0.96      0.96      1010\n",
      "\n",
      "    accuracy                           0.97     10000\n",
      "   macro avg       0.97      0.97      0.97     10000\n",
      "weighted avg       0.97      0.97      0.97     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true, y_pred = y_valid, clf.predict(x_valid)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"Results on the test set:\")\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9669"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test = clf.predict(x_test)\n",
    "accuracy_score(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9808"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_mlp = MLPClassifier(**clf.best_params_)\n",
    "best_mlp.fit(x_train, y_train)\n",
    "y_pred_test = best_mlp.predict(x_test)\n",
    "accuracy_score(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow / Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "np.random.seed(RANDOM_STATE)\n",
    "tf.random.set_seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_full, y_train_full), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "    x_train_full, y_train_full, test_size=10_000, random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize so we work with range of 0 to 1 and convert to float\n",
    "x_train_full, x_train, x_valid, x_test = map(\n",
    "    lambda x: x / 255.0, (x_train_full, x_train, x_valid, x_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract input shape of input data (shape of each instance)\n",
    "input_shape = np.shape(x_train_full)[1:]\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1738915161.468226    1003 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2874 MB memory:  -> device: 0, name: Quadro P600, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">235,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">90,300</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">90,300</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">90,300</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │       \u001b[38;5;34m235,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │        \u001b[38;5;34m90,300\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │        \u001b[38;5;34m90,300\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │        \u001b[38;5;34m90,300\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m3,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">509,410</span> (1.94 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m509,410\u001b[0m (1.94 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">509,410</span> (1.94 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m509,410\u001b[0m (1.94 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=input_shape))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(300, activation=\"relu\"))\n",
    "model.add(Dense(300, activation=\"relu\"))\n",
    "model.add(Dense(300, activation=\"relu\"))\n",
    "model.add(Dense(300, activation=\"relu\"))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExponentialLearningRate(Callback):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        self.rates = []\n",
    "        self.losses = []\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        lr = self.model.optimizer.learning_rate.numpy() * self.factor\n",
    "        self.model.optimizer.learning_rate = lr\n",
    "        self.rates.append(lr)\n",
    "        self.losses.append(logs[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1738915174.373794    2274 service.cc:148] XLA service 0x7feadc007930 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1738915174.374322    2274 service.cc:156]   StreamExecutor device (0): Quadro P600, Compute Capability 6.1\n",
      "2025-02-07 08:59:34.433945: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1738915174.621628    2274 cuda_dnn.cc:529] Loaded cuDNN version 90700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  36/1563\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.4489 - loss: 1.7006"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1738915176.142125    2274 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - accuracy: 0.6351 - loss: 1.1486 - val_accuracy: 0.0984 - val_loss: 2.5051\n"
     ]
    }
   ],
   "source": [
    "expon_lr = ExponentialLearningRate(factor=1.005)\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=1,\n",
    "    validation_data=(x_valid, y_valid),\n",
    "    callbacks=[expon_lr],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAG1CAYAAAAFuNXgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABH4UlEQVR4nO3dd3zU9f0H8Nf3LpdLLnvvxQxJgEDYMqWEociyUuusk4J1pP60qNW6SlutpdYKoiggtQVBlFYEorL3CjOEFbL3uiSX3Pz+/khyGBIg45Lv5Xuv5+PB4+F973t374OP4cVnCqIoiiAiIiKSCYXUBRARERHZEsMNERERyQrDDREREckKww0RERHJCsMNERERyQrDDREREckKww0RERHJCsMNERERyYqT1AV0N4vFgvz8fHh4eEAQBKnLISIiojYQRRHV1dUIDQ2FQnHzvhmHCzf5+fmIiIiQugwiIiLqgJycHISHh9/0HocLNx4eHgCAX3+0HX/6xUiJq6GezGg0Yvv27UhOToZKpZK6HOqh2I7IVuTelrRaLSIiIqx/j9+Mw4WbpqGoWlEFT09PiauhnsxoNEKj0cDT01OWP0ioe7Adka04Sltqy5QSh51QXFlrlLoEIiIi6gIOG24qdAapSyAiIqIu4LDhpryW4YaIiEiOHDbcaOtNMJktUpdBRERENuaw4QYAKus474aIiEhuHDrc6PRmqUsgIiIiG3PocFNrMEldAhEREdmYY4cbPcMNERGR3Dh2uDFwWIqIiEhuHDvcsOeGiIhIdhw63NQw3BAREcmOQ4ebCm7kR0REJDsOHW6KtHqpSyAiIiIbc+xwU10vdQlERERkYw4dboq1DDdERERy49DhhsNSRERE8uPg4aYeoihKXQYRERHZkEOHG73JAh038iMiIpIVhw43ABhuiIiIZMZhw42rc8NX1/HwTCIiIllx2HCjUSkBsOeGiIhIbhw23Lg4N4Ub9twQERHJicOGGzdnJwDsuSEiIpIbhw03LhyWIiIikiWHDTfXem44LEVERCQnDhtuXKyrpdhzQ0REJCcOG25cG4el6hhuiIiIZMVhw42mcViqVs9wQ0REJCcOG25cm5aCGznnhoiISE4cNty4cViKiIhIlhw23DRt4sdhKSIiInlx2HCjaQw3dRyWIiIikhWHDTcuHJYiIiKSJYcNN9al4EaGGyIiIjlx2HBj7bkxWiSuhIiIiGzJYcNNU89NPYeliIiIZMVhw41a1fDVOSxFREQkLw4bbjjnhoiISJ4cNtw07XPDYSkiIiJ5cdhw4+rEnhsiIiI5cthw09RzY7KIMJq5YoqIiEguHDbcNM25Adh7Q0REJCcOG25USgFKhQCA826IiIjkxGHDjSAIXDFFREQkQw4bboCf7lLMcENERCQXkoabJUuWYPjw4fDw8EBgYCBmz56NjIyMW75u165dSEpKgouLC3r16oXly5d36PNdnRs38uOwFBERkWxIGm527dqFRYsW4eDBg0hNTYXJZEJycjJqa2tv+JrMzEzMmDED48aNw4kTJ/DSSy/h6aefxsaNG9v9+RyWIiIikh8nKT9869atzR5/9tlnCAwMxLFjxzB+/PhWX7N8+XJERkZi6dKlAIABAwbg6NGjePfddzFv3rx2fb71fCmGGyIiItmQNNxcr6qqCgDg6+t7w3sOHDiA5OTkZtemTp2KlStXwmg0QqVSNXtOr9dDr9dbH2u1WgCA0WiE2qmh46qmzgCj0WiT70COo6nNsO1QZ7Adka3IvS2153vZTbgRRREpKSkYO3YsEhISbnhfYWEhgoKCml0LCgqCyWRCaWkpQkJCmj23ZMkSvP766y3eZ/v27aiudAegwKGjJyBmizb5HuR4UlNTpS6BZIDtiGxFrm1Jp9O1+V67CTdPPfUUTp06hb17997yXkEQmj0WRbHV6wCwePFipKSkWB9rtVpEREQgOTkZO7+9gvTKYvSNS8CMERGd/AbkaIxGI1JTUzFlypQWPYZEbcV2RLYi97bUNPLSFnYRbn7zm99g8+bN2L17N8LDw296b3BwMAoLC5tdKy4uhpOTE/z8/Frcr1aroVarW1xXqVRwUzf84RvNkGVDoO6hUqnYfqjT2I7IVuTaltrznSRdLSWKIp566il89dVX+PHHHxETE3PL14wePbpFl9v27dsxbNiwdv9hNp0vxdVSRERE8iFpuFm0aBHWrl2LL774Ah4eHigsLERhYSHq6uqs9yxevBgPPvig9fGCBQuQlZWFlJQUpKen49NPP8XKlSvx/PPPt/vzuRSciIhIfiQNN8uWLUNVVRUmTpyIkJAQ669169ZZ7ykoKEB2drb1cUxMDLZs2YKdO3ciMTERb775Jt5///12LwMHfhJuuIkfERGRbEg656ZpIvDNrFq1qsW1CRMm4Pjx453+fFdnhhsiIiK5ceizpTSN4abWYJK4EiIiIrIVhw43buqGjqtaPcMNERGRXDh2uHFuDDccliIiIpINxw436sZhKfbcEBERyYZDhxt3DksRERHJjkOHG03jsFSNnsNSREREcuHQ4aap50bH1VJERESy4dDhpmnOjc5ghsXCU8GJiIjkwMHDzbU9DLnXDRERkTw4dLhROymgVAgAGnpviIiIqOdz6HAjCALcGncpruGKKSIiIllw6HADcJdiIiIiuWG4UTctB2e4ISIikgOHDzcangxOREQkKw4fblxV15aDExERUc/n8OHG2nNjZLghIiKSA4cPN64cliIiIpIVhhtV0xEMDDdERERy4PDh5tqEYq6WIiIikgOGG2dOKCYiIpIThw83TXNudJxQTEREJAsOH264zw0REZG8OHy4cXVumlDMOTdERERy4CR1AVLTcBM/IiIiu1RvNOPo1QocuFKKvWdz2vw6hpvGYal6zrkhIiKSlCiKyCiqxr5LZdh9oQSHMstQb7QAACx6XZvfx+HDjStXSxEREUlGZzDhRHYlDmWWY9uZQmQUVTd7PtBDjbF9/TEowBm/Wtq293T4cKNpnHPDCcVERERdr85gRlpOJQ5nlmPf5VKcyK6A0Sxan3d2UmB0Lz/c1scPE/oFol+QOwRBgFarxa/a+BkOH254cCYREVHX0dYbcSSzHIcyy3E4sxxn8qpgsojN7gnxcsGIGF+M6e2HaQkh8HJVdeozGW6sw1JcLUVERNRZFbUGHLl6Lcycza/CdVkGwZ4uGBbtgzG9/XFbHz9E+mogCILNanD4cMNTwYmIiDquWFuPw1cbgsyhK+Ut5swAQLSfBqN6+WFEjC+GR/si3MfVpmHmegw3jeHGaBZhNFugUjr81j9EREQ3VKStx8ErZTh4pRyHrpThSmlti3t6B7hhZC8/jIzxxYgYX4R4uXZrjQ4fbpqGpYCGeTdergw3RERETW4VZgQBiAvxxPBoX4yM8cXwGF/4u6slqraBw4cbZ6UCSoUAs0VEncHc6UlMREREPVmlzoD9l8uw91IpDl5uPczEh3piVIwfRvXyw/AYX7v7u9Phw40gCNColKjWmzjvhoiIHI7eZMbxrErsuViCvZdKcTqvCuJPJgD3hDBzPYcPN0DD0FS13sQVU0REJHuiKOJScQ32XCzFnoslOHilvMU/7vsGumNsX3+M6e2PET0gzFyP4QY8GZyIiOStrEaPvZdKsfdiKfZcLEWhtr7Z8/7uzhjbxx9j+wZgbB9/BHu5SFSpbTDc4KcngzPcEBFRz1dnMONgZhn2XSzFvstlSC/QNnve2UmBkTG+GNfXH2P7BCA22AMKRdctze5uDDcAXFUNK6QYboiIqCcSRRFZZTrsLRTw9drj2H+5HHqTpdk9scEeGN8vAOP6+mN4tC9cVMobvFvPx3CDn5wvZeScGyIi6hlyynU4cKUMBy+X4cCVMhRU1QNQAigFAIR5u2JcX3+M6eOPMb39JF+e3Z0YbsCTwYmIyP41LdHec7EU+y6VIrtc1+x5lVJAhMaC2SP7IjkhBP2DPLp0F2B7xnADTigmIiL707REe++lEuy92LBE+6dnNDkpBAwK98Lo3g1LtAeFumPn99sxY0IvqFQ9a3WTrTHcgOGGiIikJ4oiLhTVWPebOXSTJdrj+vpjRIwf3NXX/ho3Go3dXbLdYrgB4KpqXC3FTfyIiKgbFWvrrcNMey+Vorha3+x5f3c1xvbxk80S7e7CcAP23BARUffQGUw4dKUcey6WYu+lElwoqmn2vItKgRExfhjXxx9j+/ojNthx5810BsMNfjqhmKuliIjItnLKdUg9V4Tv04tw5Go5jOZrE2cEARgY5tW4gZ4/kqJ8oHaS7xLt7sJwg2s9N1wtRUREnWW2iDiZW4kd54uReq4I5wurmz0f7uNq3TxvTG8/+Lg5S1SpfDHcgMNSRETUOcXaeuy6UIJdF0qw52IpququTe5VKgQMj/bBzwYEYfKAIET7aTjU1MUYbgDrLo3suSEiorYwmS04nl2JnRnF2JlRgnPXHW/g4eKEcX398bMBQZjUP5C9M92M4QbXdijmaikiIrqRYm09dl4owa6MEuy5WAJtffN5moPCvTChXwAm9AtAYoQ3nJQKiSolhhv8dFiKE4qJiKiBxSIiLbcSP6QXYcf5lr0z3hoVxvcNwMT+ARjfL8Chjjewdww3ALxcG3Zy/OkYKREROZ46gxn7LpXi+/QifJ9ejNKa5vvODAr3wsR+AZjQPxCJEd5QyugkbTlhuAHg2zgWWl5rgCiKnOhFRORA8ivrsDOjBD+eL8beSyWoN147TdtD7YTx/QMwOTaQvTM9CMMNroUbo1lEtd4ETxfHPpODiEjOmiYD78goxo7zxS2Waod5u+JnAwIxJS4YI2J84ezEuTM9DcMNGlZLaZyV0BnMKK8xMNwQEclMvdGM3RdKsPVMIX44X9xsGoJCAIZE+mBS/wBMig1EXIgne/B7OIabRt6uKugMZmjrOe+GiEgOavQm7DhfjK1nCrEjo7jZdh/eGhUm9msIM+P7BnCptsww3DTydFUhv6oe2jqumCIi6qkqag34Pr0I284WYvfFUhhM1+bPhHm7Ymp8MKYlBCMpyoeTgWWM4aaRh0vDbwV7boiIepbi6npsO1uEbWcKceBKGcyWa2c3xfi7YVpCMKYnBGNgmBeHmxwEw02jpnk2Wi4HJyKye7kVOmw9U4itZwpxLLsC4rU8g9hgD0xPCMG0hGD0C3JnoHFADDeNPBv3umHPDRGRfbpcUmMNNKfzqpo9lxjhjWkJwZgWH4xofzeJKiR7wXDTyLNxWKq6nnNuiIjsgSiKSC+oxtYzBdh6thAXimqszykEYHi0L6YnBCM5Phih3q4SVkr2huGmkbXnhsNSRESSEUURaTmVDT00ZwuRVaazPqdSChjT2x/TEoIxJS6IG+rRDTHcNLo2oZg9N0RE3e18oRbfpOVjc1o+8irrrNfVTgpM6BeA6QODcXtskPW4HKKbYbhpxAnFRETdK6dch80n8/FNWl6zISc3ZyUmDwjCtIRgTOwfAI0z/6qi9mGLacQJxUREXa+kWo9vT+Xjm5P5OJFdab3urFRgUmwAZiWG4fbYQLiolNIVST0ew02jaz03HJYiIrIlbb0RW88U4r8n87HvUimatqFRCMCY3v64KzEUU+ODOeRENsNw08jTtWm1FHtuiIg6q95oxo/ni7E5LR8/ZhQ32yk4McIbsxJDccegEAR6uEhYJckVw00ja88NJxQTEXWIxSLi4JUybDyeh21nC1Gjv/bztE+gO2YNDsVdiaGI8uM+NNS1GG4aNa2WqtGbYDJb4KTkEfdERG2RU67DhmO52Hg8F7kV11Y6hXm74s7BIZg1OAwDQjy4UzB1G0nDze7du/HOO+/g2LFjKCgowKZNmzB79uwb3r9z505MmjSpxfX09HTExsZ2qhYPl2tjvTV6E7w1PCGWiOhGdAYTvjtdiC+P5eDglXLrdQ+1E+4cHIq5Q8OQFOkDBQ+nJAlIGm5qa2sxePBg/OpXv8K8efPa/LqMjAx4enpaHwcEBHS6FmcnBVxVStQZzdDWMdwQEV1PFEUczarAhqO5+PZ0gXXYSRCA23r74+fDwjE1PpgrnUhykoab6dOnY/r06e1+XWBgILy9vW1ej6erU0O44aRiIiKrgqo6fHU8DxuO5SKztNZ6PdJXg7uTwjEvKRxhPP6A7EiPnHMzZMgQ1NfXIy4uDq+88kqrQ1VN9Ho99Hq99bFWqwUAGI1GGI3NQ4yH2glF0KOiph5Go6ZriifZaGo/17cjovaw13ZkMluw80Ip/n0kB3sulVlP3dY4KzEtPgjzhoZieJSPdR6NvdXviOy1LdlKe75Xjwo3ISEhWLFiBZKSkqDX6/H5559j8uTJ2LlzJ8aPH9/qa5YsWYLXX3+9xfXt27dDo2keYEx1SgACduw7hPLzYld8BZKh1NRUqUsgGbCXdqQ1AAeLBewrUqDScG2+TG8PESMDLUj0M0GtzEbpuWx8d07CQumG7KUt2ZpOp7v1TY0EURTt4m9xQRBuOaG4NTNnzoQgCNi8eXOrz7fWcxMREYHS0tJm83YA4LE1x7HrYimWzInH3UPD2v0dyLEYjUakpqZiypQpUKm4+Rh1jD20o4a5NJX41+EcbD9XBKO54a8FH40Kdw8Nw/xh4YjyY2+2vbOHttSVtFot/P39UVVV1eLv7+v1qJ6b1owaNQpr16694fNqtRpqdcuTY1UqVYs/fK/GScS1BossGwZ1jdbaElF7SdGOquuN+PpEHtYezEZGUbX1+tBIb9w/KgozBoZwcnAPJNefSe35Tj0+3Jw4cQIhISE2ea+mXYq5kR8Rydn5Qi3WHszCpuN5qDWYAQCuKiVmDwnFfSOjkBDmJXGFRJ0jabipqanBpUuXrI8zMzORlpYGX19fREZGYvHixcjLy8OaNWsAAEuXLkV0dDTi4+NhMBiwdu1abNy4ERs3brRJPTwZnIjkymCy4LszBVh7MAtHrlZYr/cKcMMDo6Iwd2g4z3Yi2ZA03Bw9erTZSqeUlBQAwEMPPYRVq1ahoKAA2dnZ1ucNBgOef/555OXlwdXVFfHx8fj2228xY8YMm9TDk8GJSG7yKuvwxaEsrDuSg9IaAwBAqRAwNT4I94+Kwuheftw5mGRH0nAzceJE3Gw+86pVq5o9fuGFF/DCCy90WT1NRzBUc1iKiHowi0XEnkul+PxAFn48X2Q9hTvIU417R0TiF8MjEezFAytJvnr8nBtbauqSrdQZJK6EiKj96o1mbDyei5V7MnHlJ5vt3dbHD/ePjMLP4oKg4rl55AAYbn4i2LPhXzKF2nqJKyEiaruKWgM+P5iF1fuvoqy24R9nHi5OuDspHPeNjEKfQHeJKyTqXgw3P9HUTVtUpYfFIvLANyKya9llOqzcewXrj+aiztiw6inM2xWPjo3B/OERcFPzRzw5Jrb8nwhq7LkxmC2o0Bng595yfxwiIqmdzKnEit1X8N2ZAut8mvhQTzwxvhfuGBgCJw49kYNjuPkJlVIBDxcnVNebUKEzMtwQkd2wWETsvFCMj3ZdwaHMcuv18f0C8OT4XhjTm6ueiJow3FzHR+OM6noTJxUTkV0wmCz4Oi0PH+++govFNQAAJ4WAuxJD8fi4XhgQcvNt6IkcEcPNdXw0KmSXAxU67nVDRNKpN5rxn8PZWLH7CvKrGhY5uKud8MuRkfjVbdEI8XKVuEIi+8Vwcx0ft4bzpcpq9Le4k4jI9mr0Jqw9mIVP9mSitPHnUICHGo+NjcG9IyOtO6kT0Y0x3FwnzLvhX0M5FW0/Wp2IqLPqjWasOpCDZbsuo7xxOXeYtysWTOyNnyeF8wBLonZguLlOlJ8GAJBVxnBDRF3PYLJgb6GAP/5tL4qqG3pqYvzdsGhSH8xKDOWme0QdwHBzneDGceziag5LEVHXMVtEfH0iD3/7/gJyK5QA9AjzdsUzk/ti7tAwLucm6gSGm+v4Nc65qajlaikisj2LRcTWs4V4L/UCLjWufvJUiXg2eQDuGx0NtROHn4g6i+HmOj6ahnBTznBDRDYkiiJ2ZpTg3e0ZOJuvBQB4a1R4fGw0AivTMXtUJFQMNkQ2wXBzHT/3xp4bnYFHMBCRTRy4XIZ3t2fgWFYFgIYl3Y+OjcGj42LgqgS2bEmXuEIieWG4uU5Tz41FBKrqjNal4URE7ZWWU4l3t2Vg76VSAIDaSYGHx0TjyQm94dv4s8Vo5J5aRLbGcHMdZycFPNROqNabUK4zMNwQUbulF2jxXuoFpJ4rAgColAJ+MTwST93ex3qGHRF1HYabVvi6OzeEm1oDegdIXQ0R9RSZpbX4W+oF/PdUPkQRUAjA3KHheGZyX0T4aqQuj8hhMNy0wkfjjKwyHScVE1Gb5FXW4f3vL2LD8VyYG4/pvmNQCJ77WT/0CXSXuDoix8Nw04qm5eAMN0R0MzqDCR/uuIwVe67AYLIAACbHBiIluR/iQ70kro7IcTHctMKH4YaIbkIURXyTlo8/fXcehdqGQy1H9fLF/02NRVKUj8TVERHDTSvYc0NEN3IqtxJ/2HwWx7MrAQARvq545Y44JMcFQRC4dQSRPWC4aYUPdykmousUV9fjna0Z+PJYLgBA46zEokl98OjYGB5qSWRnGG5a0bT/RBnDDZHD05vM+GzfVXzw4yXU6E0AgLlDwvDCtFgEe3FZN5E9Yrhpha/m2i7FROSYRFHED+nFeOvbc7hapgMADI7wxmsz4zA0kvNqiOwZw00rfBuPYCirYbghckS5FTq8+s1Z/Hi+GAAQ4KHGi9NiMXdIGI9kIeoBGG5awZ4bIsdkMlvw2b6reC/1AuqMZqiUAh4b1wuLJvWBu5o/Lol6Cv7f2oqmnhudwYx6o5mTBYkcwMmcSiz+6jTOFTSc2D0i2hd/nJuAPoEeEldGRO3FcNMKD7UTVEoBRrOI8loDQr1dpS6JiLpIjd6Ed7dlYM2Bq7CIgJerCi/NiMXPkyI4BEXUQzHctEIQBPhonFFcrWe4IZKxbWcL8do3Z60b8c1ODMUrd8bB310tcWVE1BkMNzfg63Yt3BCRvBRU1eG1b85ie+Op3VF+Grw1OwHj+vKkXCI5YLi5AV/uUkwkO2aLiDUHruLdbRmoNZjhpBDw5IRe+M3tfTm3jkhGGG5ugOGGSF7O5FXhpU2ncSq3CgCQFOWDP84ZiP7BnDBMJDcMNzfAcEMkDwaTBe//cBHLdl2G2SLCw8UJv5sei3uHR3LCMJFMMdzcQFO4Ka3RS1wJEXXU2fwq/Hb9SZwvrAYA3DEwBK/NjEOgJ49NIJIzhpsbiPZzAwBcKamVuBIiai+j2YJlOy/j/R8uwmQR4evmjLdmJ2DGwBCpSyOibtChcJOTkwNBEBAeHg4AOHz4ML744gvExcXhiSeesGmBUukT6A4AuFhcLXElRNQeF4uqkbL+JE7nNcytmRofhLfnDOTybiIHoujIi375y19ix44dAIDCwkJMmTIFhw8fxksvvYQ33njDpgVKpXeAOwQBqNAZUcahKSK7Z7GIWLk3E3f8Yy9O51XB08UJS+cnYvn9SQw2RA6mQ+HmzJkzGDFiBABg/fr1SEhIwP79+/HFF19g1apVtqxPMq7OSoQ1bt53mUNTRHatsKoeD356GG/+7xwMJgsm9g9AasoEzB4SBkHgpGEiR9OhYSmj0Qi1uuFfQt9//z3uuusuAEBsbCwKCgpsV53EQr1ckVtRh6LG3UuJyP5sOV2AxV+dRlWdES4qBV6+Iw73j4xkqCFyYB0KN/Hx8Vi+fDnuuOMOpKam4s033wQA5Ofnw8/Pz6YFSinAsyHAFVdzWIrI3lTXG/Ha5rP46ngeAGBgmBeW/iIRvQPcJa6MiKTWoXDz5z//GXPmzME777yDhx56CIMHDwYAbN682TpcJQeBHk3hhj03RPbkbH4Vfr32OLLLdVAIwMKJffDMz/pCpezQSDsRyUyHws3EiRNRWloKrVYLHx8f6/UnnngCGo3GZsVJLdCjYS+MYi17bojsxaYTufjdxtPQmywI93HF0vmJGBbtK3VZRGRHOhRu6urqIIqiNdhkZWVh06ZNGDBgAKZOnWrTAqUU5MmeGyJ7YTBZ8Mct6Vi1/yoAYGL/APx9/hB4aVTSFkZEdqdD4WbWrFmYO3cuFixYgMrKSowcORIqlQqlpaV477338Otf/9rWdUqCPTdE9qFYW49FXxzHkasVAICnJ/fFs5P78vgEImpVhwaojx8/jnHjxgEANmzYgKCgIGRlZWHNmjV4//33bVqglIK9GsJNQVU9RFGUuBoix3Qsqxx3/mMvjlytgIfaCZ88OAwpU/ox2BDRDXWo50an08HDo+Ek3e3bt2Pu3LlQKBQYNWoUsrKybFqglMJ9Gva5qdGbUKkzwqfxvCki6nqiKOLzg1l447/nYLKI6Bfkjo8eGIYYfzepSyMiO9ehnps+ffrg66+/Rk5ODrZt24bk5GQAQHFxMTw9PW1aoJRcVEoENK6YyqnQSVwNkeOoN5rx2y9P4tVvzsJkEXHHoBBsWngbgw0RtUmHws2rr76K559/HtHR0RgxYgRGjx4NoKEXZ8iQITYtUGoRjb03OeV1EldC5BhyynWYt2w/vjqeB6VCwMszBuCDe4fATc1zfomobTr00+Luu+/G2LFjUVBQYN3jBgAmT56MOXPm2Kw4exDhq8Hx7Er23BB1g90XSvD0f06gUmeEn5sz/vHLIRjT21/qsoioh+nwP4WCg4MRHByM3NxcCIKAsLAwWW3g1yTCp2HfnpxyhhuirmK2iPhwxyW89/0FiCIwONwLy+5PQmjj+W5ERO3RoWEpi8WCN954A15eXoiKikJkZCS8vb3x5ptvwmKx2LpGSUX4Ng5LVXBYiqgr1OhNeOjTw/hrakOw+cXwCKx7cjSDDRF1WId6bl5++WWsXLkSf/rTn3DbbbdBFEXs27cPf/jDH1BfX4+3337b1nVKJsy7oecmv5LhhqgrvP1tOvZeKoWrSok3ZsXj58MipC6JiHq4DoWb1atX45NPPrGeBg4AgwcPRlhYGBYuXCircNO0Wqqshhv5Edma0WzBuiPZAIC/zR+MaQkhEldERHLQoWGp8vJyxMbGtrgeGxuL8vLyThdlT/zdG/a2qdAZYTLLa8iNSGp1RjMsjftjTooNlLYYIpKNDoWbwYMH44MPPmhx/YMPPsCgQYM6XZQ98dY4o2kj1PJag7TFEMlMncEMAFAqBDjzRG8ispEODUv95S9/wR133IHvv/8eo0ePhiAI2L9/P3JycrBlyxZb1ygppUJAmI8rcsrrcLZAi0BPF6lLIpKNpnDjqlJCEHicAhHZRof+qTRhwgRcuHABc+bMQWVlJcrLyzF37lycPXsWn332ma1rlNzYPgEAgA3HciWuhEhe6owN4cZFpZS4EiKSkw7vcxMaGtpi4vDJkyexevVqfPrpp50uzJ7MSgzFvw9n40RWhdSlEMlKU7hxdeaQFBHZDn+itEH/oIZDQvOr6lGrN0lcDZF8NA1LaVQ8WoGIbIfhpg183JwR4tUw1+ZkTqW0xRDJSFO4cXHmsBQR2Q7DTRslRfkAAE7mVklcCZF8XC2rBQD4uTlLXAkRyUm7+oLnzp170+crKys7U4td6xfkAaAAl4prpC6FSBZ2XyjB33+4CAAYHu0rcTVEJCftCjdeXl63fP7BBx/sVEH2qk+gOwDgUgnDDVFnXSmpwSOrjsBkETE4whv3jYqUuiQikpF2hRs5LvNuq6Zwc7m4BqIock8Ook7YkVECk0XEkEhv/PvxUVwKTkQ2xTk3bRTt5wYnhYAavQl5PESTqMPOF2qxYvdlAMAdA0MYbIjI5hhu2sjZSdE47wY4k8dJxUQdUas34d4VB1Gk1SPM2xXzhoZLXRIRyRDDTTvEBjeEm8sltRJXQtQz5VbUoUJnhLvaCf/9zVj4cJUUEXUBhpt2iPZ3AwBkljLcEHVEraFhE0xvjQq+DDZE1EUYbtqhKdxcZbgh6pCmTfvcnLkjMRF1HUnDze7duzFz5kyEhoZCEAR8/fXXt3zNrl27kJSUBBcXF/Tq1QvLly/v+kIbxfg1hpsyhhuijmg6vkSj5iRiIuo6koab2tpaDB48GB988EGb7s/MzMSMGTMwbtw4nDhxAi+99BKefvppbNy4sYsrbRDtrwEAlNYYUF1v7JbPJJITHXtuiKgbSPoTZvr06Zg+fXqb71++fDkiIyOxdOlSAMCAAQNw9OhRvPvuu5g3b14XVXmNh4sK/u5qlNbocbVUh4HhN9/UkIiaa5pzo+FZUkTUhXrUP58OHDiA5OTkZtemTp2KlStXwmg0QqVStXiNXq+HXq+3PtZqtQAAo9EIo7H9vS8x/hqU1uhxvqASsUGadr+e5KOp/XSkHTmiGr0J/03LAwC4OSv4+9aI7YhsRe5tqT3fq0eFm8LCQgQFBTW7FhQUBJPJhNLSUoSEhLR4zZIlS/D666+3uL59+3ZoNO0PJxq9AoAC/913Cs75ae1+PclPamqq1CXYvSoDsOK8Erm1ApwVIqJMOdiyJUfqsuwK2xHZilzbkk6na/O9PSrcAGhx7IEoiq1eb7J48WKkpKRYH2u1WkRERCA5ORmenp7t/nzTyQLs2nAaWpUPZswY2e7Xk3wYjUakpqZiypQprfYaUoNLxTV47PPjyKuth6+bCivuH4rBHNK1YjsiW5F7W2oaeWmLHhVugoODUVhY2OxacXExnJyc4Ofn1+pr1Go11Gp1i+sqlapDf/hDoxs+J72gGlAooVJyNb2j62hbcgSHM8vx+JqjqKozItpPg9WPjEBU46pDao7tiGxFrm2pPd+pR/3NPHr06Bbdbdu3b8ewYcO67Q8y2k8DTxcn6E0WZBRWd8tnEvVE354qwP0rD6Gqzoghkd7Y+OsxDDZE1C0kDTc1NTVIS0tDWloagIal3mlpacjOzgbQMKT04IMPWu9fsGABsrKykJKSgvT0dHz66adYuXIlnn/++W6rWRAEDAr3BgCcyuUZU0St+WTPFTz17+MwmCxIjgvCF4+Ngp97yx5UIqKuIGm4OXr0KIYMGYIhQ4YAAFJSUjBkyBC8+uqrAICCggJr0AGAmJgYbNmyBTt37kRiYiLefPNNvP/++92yDPynBjXOFziZU9mtn0vUE3y48xLe+jYdogg8ODoKy+5PgiuXfhNRN5J0zs3EiROtE4Jbs2rVqhbXJkyYgOPHj3dhVbfW1HNzMrdS0jqI7M3BK2VY+v1FAMBvp/TDU7f3ueFkfyKirtKj5tzYi8QIbwDAxeIa61k5RI5u88l8PLDyEAwmC0b18mWwISLJMNx0QLCXCwI91DBbRGw/V3jrFxDJnMlsweKNp2A0i5gxMBirfjWCwYaIJMNw00E+GmcAwDP/SZO2ECI7kFWuQ63BDBeVAv+4dyhcVJxjQ0TSYbjpoHlJYdb/rqqT51bXRG1hNFvw7rYMAED/IA8oFeyxISJpMdx00BPje8PDpWE+9tk8Lgknx2QyW5Cy/iS+O1MIZ6UC/zc1VuqSiIgYbjpjbB9/AMBJ7ndDDuov2zLw35P5UCkFLLt/KMb29Ze6JCIihpvOSIryAQAcyiyTuBIiaWw/2zCh/u3ZAzF5QNAt7iYi6h4MN50wqlfDOVNHMsthNFskroao+9U2boWQEMaDMInIfjDcdEJciCe8XFWoNZhxhvNuyAHp9CYAgIY7EBORHWG46QSFQsDIGF8ADacfEzkSURShMzb03GjUDDdEZD8YbjppcONuxecKtNIWQtTN6o0WNJ2e4uYs6UkuRETNMNx00oAQDwBAOsMNORidwWT9b1du2kdEdoThppPiQhomUl4uqUW9kedMkePQ1jeEG1eVEgpu3EdEdoThppOCPNXw0ahgtoi4WFQjdTlE3aLeaMYLG04CAKL93SSuhoioOYabThIEAXGhngCAM/lcMUXyZzJb8NQXJ3DkagU8XJzw3j2DpS6JiKgZhhsbSGycVHzwCjfzI/nbcqYQ36cXQe2kwMqHhmNAiKfUJRERNcNwYwO3xwYCAL49VYCKWoPE1RB1rV0ZJQCA+0ZGYUTjVghERPaE4cYGkqJ8ERvsAZNFxI6MYqnLIeoyW04X4KsTuQCA2/r4SVwNEVHrGG5sZEpcw7k6288WSVwJUdc4llWBZ9elQRSB+0dFWnssiYjsDcONjTSFm90XS7gknGSnRm/CU18ch8Fkwc8GBOH1uxIgCFz+TUT2ieHGRgaGeSHY0wU6gxk7G+ckEMnFvkulKKiqR5CnGn//RSKU3NeGiOwYw42NCIKAuxJDAQB/3Z4BsWlfeqIeThRFbD1TCAAY1zcAbmoetUBE9o3hxoaeHN8Lzk4KXCyuwcVibuhH8vDOtgxsOpEHQQBmDg6VuhwioltiuLEhP3c1xvRuWEHyQzpXTVHP9+HOS/hw52UAwJuzEjChX4DEFRER3RrDjY01rSDZcZ7hhnq2zw9cxV+2ZgAAFk+Pxf2joiSuiIiobRhubGxS/4Zwc/hqOcq5oR/1UF8dz8XvvzkLAHhqUh88OaG3xBUREbUdw42NRfhqEOChBgAMfTNV4mqI2m/rmUL834ZTAICHx0Tjt8n9JK6IiKh9GG66wPSEYOt/Z5fpJKyEqH0OXC7D0/8+AbNFxN1J4Xj1zjjuZ0NEPQ7DTRd45Y44639PfHcHN/WjHuFsfhWeWHMUBrMFU+OD8Ke5A6HgfjZE1AMx3HQBZycFvnh8JADAIjacx0Nkz3LKdXjo0yOo1pswIsYXf//FEDgp+eOBiHom/vTqImN6++PxcTEAgLUHsySuhujGavQmPLr6CEpr9IgN9sDHDw6Di0opdVlERB3GcNOFHh/fC04KAcezK3EuXyt1OUQtWCwiUtal4UJRDQI81Fj1qxHwclVJXRYRUacw3HShQA8XTI1vmFy86IvjyCytlbgioub+/sNFbD9XBGelAh89kIRgLxepSyIi6jSGmy7264m9IQhAZmktHlt9BCazReqSiAA0LPn++w8XAQBvzUnA0EgfiSsiIrINhpsulhDmha8X3gYAuFxSi8Gvb0eN3iRxVeToLhZV47fr0wA07GVzz7AIaQsiIrIhhptuMDjCG/83tT8AoNZgxiOrjqBKZ5S4KnJUVXVGPPH5MdQazBjdyw8v3zFA6pKIiGyK4aabPDm+l/XcqcOZ5Xhp02mJKyJH9db/ziGztBZh3q744JdDoOKSbyKSGf5U6yZOSgU+fXg4vll0G5QKAd+eLsDODB6uSd1r14USbDieCwB4/95E+LmrJa6IiMj2GG662eAIbzzQeLry29+mo6CqTuKKyFFkldXiN18chygC946IQFKUr9QlERF1CYYbCTw2LgZeripcLK7B7H/uwzdpeTBbRKnLIhnTGUx48vNj0NabMCTSG6/flSB1SUREXYbhRgLhPhpsWjgGQZ5qFGn1eOY/aXjpq9MQRQYcsj1RFPHChlM4X1gNf3dnLLsvCc5O/F+fiOSLP+Ek0ivAHVufGY+FE3sDANYdzcGK3Vckrork6KPdV/C/UwVwUgj48D5u1EdE8sdwIyEfN2e8MC0Wz/2sHwBgyXfn8YfNZyWuiuTkWFYF/rL1PADgtbviMSKG82yISP4YbuzA05P74De39wEArNp/FR+zB4dsoKrOiGf+cwIWEZidGIr7R0ZKXRIRUbdguLEDgiDgt8n98avbogEAf/v+Agqr6qUtinq8v6VeQG5FHSJ8XfHG7AQIgiB1SURE3YLhxo68emccBkd4Q2cwY96y/Sit0UtdEvVQdQYzNjbuZ/PmrAR4uvCkbyJyHAw3dkQQBLxz9yD4ujkjr7IO//flSVi4RJw64NN9maiuNyHSV4PxfQOkLoeIqFsx3NiZfkEe+OLxkXB2UmBHRgk+2cv5N9R+354qAAAsmtQbCgWHo4jIsTDc2KHYYE+8emccAOAvWzNw9Gq5xBVRT2I0W3ChqBoAMJa9NkTkgBhu7NR9IyNxx6AQmCwi5q84iH8dypK6JOohssp0MFlEuKqUCPHknjZE5HgYbuyUIAj409yBGBzhDbNFxMubzuCTPRyiols7nlUBAIgL9eSQFBE5JIYbO+bhosJXvx6DpCgfAMBb36bjzf+dw9XSWokrI3v231P5AICR3LCPiBwUw42dUyoEbFgwGncOCgEArNybiYnv7sSGY7kSV0b2KKdchz0XSwEAY/v6S1wNEZE0GG56AEEQ8Me5AzF3SJj12gsbTuKbtDwJqyJ7lJZTCQAI9FBjTG+GGyJyTAw3PYSniwrvzU9E+hvTMHdoGCwikLKeAYca6E1mrNqXiRc3ngIAJMcHSVwREZF0nKQugNrH1VmJv8wbhLIaA3ZdKMEz/0lDWk4lnpvSj7vQOqiqOiMe/uwwTmRXAmiYa/Ns42GsRESOiOGmB3JSKvDxg8PwwoaT+DotH5/tu4rP9l3Fw2Oi8fIdA6BSskNO7vQmMzan5WPrmUL8cL7Yen3hxN74bXJ/KLlKiogcGMNND+XspMDf5idiUmwgfv/1GWjrTVi1/youl9Tgd9NjER/qJXWJ1EW+PJqD91IvoOAnh6sGe7rg93fG4Y7GiedERI6M4aYHEwQBsxLDMC0hGN+dLsTzX57Enoul2HNxL+YPi8BzU/oh2IubuMmFKIp443/n8Nm+qwAaAs2sxFDcnRSOvkEe0hZHRGRHGG5kQO2kxOwhYegT6I4/bD6Lo1kVWHc0Bz+cL8J/fzMWIV6uUpdInVRdb8Qd7+9FdrkOAPD05L5YOLE3XFRKiSsjIrI/nJwhIwlhXtjw6zFY88gIhHq5oLTGgDn/3I/vThdAFHm6eE91Jq8K05busQabx8fFIGVKPwYbIqIbYM+NDI3vF4B1T47Gr1YdwaXiGvz6X8cR6atBclwQ5gwN43ycHiK3QofXvjlrnTDsqlLijVnx+PmwCIkrIyKybww3MhXhq8HXi27DX7dn4LN9V5FdrsMnezPxyd5MBHmqMbqXH+qMZgR4qPHo2F6I8XeTumSHdb5Qi+/PFeFKaS1yy+tgtFigdlLgXL4W2noTAODOQSF4bko/9A5wl7haIiL7x3AjY+5qJ7w2Mx6Pjo3B4q9O40pJLQqq6lCk1ePrtHzrfZuO5yEu1BNltQZ4u6owKzEMvQPcMaqXL5y4rNymRFHExeIa7LtUivQCLY5lVeByyY3PCnNVKfGPe4fgZ3HclI+IqK0YbhxAuI8Gnz86EgCgM5hw6Eo5vjtTgNyKOpRU63GxuAZHrlZY7z/euBmcq0qJgeFeKNLWI8zbFQPDvdA7wB1T44LhpeGGge0liiJe/+85rNp/tcVzvQPcMCLGFwlhXvDROMNsEeHlqsLgCG94ufL3moioPRhuHIzG2QmTYgMxKTYQAGAyW/B9ejEKqupQqzfhQlENzhVocam4BnVGMw5nlgMAssp02H+5DADwlss5LJzUB78cGcldkdugSFuPFbuv4D+Hs1FrMAMAQr1ccHdSOGIC3DA00gdRfhwWJCKyFYYbB+ekVGBaQnCL6zqDCRuP5eJMnhYXiqshANAZzCitMaC0Ro8/fXceS7+/gMkDgjCmtx9u6+2PaM7baaa81oA9F0vw0lenraHGWanAi9Nj8ejYGImrIyKSL4YbapXG2QkPjI5ucd1sEfHJnitYcyALeZV1+PZUAb49VQAAmBwbiClxQZgxKERWPTpmiwiF0LBpIgDUGcxwUbWci1RYVY/LJTW4UFSNdUdycL6w2vpcpK8GL82Ixeje/hxmIiLqYpKHmw8//BDvvPMOCgoKEB8fj6VLl2LcuHGt3rtz505MmjSpxfX09HTExsZ2dakEQKkQ8OSE3nhifC+cyKnErowSHLhShqNXy/HD+WL8cL4YizedRrSfG4I9XZBbqYOHWoUJ/QMwMsYXI2J8oXGWvNm1IIoizuRpcfBKGdILtDiUWQ6VUoBZFJFXUQcnhQIx/m64VFIDs0WEt0aF/kHu0FYo8E35CeiMZhy5WgGzpfl+Qh4uTvjZgCD8YWY85ykREXUTSf+WWbduHZ599ll8+OGHuO222/DRRx9h+vTpOHfuHCIjI2/4uoyMDHh6elofBwQEdEe59BOCIGBopA+GRvrgOQDHsirwxy3pOJZVAVEEMktrkVnatAqoDucKtFi28zJUSgHDo31x74hIJEZ4I9zH1doj8lOiKMIiAjX1JriplTiVVwWLRUSFzogavREmswh3tRP8PdSI8tUg0LPjx0x8fuAqlu+6grzKuhveYzBbkFF0rSemUmfEocwKAAqkV5ZYr0f4uiLSV4P+QZ6ICXDD/SMjW/1+RETUdSQNN++99x4effRRPPbYYwCApUuXYtu2bVi2bBmWLFlyw9cFBgbC29u7U5+tM5jgZDB16j3omgEhHvj80REQRRGZZTrkN67EqqozoqCqHsU19TidW4X8ynrsv1xmnZwc6OEMf3c1LBbAIorQmy3Iq9DBIgKWdmyqHOypRqCnCxSCgH5B7gjydEGwlwtq6k3wcVMhzNsVpTUGeLqocKGoGmW1eoR5a3A6txIbjudZ32dgmBeGx/igl787gj1doFIKCPPRoNZgwrGrFcit1OGepAjU6E04l1eJHw6fRVRMFAaEeiHKzw2Dw72ahZk6o9lmv8ckT0ajCXpzw88klcggTB0n97aka8ff2YIo0b78BoMBGo0GX375JebMmWO9/swzzyAtLQ27du1q8ZqmYano6GjU19cjLi4Or7zySqtDVU30ej30er31sVarRUREBCKeXQ+FWmPbL0VERERdwqLXIWfpPaiqqmo2etMayXZoKy0thdlsRlBQ883JgoKCUFhY2OprQkJCsGLFCmzcuBFfffUV+vfvj8mTJ2P37t03/JwlS5bAy8vL+isiglvXExERyZlkPTf5+fkICwvD/v37MXr0aOv1t99+G59//jnOnz/fpveZOXMmBEHA5s2bW33+Rj032fmFt0x+JD8WCyAIDb86y2g04ccff8Ttt98Olcr+JklTz8B2RLYi97ak1WoRGRrcpp4byb69v78/lEpli16a4uLiFr05NzNq1CisXbv2hs+r1Wqo1eoW173cXOHp5tr2gomuYzQaoVYCXm4uUKm4Eoo6hu2IbEXubUkwG9t8r2TDUs7OzkhKSkJqamqz66mpqRgzZkyb3+fEiRMICQmxdXlERETUQ0nab5WSkoIHHngAw4YNw+jRo7FixQpkZ2djwYIFAIDFixcjLy8Pa9asAdCwmio6Ohrx8fEwGAxYu3YtNm7ciI0bN0r5NYiIiMiOSBpu5s+fj7KyMrzxxhsoKChAQkICtmzZgqioKABAQUEBsrOzrfcbDAY8//zzyMvLg6urK+Lj4/Htt99ixowZUn0FIiIisjOSzzhauHAhFi5c2Opzq1atavb4hRdewAsvvNANVREREVFPJdmcGyIiIqKuwHBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREsiJ5uPnwww8RExMDFxcXJCUlYc+ePTe9f9euXUhKSoKLiwt69eqF5cuXd1OlRERE1BNIGm7WrVuHZ599Fi+//DJOnDiBcePGYfr06cjOzm71/szMTMyYMQPjxo3DiRMn8NJLL+Hpp5/Gxo0bu7lyIiIisleShpv33nsPjz76KB577DEMGDAAS5cuRUREBJYtW9bq/cuXL0dkZCSWLl2KAQMG4LHHHsMjjzyCd999t5srJyIiInvlJNUHGwwGHDt2DL/73e+aXU9OTsb+/ftbfc2BAweQnJzc7NrUqVOxcuVKGI1GqFSqFq/R6/XQ6/XWx1VVVQCA8vJyGI3Gzn4NcmBGoxE6nQ5lZWWttj2itmA7IluRe1uqrq4GAIiieMt7JQs3paWlMJvNCAoKanY9KCgIhYWFrb6msLCw1ftNJhNKS0sREhLS4jVLlizB66+/3uJ6TExMJ6onIiIiKVRXV8PLy+um90gWbpoIgtDssSiKLa7d6v7WrjdZvHgxUlJSrI8tFgvKy8vh5+d308+xJ8OHD8eRI0d6zOd05n3a89q23nur+zr6vFarRUREBHJycuDp6dmmmqXmKG2pva+Tsi2xHXXP53RHW7JVO7rVPY76M0kURVRXVyM0NPSW90oWbvz9/aFUKlv00hQXF7fonWkSHBzc6v1OTk7w8/Nr9TVqtRpqtbrZNW9v744XLgGlUtktDdVWn9OZ92nPa9t6763u6+zznp6ePeYHiaO0pfa+zh7aEttR135Od7QlW7WjW93jyD+TbtVj00SyCcXOzs5ISkpCampqs+upqakYM2ZMq68ZPXp0i/u3b9+OYcOGyXJ8scmiRYt61Od05n3a89q23nur+zr7fE/iKG2pva9jW2qfntaOOvNeUvxMutU9cmlHQNd9F0Fsy8ycLrJu3To88MADWL58OUaPHo0VK1bg448/xtmzZxEVFYXFixcjLy8Pa9asAdCwFDwhIQFPPvkkHn/8cRw4cAALFizAv//9b8ybN0+qr0EOSqvVwsvLC1VVVT3mX0lkf9iOyFbYlq6RdM7N/PnzUVZWhjfeeAMFBQVISEjAli1bEBUVBQAoKChotudNTEwMtmzZgueeew7//Oc/ERoaivfff5/BhiShVqvx2muvtRj2JGoPtiOyFbalayTtuSEiIiKyNcmPXyAiIiKyJYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGG6IulpOTg4kTJyIuLg6DBg3Cl19+KXVJ1IPNmTMHPj4+uPvuu6UuhXqQ//3vf+jfvz/69u2LTz75ROpyuhyXghN1sYKCAhQVFSExMRHFxcUYOnQoMjIy4ObmJnVp1APt2LEDNTU1WL16NTZs2CB1OdQDmEwmxMXFYceOHfD09MTQoUNx6NAh+Pr6Sl1al2HPDVEXCwkJQWJiIgAgMDAQvr6+KC8vl7Yo6rEmTZoEDw8PqcugHuTw4cOIj49HWFgYPDw8MGPGDGzbtk3qsroUww05vN27d2PmzJkIDQ2FIAj4+uuvW9zz4YcfIiYmBi4uLkhKSsKePXs69FlHjx6FxWJBREREJ6sme9SdbYkcR2fbVX5+PsLCwqyPw8PDkZeX1x2lS4bhhhxebW0tBg8ejA8++KDV59etW4dnn30WL7/8Mk6cOIFx48Zh+vTpzY4GSUpKQkJCQotf+fn51nvKysrw4IMPYsWKFV3+nUga3dWWyLF0tl21NvtEEIQurVlyIhFZARA3bdrU7NqIESPEBQsWNLsWGxsr/u53v2vz+9bX14vjxo0T16xZY4syqQfoqrYkiqK4Y8cOcd68eZ0tkXqgjrSrffv2ibNnz7Y+9/TTT4v/+te/urxWKbHnhugmDAYDjh07huTk5GbXk5OTsX///ja9hyiKePjhh3H77bfjgQce6IoyqQewRVsiul5b2tWIESNw5swZ5OXlobq6Glu2bMHUqVOlKLfbSHoqOJG9Ky0thdlsRlBQULPrQUFBKCwsbNN77Nu3D+vWrcOgQYOsY+Wff/45Bg4caOtyyY7Zoi0BwNSpU3H8+HHU1tYiPDwcmzZtwvDhw21dLvUQbWlXTk5O+Otf/4pJkybBYrHghRdegJ+fnxTldhuGG6I2uH58WhTFNo9Zjx07FhaLpSvKoh6oM20JgOxXuVDH3Kpd3XXXXbjrrru6uyzJcFiK6Cb8/f2hVCpb/Mu6uLi4xb+UiG6GbYm6AttV6xhuiG7C2dkZSUlJSE1NbXY9NTUVY8aMkagq6onYlqgrsF21jsNS5PBqampw6dIl6+PMzEykpaXB19cXkZGRSElJwQMPPIBhw4Zh9OjRWLFiBbKzs7FgwQIJqyZ7xLZEXYHtqgOkXaxFJL0dO3aIAFr8euihh6z3/POf/xSjoqJEZ2dncejQoeKuXbukK5jsFtsSdQW2q/bj2VJEREQkK5xzQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDRD1SdHQ0li5dKnUZRGSHuEMxEd3Qww8/jMrKSnz99ddSl9JCSUkJ3NzcoNFopC6lVfb8e0ckd+y5ISK7YjQa23RfQECAJMGmrfURkXQYboiow86dO4cZM2bA3d0dQUFBeOCBB1BaWmp9fuvWrRg7diy8vb3h5+eHO++8E5cvX7Y+f/XqVQiCgPXr12PixIlwcXHB2rVr8fDDD2P27Nl49913ERISAj8/PyxatKhZsLh+WEoQBHzyySeYM2cONBoN+vbti82bNzerd/Pmzejbty9cXV0xadIkrF69GoIgoLKy8obfURAELF++HLNmzYKbmxveeustmM1mPProo4iJiYGrqyv69++Pv//979bX/OEPf8Dq1avxzTffQBAECIKAnTt3AgDy8vIwf/58+Pj4wM/PD7NmzcLVq1c79gdARK1iuCGiDikoKMCECROQmJiIo0ePYuvWrSgqKsI999xjvae2thYpKSk4cuQIfvjhBygUCsyZMwcWi6XZe7344ot4+umnkZ6ejqlTpwIAduzYgcuXL2PHjh1YvXo1Vq1ahVWrVt20ptdffx333HMPTp06hRkzZuC+++5DeXk5gIYgdffdd2P27NlIS0vDk08+iZdffrlN3/W1117DrFmzcPr0aTzyyCOwWCwIDw/H+vXrce7cObz66qt46aWXsH79egDA888/j3vuuQfTpk1DQUEBCgoKMGbMGOh0OkyaNAnu7u7YvXs39u7dC3d3d0ybNg0Gg6Gtv/VEdCvSHkpORPbsoYceEmfNmtXqc7///e/F5OTkZtdycnJEAGJGRkarrykuLhYBiKdPnxZFURQzMzNFAOLSpUtbfG5UVJRoMpms137+85+L8+fPtz6OiooS//a3v1kfAxBfeeUV6+OamhpREATxu+++E0VRFF988UUxISGh2ee8/PLLIgCxoqKi9d+Axvd99tlnb/h8k4ULF4rz5s1r9h2u/71buXKl2L9/f9FisViv6fV60dXVVdy2bdstP4OI2oY9N0TUIceOHcOOHTvg7u5u/RUbGwsA1qGny5cv45e//CV69eoFT09PxMTEAACys7ObvdewYcNavH98fDyUSqX1cUhICIqLi29a06BBg6z/7ebmBg8PD+trMjIyMHz48Gb3jxgxok3ftbX6li9fjmHDhiEgIADu7u74+OOPW3yv6x07dgyXLl2Ch4eH9ffM19cX9fX1zYbriKhznKQugIh6JovFgpkzZ+LPf/5zi+dCQkIAADNnzkRERAQ+/vhjhIaGwmKxICEhocUQjJubW4v3UKlUzR4LgtBiOKs9rxFFEYIgNHtebONi0evrW79+PZ577jn89a9/xejRo+Hh4YF33nkHhw4duun7WCwWJCUl4V//+leL5wICAtpUCxHdGsMNEXXI0KFDsXHjRkRHR8PJqeWPkrKyMqSnp+Ojjz7CuHHjAAB79+7t7jKtYmNjsWXLlmbXjh492qH32rNnD8aMGYOFCxdar13f8+Ls7Ayz2dzs2tChQ7Fu3ToEBgbC09OzQ59NRLfGYSkiuqmqqiqkpaU1+5WdnY1FixahvLwc9957Lw4fPowrV65g+/bteOSRR2A2m62rgVasWIFLly7hxx9/REpKimTf48knn8T58+fx4osv4sKFC1i/fr11gvL1PTq30qdPHxw9ehTbtm3DhQsX8Pvf/x5Hjhxpdk90dDROnTqFjIwMlJaWwmg04r777oO/vz9mzZqFPXv2IDMzE7t27cIzzzyD3NxcW31VIofHcENEN7Vz504MGTKk2a9XX30VoaGh2LdvH8xmM6ZOnYqEhAQ888wz8PLygkKhgEKhwH/+8x8cO3YMCQkJeO655/DOO+9I9j1iYmKwYcMGfPXVVxg0aBCWLVtmXS2lVqvb9V4LFizA3LlzMX/+fIwcORJlZWXNenEA4PHHH0f//v2t83L27dsHjUaD3bt3IzIyEnPnzsWAAQPwyCOPoK6ujj05RDbEHYqJyGG9/fbbWL58OXJycqQuhYhsiHNuiMhhfPjhhxg+fDj8/Pywb98+vPPOO3jqqaekLouIbIzhhogcxsWLF/HWW2+hvLwckZGR+O1vf4vFixdLXRYR2RiHpYiIiEhWOKGYiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhk5f8BvErGyiXeJP0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(expon_lr.rates, expon_lr.losses)\n",
    "plt.gca().set_xscale(\"log\")\n",
    "plt.hlines(min(expon_lr.losses), min(expon_lr.rates), max(expon_lr.rates))\n",
    "plt.axis([min(expon_lr.rates), max(expon_lr.rates), 0, expon_lr.losses[0]])\n",
    "plt.grid()\n",
    "plt.xlabel(\"Learning rate\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1738872771.262450    4664 service.cc:148] XLA service 0x7f36fc0067c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1738872771.262507    4664 service.cc:156]   StreamExecutor device (0): Quadro P600, Compute Capability 6.1\n",
      "2025-02-06 21:12:51.294251: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1738872771.473339    4664 cuda_dnn.cc:529] Loaded cuDNN version 90700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  70/1563\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5824 - loss: 1.3090"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1738872772.999749    4664 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8885 - loss: 0.3627 - val_accuracy: 0.9595 - val_loss: 0.1332\n",
      "Epoch 2/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9670 - loss: 0.1089 - val_accuracy: 0.9648 - val_loss: 0.1176\n",
      "Epoch 3/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9764 - loss: 0.0743 - val_accuracy: 0.9700 - val_loss: 0.1120\n",
      "Epoch 4/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9828 - loss: 0.0551 - val_accuracy: 0.9732 - val_loss: 0.1026\n",
      "Epoch 5/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9859 - loss: 0.0470 - val_accuracy: 0.9732 - val_loss: 0.1056\n",
      "Epoch 6/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9874 - loss: 0.0402 - val_accuracy: 0.9742 - val_loss: 0.1060\n",
      "Epoch 7/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9896 - loss: 0.0308 - val_accuracy: 0.9776 - val_loss: 0.1033\n",
      "Epoch 8/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9922 - loss: 0.0286 - val_accuracy: 0.9776 - val_loss: 0.0988\n",
      "Epoch 9/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9920 - loss: 0.0282 - val_accuracy: 0.9773 - val_loss: 0.1148\n",
      "Epoch 10/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9922 - loss: 0.0238 - val_accuracy: 0.9732 - val_loss: 0.1300\n",
      "Epoch 11/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9933 - loss: 0.0209 - val_accuracy: 0.9764 - val_loss: 0.1237\n",
      "Epoch 12/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9946 - loss: 0.0170 - val_accuracy: 0.9779 - val_loss: 0.1204\n",
      "Epoch 13/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9940 - loss: 0.0175 - val_accuracy: 0.9775 - val_loss: 0.1211\n",
      "Epoch 14/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9930 - loss: 0.0231 - val_accuracy: 0.9779 - val_loss: 0.1341\n",
      "Epoch 15/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9948 - loss: 0.0181 - val_accuracy: 0.9737 - val_loss: 0.1374\n",
      "Epoch 16/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9950 - loss: 0.0157 - val_accuracy: 0.9786 - val_loss: 0.1354\n",
      "Epoch 17/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9960 - loss: 0.0146 - val_accuracy: 0.9812 - val_loss: 0.1383\n",
      "Epoch 18/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9962 - loss: 0.0150 - val_accuracy: 0.9784 - val_loss: 0.1382\n",
      "Epoch 19/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9952 - loss: 0.0183 - val_accuracy: 0.9798 - val_loss: 0.1263\n",
      "Epoch 20/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9964 - loss: 0.0126 - val_accuracy: 0.9804 - val_loss: 0.1289\n",
      "Epoch 21/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9969 - loss: 0.0109 - val_accuracy: 0.9796 - val_loss: 0.1463\n",
      "Epoch 22/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9968 - loss: 0.0119 - val_accuracy: 0.9780 - val_loss: 0.1428\n",
      "Epoch 23/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9964 - loss: 0.0141 - val_accuracy: 0.9787 - val_loss: 0.1608\n",
      "Epoch 24/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9968 - loss: 0.0138 - val_accuracy: 0.9799 - val_loss: 0.1508\n",
      "Epoch 25/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9969 - loss: 0.0107 - val_accuracy: 0.9753 - val_loss: 0.2108\n",
      "Epoch 26/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9945 - loss: 0.0259 - val_accuracy: 0.9827 - val_loss: 0.1455\n",
      "Epoch 27/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9980 - loss: 0.0075 - val_accuracy: 0.9790 - val_loss: 0.1923\n",
      "Epoch 28/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9961 - loss: 0.0160 - val_accuracy: 0.9822 - val_loss: 0.1624\n",
      "Epoch 29/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0069 - val_accuracy: 0.9789 - val_loss: 0.1930\n",
      "Epoch 30/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9972 - loss: 0.0108 - val_accuracy: 0.9794 - val_loss: 0.1866\n",
      "Epoch 31/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9972 - loss: 0.0154 - val_accuracy: 0.9794 - val_loss: 0.1865\n",
      "Epoch 32/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9975 - loss: 0.0100 - val_accuracy: 0.9804 - val_loss: 0.1722\n",
      "Epoch 33/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9971 - loss: 0.0098 - val_accuracy: 0.9812 - val_loss: 0.2016\n",
      "Epoch 34/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9974 - loss: 0.0129 - val_accuracy: 0.9789 - val_loss: 0.2046\n",
      "Epoch 35/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9973 - loss: 0.0126 - val_accuracy: 0.9795 - val_loss: 0.1765\n",
      "Epoch 36/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9975 - loss: 0.0118 - val_accuracy: 0.9808 - val_loss: 0.2112\n",
      "Epoch 37/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9979 - loss: 0.0096 - val_accuracy: 0.9810 - val_loss: 0.1864\n",
      "Epoch 38/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0044 - val_accuracy: 0.9816 - val_loss: 0.1687\n",
      "Epoch 39/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9973 - loss: 0.0107 - val_accuracy: 0.9813 - val_loss: 0.1747\n",
      "Epoch 40/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0053 - val_accuracy: 0.9744 - val_loss: 0.2895\n",
      "Epoch 41/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9969 - loss: 0.0167 - val_accuracy: 0.9805 - val_loss: 0.1956\n",
      "Epoch 42/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9979 - loss: 0.0095 - val_accuracy: 0.9813 - val_loss: 0.2154\n",
      "Epoch 43/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9979 - loss: 0.0111 - val_accuracy: 0.9776 - val_loss: 0.2004\n",
      "Epoch 44/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9981 - loss: 0.0099 - val_accuracy: 0.9806 - val_loss: 0.2443\n",
      "Epoch 45/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9966 - loss: 0.0211 - val_accuracy: 0.9823 - val_loss: 0.2024\n",
      "Epoch 46/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0083 - val_accuracy: 0.9797 - val_loss: 0.1926\n",
      "Epoch 47/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9978 - loss: 0.0104 - val_accuracy: 0.9811 - val_loss: 0.2140\n",
      "Epoch 48/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9973 - loss: 0.0122 - val_accuracy: 0.9815 - val_loss: 0.2345\n",
      "Epoch 49/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9973 - loss: 0.0151 - val_accuracy: 0.9836 - val_loss: 0.1929\n",
      "Epoch 50/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0042 - val_accuracy: 0.9812 - val_loss: 0.2155\n",
      "Epoch 51/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0106 - val_accuracy: 0.9825 - val_loss: 0.2166\n",
      "Epoch 52/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9979 - loss: 0.0117 - val_accuracy: 0.9835 - val_loss: 0.2126\n",
      "Epoch 53/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0084 - val_accuracy: 0.9806 - val_loss: 0.2389\n",
      "Epoch 54/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0123 - val_accuracy: 0.9796 - val_loss: 0.2498\n",
      "Epoch 55/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0091 - val_accuracy: 0.9804 - val_loss: 0.2285\n",
      "Epoch 56/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0054 - val_accuracy: 0.9794 - val_loss: 0.2952\n",
      "Epoch 57/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9975 - loss: 0.0168 - val_accuracy: 0.9800 - val_loss: 0.2664\n",
      "Epoch 58/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9971 - loss: 0.0179 - val_accuracy: 0.9802 - val_loss: 0.2792\n",
      "Epoch 59/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0105 - val_accuracy: 0.9819 - val_loss: 0.2249\n",
      "Epoch 60/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0074 - val_accuracy: 0.9842 - val_loss: 0.2533\n",
      "Epoch 61/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0029 - val_accuracy: 0.9809 - val_loss: 0.2704\n",
      "Epoch 62/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0103 - val_accuracy: 0.9808 - val_loss: 0.2826\n",
      "Epoch 63/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0091 - val_accuracy: 0.9825 - val_loss: 0.2696\n",
      "Epoch 64/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0091 - val_accuracy: 0.9770 - val_loss: 0.3500\n",
      "Epoch 65/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9977 - loss: 0.0133 - val_accuracy: 0.9818 - val_loss: 0.3053\n",
      "Epoch 66/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0085 - val_accuracy: 0.9815 - val_loss: 0.3059\n",
      "Epoch 67/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0065 - val_accuracy: 0.9811 - val_loss: 0.3300\n",
      "Epoch 68/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0105 - val_accuracy: 0.9804 - val_loss: 0.3056\n",
      "Epoch 69/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0133 - val_accuracy: 0.9817 - val_loss: 0.2780\n",
      "Epoch 70/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0079 - val_accuracy: 0.9820 - val_loss: 0.3175\n",
      "Epoch 71/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0083 - val_accuracy: 0.9797 - val_loss: 0.3677\n",
      "Epoch 72/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0158 - val_accuracy: 0.9810 - val_loss: 0.3622\n",
      "Epoch 73/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0074 - val_accuracy: 0.9801 - val_loss: 0.3321\n",
      "Epoch 74/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0118 - val_accuracy: 0.9816 - val_loss: 0.2508\n",
      "Epoch 75/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0026 - val_accuracy: 0.9821 - val_loss: 0.2971\n",
      "Epoch 76/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0092 - val_accuracy: 0.9807 - val_loss: 0.3537\n",
      "Epoch 77/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0118 - val_accuracy: 0.9836 - val_loss: 0.2673\n",
      "Epoch 78/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0074 - val_accuracy: 0.9825 - val_loss: 0.2870\n",
      "Epoch 79/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0045 - val_accuracy: 0.9786 - val_loss: 0.3903\n",
      "Epoch 80/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0106 - val_accuracy: 0.9818 - val_loss: 0.3133\n",
      "Epoch 81/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0069 - val_accuracy: 0.9802 - val_loss: 0.2947\n",
      "Epoch 82/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0081 - val_accuracy: 0.9801 - val_loss: 0.3427\n",
      "Epoch 83/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0140 - val_accuracy: 0.9811 - val_loss: 0.3205\n",
      "Epoch 84/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0078 - val_accuracy: 0.9799 - val_loss: 0.3454\n",
      "Epoch 85/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9984 - loss: 0.0148 - val_accuracy: 0.9827 - val_loss: 0.2967\n",
      "Epoch 86/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0077 - val_accuracy: 0.9805 - val_loss: 0.3266\n",
      "Epoch 87/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0116 - val_accuracy: 0.9800 - val_loss: 0.3460\n",
      "Epoch 88/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9980 - loss: 0.0127 - val_accuracy: 0.9826 - val_loss: 0.3658\n",
      "Epoch 89/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0140 - val_accuracy: 0.9839 - val_loss: 0.3526\n",
      "Epoch 90/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0091 - val_accuracy: 0.9822 - val_loss: 0.2904\n",
      "Epoch 91/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0095 - val_accuracy: 0.9823 - val_loss: 0.3408\n",
      "Epoch 92/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0074 - val_accuracy: 0.9789 - val_loss: 0.4420\n",
      "Epoch 93/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0125 - val_accuracy: 0.9797 - val_loss: 0.3385\n",
      "Epoch 94/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0055 - val_accuracy: 0.9831 - val_loss: 0.3160\n",
      "Epoch 95/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0043 - val_accuracy: 0.9782 - val_loss: 0.4313\n",
      "Epoch 96/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0131 - val_accuracy: 0.9826 - val_loss: 0.3649\n",
      "Epoch 97/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0055 - val_accuracy: 0.9804 - val_loss: 0.4524\n",
      "Epoch 98/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0089 - val_accuracy: 0.9798 - val_loss: 0.4785\n",
      "Epoch 99/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9977 - loss: 0.0294 - val_accuracy: 0.9803 - val_loss: 0.3626\n",
      "Epoch 100/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0070 - val_accuracy: 0.9833 - val_loss: 0.3032\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_train, y_train, batch_size=32, epochs=100, validation_data=(x_valid, y_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(\n",
    "    figsize=(8, 5),\n",
    "    xlim=[0, 59],\n",
    "    ylim=[0, 1],\n",
    "    grid=True,\n",
    "    xlabel=\"Epoch\",\n",
    "    style=[\"r--\", \"r--.\", \"b-\", \"b-*\"],\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difference between train and validation accurracy points to overfitting. Constant increase in validation loss is another sign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9791 - loss: 0.4660\n",
      "test loss, test acc: [0.3696935474872589, 0.9822999835014343]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test, y_test)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual DNN hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('my_logs/run_2025_02_07_09_31_48')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_run_logdir(root_logdir=\"my_logs\"):\n",
    "    return Path(root_logdir) / strftime(\"run_%Y_%m_%d_%H_%M_%S\")\n",
    "\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">235,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">90,300</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">90,300</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">90,300</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │       \u001b[38;5;34m235,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │        \u001b[38;5;34m90,300\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │        \u001b[38;5;34m90,300\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │        \u001b[38;5;34m90,300\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m3,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">509,410</span> (1.94 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m509,410\u001b[0m (1.94 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">509,410</span> (1.94 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m509,410\u001b[0m (1.94 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=input_shape))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(300, activation=\"relu\"))\n",
    "model.add(Dense(300, activation=\"relu\"))\n",
    "model.add(Dense(300, activation=\"relu\"))\n",
    "model.add(Dense(300, activation=\"relu\"))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintValTrainRatioCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        ratio = logs[\"val_loss\"] / logs[\"loss\"]\n",
    "        print(f\"Epoch={epoch}, val/train={ratio:.2f}\")\n",
    "        return super().on_epoch_end(epoch, logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8799 - loss: 0.3829Epoch=0, val/train=0.61\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8800 - loss: 0.3828 - val_accuracy: 0.9591 - val_loss: 0.1372\n",
      "Epoch 2/100\n",
      "\u001b[1m1557/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9650 - loss: 0.1171Epoch=1, val/train=1.06\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9650 - loss: 0.1171 - val_accuracy: 0.9683 - val_loss: 0.1132\n",
      "Epoch 3/100\n",
      "\u001b[1m1557/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9767 - loss: 0.0806Epoch=2, val/train=1.63\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9767 - loss: 0.0806 - val_accuracy: 0.9677 - val_loss: 0.1210\n",
      "Epoch 4/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9805 - loss: 0.0652Epoch=3, val/train=1.69\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9805 - loss: 0.0652 - val_accuracy: 0.9722 - val_loss: 0.1011\n",
      "Epoch 5/100\n",
      "\u001b[1m1560/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9831 - loss: 0.0575Epoch=4, val/train=2.06\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9831 - loss: 0.0575 - val_accuracy: 0.9746 - val_loss: 0.1083\n",
      "Epoch 6/100\n",
      "\u001b[1m1562/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9871 - loss: 0.0420Epoch=5, val/train=2.91\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9872 - loss: 0.0420 - val_accuracy: 0.9714 - val_loss: 0.1172\n",
      "Epoch 7/100\n",
      "\u001b[1m1562/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9880 - loss: 0.0387Epoch=6, val/train=3.51\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9880 - loss: 0.0387 - val_accuracy: 0.9722 - val_loss: 0.1270\n",
      "Epoch 8/100\n",
      "\u001b[1m1557/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9887 - loss: 0.0371Epoch=7, val/train=2.80\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9887 - loss: 0.0371 - val_accuracy: 0.9773 - val_loss: 0.0994\n",
      "Epoch 9/100\n",
      "\u001b[1m1559/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9913 - loss: 0.0300Epoch=8, val/train=4.16\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9913 - loss: 0.0300 - val_accuracy: 0.9746 - val_loss: 0.1227\n",
      "Epoch 10/100\n",
      "\u001b[1m1556/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9922 - loss: 0.0283Epoch=9, val/train=4.13\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9922 - loss: 0.0283 - val_accuracy: 0.9764 - val_loss: 0.1154\n",
      "Epoch 11/100\n",
      "\u001b[1m1559/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9919 - loss: 0.0289Epoch=10, val/train=4.57\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9919 - loss: 0.0289 - val_accuracy: 0.9776 - val_loss: 0.1168\n",
      "Epoch 12/100\n",
      "\u001b[1m1560/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9936 - loss: 0.0227Epoch=11, val/train=5.16\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9936 - loss: 0.0227 - val_accuracy: 0.9770 - val_loss: 0.1174\n",
      "Epoch 13/100\n",
      "\u001b[1m1560/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9926 - loss: 0.0232Epoch=12, val/train=6.28\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9926 - loss: 0.0232 - val_accuracy: 0.9807 - val_loss: 0.1254\n",
      "Epoch 14/100\n",
      "\u001b[1m1561/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9940 - loss: 0.0209Epoch=13, val/train=5.20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9939 - loss: 0.0209 - val_accuracy: 0.9809 - val_loss: 0.1189\n",
      "Epoch 15/100\n",
      "\u001b[1m1556/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9942 - loss: 0.0205Epoch=14, val/train=6.54\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9942 - loss: 0.0205 - val_accuracy: 0.9768 - val_loss: 0.1336\n",
      "Epoch 16/100\n",
      "\u001b[1m1556/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9938 - loss: 0.0211Epoch=15, val/train=6.13\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9938 - loss: 0.0211 - val_accuracy: 0.9785 - val_loss: 0.1308\n",
      "Epoch 17/100\n",
      "\u001b[1m1559/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9953 - loss: 0.0171Epoch=16, val/train=8.11\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9953 - loss: 0.0171 - val_accuracy: 0.9822 - val_loss: 0.1330\n",
      "Epoch 18/100\n",
      "\u001b[1m1556/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9952 - loss: 0.0186Epoch=17, val/train=6.41\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9952 - loss: 0.0186 - val_accuracy: 0.9798 - val_loss: 0.1173\n",
      "Epoch 19/100\n",
      "\u001b[1m1557/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9951 - loss: 0.0183Epoch=18, val/train=6.69\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9951 - loss: 0.0183 - val_accuracy: 0.9814 - val_loss: 0.1174\n",
      "Epoch 20/100\n",
      "\u001b[1m1557/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9955 - loss: 0.0172Epoch=19, val/train=7.38\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9955 - loss: 0.0172 - val_accuracy: 0.9802 - val_loss: 0.1302\n",
      "Epoch 21/100\n",
      "\u001b[1m1561/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9968 - loss: 0.0123Epoch=20, val/train=9.06\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9968 - loss: 0.0123 - val_accuracy: 0.9802 - val_loss: 0.1352\n",
      "Epoch 22/100\n",
      "\u001b[1m1558/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9968 - loss: 0.0158Epoch=21, val/train=7.86\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9968 - loss: 0.0158 - val_accuracy: 0.9816 - val_loss: 0.1275\n",
      "Epoch 23/100\n",
      "\u001b[1m1562/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9961 - loss: 0.0154Epoch=22, val/train=9.49\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9961 - loss: 0.0154 - val_accuracy: 0.9811 - val_loss: 0.1438\n",
      "Epoch 24/100\n",
      "\u001b[1m1557/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9965 - loss: 0.0140Epoch=23, val/train=13.58\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9965 - loss: 0.0140 - val_accuracy: 0.9710 - val_loss: 0.2002\n",
      "Epoch 25/100\n",
      "\u001b[1m1559/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9950 - loss: 0.0187Epoch=24, val/train=11.22\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9950 - loss: 0.0187 - val_accuracy: 0.9796 - val_loss: 0.1736\n",
      "Epoch 26/100\n",
      "\u001b[1m1562/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9967 - loss: 0.0144Epoch=25, val/train=7.87\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9967 - loss: 0.0144 - val_accuracy: 0.9836 - val_loss: 0.1170\n",
      "Epoch 27/100\n",
      "\u001b[1m1561/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9965 - loss: 0.0166Epoch=26, val/train=8.29\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9965 - loss: 0.0166 - val_accuracy: 0.9808 - val_loss: 0.1444\n",
      "Epoch 28/100\n",
      "\u001b[1m1562/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9965 - loss: 0.0163Epoch=27, val/train=10.09\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9965 - loss: 0.0163 - val_accuracy: 0.9823 - val_loss: 0.1393\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=32,\n",
    "    epochs=100,\n",
    "    validation_data=(x_valid, y_valid),\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=20, restore_best_weights=True),\n",
    "        PrintValTrainRatioCallback(),\n",
    "        TensorBoard(get_run_logdir()),\n",
    "        ModelCheckpoint(\"my_checkpoints/checkpoint.weights.h5\", save_weights_only=True),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9735 - loss: 0.1167\n",
      "test loss, test acc: [0.09471593052148819, 0.9782999753952026]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test, y_test)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test loss is smaller but accuracy dropped as well.\n",
    "\n",
    "Higher learning rate (0.002) performs worse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More neurons and layers seems to be better (higher accuracy).\n",
    "\n",
    "Less neurons and layers doesn't lower overfitting.\n",
    "\n",
    "98% accuracy on test set achieved by adding another hidden layer (4)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp: HyperParameters) -> Sequential:\n",
    "    n_hidden = hp.Int(\"n_hidden\", min_value=2, max_value=8, default=4)\n",
    "    n_neurons = hp.Int(\"n_neurons\", min_value=128, max_value=512)\n",
    "    learning_rate = hp.Float(\n",
    "        \"learning_rate\", min_value=1e-3, max_value=1e-2, sampling=\"log\"\n",
    "    )\n",
    "    optimizer = hp.Choice(\"optimizer\", values=[\"sgd\", \"adam\"])\n",
    "    if optimizer == \"sgd\":\n",
    "        optimizer = SGD(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Flatten())\n",
    "    for _ in range(n_hidden):\n",
    "        model.add(Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        optimizer=optimizer,\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyClassificationHyperModel(HyperModel):\n",
    "\n",
    "    def build(self, hp):\n",
    "        return build_model(hp)\n",
    "\n",
    "    def fit(self, hp, model, X, y, **kwargs):\n",
    "        if hp.Boolean(\"normalize\"):\n",
    "            norm_layer = Normalization()\n",
    "            X = norm_layer(X)\n",
    "        batch_size = hp.Int(\"batch_size\", min_value=16, max_value=128, default=32, step=16)\n",
    "        return model.fit(X, y, batch_size=batch_size, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "5                 |5                 |n_hidden\n",
      "25                |25                |n_neurons\n",
      "0.00065625        |0.00065625        |learning_rate\n",
      "sgd               |sgd               |optimizer\n",
      "\n",
      "Epoch 1/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.1098 - loss: 2.3106 - val_accuracy: 0.1497 - val_loss: 2.2797\n",
      "Epoch 2/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.1697 - loss: 2.2695 - val_accuracy: 0.2031 - val_loss: 2.2286\n",
      "Epoch 3/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.2077 - loss: 2.2095 - val_accuracy: 0.2404 - val_loss: 2.1426\n",
      "Epoch 4/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.2688 - loss: 2.1172 - val_accuracy: 0.3319 - val_loss: 2.0434\n",
      "Epoch 5/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.3535 - loss: 2.0130 - val_accuracy: 0.4093 - val_loss: 1.9111\n",
      "Epoch 6/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.4393 - loss: 1.8613 - val_accuracy: 0.5092 - val_loss: 1.6845\n",
      "Epoch 7/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.5253 - loss: 1.6039 - val_accuracy: 0.5838 - val_loss: 1.3229\n",
      "Epoch 8/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.6150 - loss: 1.2312 - val_accuracy: 0.6873 - val_loss: 1.0053\n",
      "Epoch 9/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.7089 - loss: 0.9591 - val_accuracy: 0.7349 - val_loss: 0.8351\n",
      "Epoch 10/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.7518 - loss: 0.8113 - val_accuracy: 0.7759 - val_loss: 0.7274\n",
      "Epoch 11/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.7830 - loss: 0.7130 - val_accuracy: 0.8032 - val_loss: 0.6504\n",
      "Epoch 12/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8061 - loss: 0.6406 - val_accuracy: 0.8200 - val_loss: 0.5919\n",
      "Epoch 13/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8246 - loss: 0.5843 - val_accuracy: 0.8368 - val_loss: 0.5458\n",
      "Epoch 14/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8393 - loss: 0.5396 - val_accuracy: 0.8517 - val_loss: 0.5085\n",
      "Epoch 15/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8503 - loss: 0.5033 - val_accuracy: 0.8621 - val_loss: 0.4775\n",
      "Epoch 16/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8593 - loss: 0.4732 - val_accuracy: 0.8696 - val_loss: 0.4512\n",
      "Epoch 17/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8685 - loss: 0.4478 - val_accuracy: 0.8743 - val_loss: 0.4290\n",
      "Epoch 18/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8744 - loss: 0.4262 - val_accuracy: 0.8809 - val_loss: 0.4101\n",
      "Epoch 19/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8803 - loss: 0.4077 - val_accuracy: 0.8851 - val_loss: 0.3940\n",
      "Epoch 20/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8854 - loss: 0.3918 - val_accuracy: 0.8901 - val_loss: 0.3799\n",
      "Epoch 21/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8898 - loss: 0.3778 - val_accuracy: 0.8941 - val_loss: 0.3675\n",
      "Epoch 22/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8938 - loss: 0.3653 - val_accuracy: 0.8967 - val_loss: 0.3567\n",
      "Epoch 23/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8977 - loss: 0.3543 - val_accuracy: 0.8998 - val_loss: 0.3469\n",
      "Epoch 24/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9004 - loss: 0.3444 - val_accuracy: 0.9017 - val_loss: 0.3382\n",
      "Epoch 25/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9024 - loss: 0.3356 - val_accuracy: 0.9041 - val_loss: 0.3302\n",
      "Epoch 26/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9044 - loss: 0.3274 - val_accuracy: 0.9054 - val_loss: 0.3227\n",
      "Epoch 27/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9067 - loss: 0.3198 - val_accuracy: 0.9079 - val_loss: 0.3159\n",
      "Epoch 28/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9090 - loss: 0.3128 - val_accuracy: 0.9098 - val_loss: 0.3095\n",
      "Epoch 29/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9113 - loss: 0.3062 - val_accuracy: 0.9108 - val_loss: 0.3036\n",
      "Epoch 30/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9126 - loss: 0.3000 - val_accuracy: 0.9124 - val_loss: 0.2980\n",
      "Epoch 31/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9148 - loss: 0.2942 - val_accuracy: 0.9129 - val_loss: 0.2927\n",
      "Epoch 32/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9165 - loss: 0.2885 - val_accuracy: 0.9145 - val_loss: 0.2876\n",
      "Epoch 33/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9178 - loss: 0.2832 - val_accuracy: 0.9155 - val_loss: 0.2829\n",
      "Epoch 34/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9190 - loss: 0.2781 - val_accuracy: 0.9172 - val_loss: 0.2783\n",
      "Epoch 35/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9203 - loss: 0.2732 - val_accuracy: 0.9199 - val_loss: 0.2741\n",
      "Epoch 36/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9213 - loss: 0.2686 - val_accuracy: 0.9222 - val_loss: 0.2699\n",
      "Epoch 37/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9228 - loss: 0.2642 - val_accuracy: 0.9226 - val_loss: 0.2660\n",
      "Epoch 38/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9243 - loss: 0.2599 - val_accuracy: 0.9244 - val_loss: 0.2621\n",
      "Epoch 39/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9256 - loss: 0.2559 - val_accuracy: 0.9251 - val_loss: 0.2585\n",
      "Epoch 40/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9266 - loss: 0.2519 - val_accuracy: 0.9261 - val_loss: 0.2550\n",
      "Epoch 41/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9274 - loss: 0.2482 - val_accuracy: 0.9281 - val_loss: 0.2516\n",
      "Epoch 42/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9281 - loss: 0.2445 - val_accuracy: 0.9279 - val_loss: 0.2484\n",
      "Epoch 43/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9295 - loss: 0.2410 - val_accuracy: 0.9282 - val_loss: 0.2453\n",
      "Epoch 44/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9310 - loss: 0.2376 - val_accuracy: 0.9292 - val_loss: 0.2424\n",
      "Epoch 45/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9317 - loss: 0.2342 - val_accuracy: 0.9302 - val_loss: 0.2395\n",
      "Epoch 46/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9326 - loss: 0.2310 - val_accuracy: 0.9315 - val_loss: 0.2367\n",
      "Epoch 47/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9339 - loss: 0.2278 - val_accuracy: 0.9319 - val_loss: 0.2340\n",
      "Epoch 48/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9349 - loss: 0.2248 - val_accuracy: 0.9331 - val_loss: 0.2315\n",
      "Epoch 49/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9358 - loss: 0.2217 - val_accuracy: 0.9336 - val_loss: 0.2290\n",
      "Epoch 50/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9369 - loss: 0.2188 - val_accuracy: 0.9346 - val_loss: 0.2267\n",
      "Epoch 51/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9380 - loss: 0.2160 - val_accuracy: 0.9351 - val_loss: 0.2244\n",
      "Epoch 52/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9385 - loss: 0.2133 - val_accuracy: 0.9350 - val_loss: 0.2223\n",
      "Epoch 53/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9390 - loss: 0.2106 - val_accuracy: 0.9356 - val_loss: 0.2202\n",
      "Epoch 54/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9393 - loss: 0.2080 - val_accuracy: 0.9363 - val_loss: 0.2181\n",
      "Epoch 55/100\n",
      "\u001b[1m 159/1563\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.9402 - loss: 0.1977"
     ]
    }
   ],
   "source": [
    "random_search_tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=5,\n",
    "    seed=RANDOM_STATE,\n",
    "    overwrite=True,\n",
    "    directory=\"my_mnist\",\n",
    "    project_name=\"my_rnd_search\",\n",
    ")\n",
    "random_search_tuner.search(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(x_valid, y_valid),\n",
    "    callbacks=[EarlyStopping(patience=2), TensorBoard(get_run_logdir())],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperband_tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    seed=RANDOM_STATE,\n",
    "    max_epochs=10,\n",
    "    factor=3,\n",
    "    hyperband_iterations=2,\n",
    "    overwrite=True,\n",
    "    directory=\"my_mnist\",\n",
    "    project_name=\"hyperband\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Complete [00h 00m 19s]\n",
      "val_accuracy: 0.43540000915527344\n",
      "\n",
      "Best val_accuracy So Far: 0.43540000915527344\n",
      "Total elapsed time: 00h 00m 41s\n",
      "\n",
      "Search: Running Trial #3\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "5                 |8                 |n_hidden\n",
      "221               |263               |n_neurons\n",
      "0.0090513         |0.0012483         |learning_rate\n",
      "adam              |sgd               |optimizer\n",
      "2                 |2                 |tuner/epochs\n",
      "0                 |0                 |tuner/initial_epoch\n",
      "2                 |2                 |tuner/bracket\n",
      "0                 |0                 |tuner/round\n",
      "\n",
      "Epoch 1/2\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.8236 - loss: 0.6204 - val_accuracy: 0.9181 - val_loss: 0.3215\n",
      "Epoch 2/2\n",
      "\u001b[1m 852/1563\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9298 - loss: 0.3065"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m tensorboard_cb \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mTensorBoard(root_logdir)\n\u001b[1;32m      3\u001b[0m early_stopping_cb \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mhyperband_tuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_valid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping_cb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensorboard_cb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:234\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_end(trial)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:274\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m         trial\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m trial_module\u001b[38;5;241m.\u001b[39mTrialStatus\u001b[38;5;241m.\u001b[39mCOMPLETED\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:239\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[0;32m--> 239\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_trial(trial\u001b[38;5;241m.\u001b[39mtrial_id)\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mexists(\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m    242\u001b[0m     ):\n\u001b[1;32m    243\u001b[0m         \u001b[38;5;66;03m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;66;03m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;66;03m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[1;32m    246\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe use case of calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    248\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    254\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    255\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/keras_tuner/src/tuners/hyperband.py:427\u001b[0m, in \u001b[0;36mHyperband.run_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    425\u001b[0m     fit_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m hp\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtuner/epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    426\u001b[0m     fit_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m hp\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtuner/initial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py:314\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(model_checkpoint)\n\u001b[1;32m    313\u001b[0m     copied_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m callbacks\n\u001b[0;32m--> 314\u001b[0m     obj_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_and_fit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcopied_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m     histories\u001b[38;5;241m.\u001b[39mappend(obj_value)\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py:233\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m hp \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39mhyperparameters\n\u001b[1;32m    232\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_build(hp)\n\u001b[0;32m--> 233\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhypermodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m# Save the build config for model loading later.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmulti_backend():\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/keras_tuner/src/engine/hypermodel.py:149\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    126\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:321\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    319\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m    320\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m--> 321\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/keras/src/callbacks/callback_list.py:178\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_async_dispatch(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_train_batch_end, batch, logs)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_on_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/keras/src/callbacks/callback_list.py:202\u001b[0m, in \u001b[0;36mCallbackList._on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    200\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m--> 202\u001b[0m     \u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/keras/src/callbacks/tensorboard.py:456\u001b[0m, in \u001b[0;36mTensorBoard.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(logs, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m logs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 456\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscalar\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch_\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_step\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_trace:\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/tensorflow/python/summary/tb_summary.py:303\u001b[0m, in \u001b[0;36mscalar\u001b[0;34m(name, data, step, description)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    302\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m TBNotInstalledError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.summary.scalar\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[0;32m--> 303\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mscalar_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdescription\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/tensorboard/plugins/scalar/summary_v2.py:88\u001b[0m, in \u001b[0;36mscalar\u001b[0;34m(name, data, step, description)\u001b[0m\n\u001b[1;32m     83\u001b[0m summary_scope \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28mgetattr\u001b[39m(tf\u001b[38;5;241m.\u001b[39msummary\u001b[38;5;241m.\u001b[39mexperimental, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary_scope\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m tf\u001b[38;5;241m.\u001b[39msummary\u001b[38;5;241m.\u001b[39msummary_scope\n\u001b[1;32m     86\u001b[0m )\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m summary_scope(name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscalar_summary\u001b[39m\u001b[38;5;124m\"\u001b[39m, values\u001b[38;5;241m=\u001b[39m[data, step]) \u001b[38;5;28;01mas\u001b[39;00m (tag, _):\n\u001b[0;32m---> 88\u001b[0m     \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdebugging\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_scalar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39msummary\u001b[38;5;241m.\u001b[39mwrite(\n\u001b[1;32m     90\u001b[0m         tag\u001b[38;5;241m=\u001b[39mtag,\n\u001b[1;32m     91\u001b[0m         tensor\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mcast(data, tf\u001b[38;5;241m.\u001b[39mfloat32),\n\u001b[1;32m     92\u001b[0m         step\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m     93\u001b[0m         metadata\u001b[38;5;241m=\u001b[39msummary_metadata,\n\u001b[1;32m     94\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/tensorflow/python/util/dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1262\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/tensorflow/python/ops/check_ops.py:2181\u001b[0m, in \u001b[0;36massert_scalar_v2\u001b[0;34m(tensor, message, name)\u001b[0m\n\u001b[1;32m   2161\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdebugging.assert_scalar\u001b[39m\u001b[38;5;124m'\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m   2162\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39madd_dispatch_support\n\u001b[1;32m   2163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21massert_scalar_v2\u001b[39m(tensor, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   2164\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Asserts that the given `tensor` is a scalar.\u001b[39;00m\n\u001b[1;32m   2165\u001b[0m \n\u001b[1;32m   2166\u001b[0m \u001b[38;5;124;03m  This function raises `ValueError` unless it can be certain that the given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2179\u001b[0m \u001b[38;5;124;03m      unknown.\u001b[39;00m\n\u001b[1;32m   2180\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2181\u001b[0m   \u001b[43massert_scalar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/tensorflow/python/util/dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1262\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/tensorflow/python/ops/check_ops.py:2207\u001b[0m, in \u001b[0;36massert_scalar\u001b[0;34m(tensor, name, message)\u001b[0m\n\u001b[1;32m   2188\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Asserts that the given `tensor` is a scalar (i.e. zero-dimensional).\u001b[39;00m\n\u001b[1;32m   2189\u001b[0m \n\u001b[1;32m   2190\u001b[0m \u001b[38;5;124;03mThis function raises `ValueError` unless it can be certain that the given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2204\u001b[0m \u001b[38;5;124;03m    unknown.\u001b[39;00m\n\u001b[1;32m   2205\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2206\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(name, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124massert_scalar\u001b[39m\u001b[38;5;124m'\u001b[39m, [tensor]) \u001b[38;5;28;01mas\u001b[39;00m name_scope:\n\u001b[0;32m-> 2207\u001b[0m   tensor \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname_scope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2208\u001b[0m   shape \u001b[38;5;241m=\u001b[39m tensor\u001b[38;5;241m.\u001b[39mget_shape()\n\u001b[1;32m   2209\u001b[0m   message \u001b[38;5;241m=\u001b[39m _message_prefix(message)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/tensorflow/python/framework/ops.py:732\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;66;03m# TODO(b/142518781): Fix all call-sites and remove redundant arg\u001b[39;00m\n\u001b[1;32m    731\u001b[0m preferred_dtype \u001b[38;5;241m=\u001b[39m preferred_dtype \u001b[38;5;129;01mor\u001b[39;00m dtype_hint\n\u001b[0;32m--> 732\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor_conversion_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreferred_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccepted_result_types\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:234\u001b[0m, in \u001b[0;36mconvert\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[1;32m    225\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    226\u001b[0m           _add_error_prefix(\n\u001b[1;32m    227\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversion_func\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    231\u001b[0m               name\u001b[38;5;241m=\u001b[39mname))\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 234\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m    237\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/tensorflow/python/framework/constant_tensor_conversion.py:29\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m constant_op  \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[1;32m     28\u001b[0m _ \u001b[38;5;241m=\u001b[39m as_ref\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/tensorflow/python/ops/weak_tensor_ops.py:142\u001b[0m, in \u001b[0;36mweak_tensor_binary_op_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    141\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    144\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/tensorflow/python/framework/constant_op.py:276\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(\n\u001b[1;32m    179\u001b[0m     value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    180\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[ops\u001b[38;5;241m.\u001b[39mOperation, ops\u001b[38;5;241m.\u001b[39m_EagerTensorBase]:\n\u001b[1;32m    181\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 276\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/tensorflow/python/framework/constant_op.py:289\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    288\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 289\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    291\u001b[0m const_tensor \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39m_create_graph_constant(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    292\u001b[0m     value, dtype, shape, name, verify_shape, allow_broadcast\n\u001b[1;32m    293\u001b[0m )\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m const_tensor\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/tensorflow/python/framework/constant_op.py:301\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_eager_impl\u001b[39m(\n\u001b[1;32m    298\u001b[0m     ctx, value, dtype, shape, verify_shape\n\u001b[1;32m    299\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ops\u001b[38;5;241m.\u001b[39m_EagerTensorBase:\n\u001b[1;32m    300\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 301\u001b[0m   t \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/tensorflow/python/framework/constant_op.py:108\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    106\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    107\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hyperband_tuner.search(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=10,\n",
    "    validation_data=(x_valid, y_valid),\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=2),\n",
    "        TensorBoard(Path(hyperband_tuner.project_dir) / \"tensorboard\"),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0054 summary\n",
      "Hyperparameters:\n",
      "n_hidden: 7\n",
      "n_neurons: 159\n",
      "learning_rate: 0.001989751755243559\n",
      "optimizer: adam\n",
      "tuner/epochs: 10\n",
      "tuner/initial_epoch: 4\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0052\n",
      "Score: 0.9757999777793884\n"
     ]
    }
   ],
   "source": [
    "best_trial = hyperband_tuner.oracle.get_best_trials(num_trials=1)[0]\n",
    "best_trial.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9811 - loss: 0.0855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f5d5660b350>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = hyperband_tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "best_model.fit(x_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9687 - loss: 0.1282\n",
      "test loss, test acc: [0.11546468734741211, 0.9714999794960022]\n"
     ]
    }
   ],
   "source": [
    "results = best_model.evaluate(x_test, y_test)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 Complete [00h 00m 42s]\n",
      "val_accuracy: 0.9679999947547913\n",
      "\n",
      "Best val_accuracy So Far: 0.9782000184059143\n",
      "Total elapsed time: 01h 36m 07s\n"
     ]
    }
   ],
   "source": [
    "bayesian_opt_tuner = BayesianOptimization(\n",
    "    MyClassificationHyperModel(),\n",
    "    objective=\"val_accuracy\",\n",
    "    seed=42,\n",
    "    max_trials=20,\n",
    "    alpha=1e-4,\n",
    "    beta=2.6,\n",
    "    overwrite=True,\n",
    "    directory=\"my_mnist\",\n",
    "    project_name=\"bayesian_opt\",\n",
    ")\n",
    "bayesian_opt_tuner.search(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(x_valid, y_valid),\n",
    "    callbacks=[EarlyStopping(patience=2), TensorBoard(Path(bayesian_opt_tuner.project_dir) / \"tensorboard\")],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 07 summary\n",
      "Hyperparameters:\n",
      "n_hidden: 3\n",
      "n_neurons: 319\n",
      "learning_rate: 0.005389284745949777\n",
      "optimizer: sgd\n",
      "normalize: True\n",
      "batch_size: 32\n",
      "Score: 0.9782000184059143\n"
     ]
    }
   ],
   "source": [
    "best_trial = bayesian_opt_tuner.oracle.get_best_trials(num_trials=1)[0]\n",
    "best_trial.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trial 02 summary\n",
    "Hyperparameters:\n",
    "n_hidden: 8\n",
    "n_neurons: 365\n",
    "learning_rate: 0.006718710759425462\n",
    "optimizer: sgd\n",
    "normalize: True\n",
    "batch_size: 16\n",
    "Score: 0.972599983215332"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9942 - loss: 0.0247\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9952 - loss: 0.0221\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9959 - loss: 0.0199\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9964 - loss: 0.0182\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9967 - loss: 0.0167\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9972 - loss: 0.0155\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9976 - loss: 0.0143\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9979 - loss: 0.0133\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9982 - loss: 0.0124\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9985 - loss: 0.0116\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f24bc274b90>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = bayesian_opt_tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "best_model.fit(x_train_full, y_train_full, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9744 - loss: 0.0882\n",
      "test loss, test acc: [0.07178439199924469, 0.979200005531311]\n"
     ]
    }
   ],
   "source": [
    "results = best_model.evaluate(x_test, y_test)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "313/313 ━━━━━━━━━━━━━━━━━━━━ 1s 3ms/step - accuracy: 0.9744 - loss: 0.0878\n",
    "test loss, test acc: [0.07178439199924469, 0.979200005531311]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Launching TensorBoard..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
