{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Variational Auto-Encoder\n",
    "\n",
    "_Exercise: Train a variational autoencoder on the image dataset of your choice, and use it to generate images. Alternatively, you can try to find an unlabeled dataset that you are interested in and see if you can generate new samples._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 17:34:56.100455: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744385696.141948  480674 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744385696.157457  480674 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-11 17:34:56.246155: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras import (\n",
    "    layers,\n",
    "    datasets,\n",
    "    metrics,\n",
    "    optimizers,\n",
    "    callbacks,\n",
    "    Model,\n",
    "    losses,\n",
    "    Sequential,\n",
    "    Input\n",
    ")\n",
    "import keras_tuner as kt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score, silhouette_score\n",
    "\n",
    "from skimage.metrics import structural_similarity\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Set the seed using keras.utils.set_random_seed. This will set:\n",
    "# 1) `numpy` seed\n",
    "# 2) backend random seed\n",
    "# 3) `python` random seed\n",
    "keras.utils.set_random_seed(42)\n",
    "\n",
    "# If using TensorFlow, this will make GPU ops as deterministic as possible,\n",
    "# but it will affect the overall performance, so be mindful of that.\n",
    "tf.config.experimental.enable_op_determinism()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 28\n",
    "IMG_HEIGHT = 28\n",
    "IMG_CHANNELS = 1\n",
    "INPUT_SHAPE = (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
    "FLAT_SHAPE = IMG_HEIGHT * IMG_WIDTH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 25\n",
    "EARLY_STOPPING_PATIENCE = 5\n",
    "BATCH_SIZE = 128\n",
    "OPTIMIZER = \"adam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_DIM_OPTIONS = [8, 16, 32, 64, 128]\n",
    "KL_WEIGHT_OPTIONS = [1.0, 3.0, 5.0, 10.0] # [0.1, 0.2, 0.5, 1.0, 3.0, 5.0]\n",
    "LEARNING_RATE_OPTIONS = [5e-3, 1e-3, 5e-4, 1e-4, 5e-5, 1e-5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/27\n"
     ]
    }
   ],
   "source": [
    "PARENT_LOGS_PATH = \"logs\"\n",
    "ITERATION = 27\n",
    "\n",
    "current_logs_path = os.path.join(PARENT_LOGS_PATH, str(ITERATION))\n",
    "os.makedirs(current_logs_path, exist_ok=True)\n",
    "print(current_logs_path)\n",
    "\n",
    "logs = {\n",
    "    \"iteration\" : ITERATION,\n",
    "    \"summary\" : \"Hyperparameter tuning before fitting\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs[\"EPOCHS\"] = EPOCHS\n",
    "logs[\"EARLY_STOPPING_PATIENCE\"] = EARLY_STOPPING_PATIENCE\n",
    "logs[\"BATCH_SIZE\"] = BATCH_SIZE\n",
    "logs[\"OPTIMIZER\"] = OPTIMIZER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(array):\n",
    "    \"\"\"Normalize and reshape images.\"\"\"\n",
    "    array = array.astype(\"float32\") / 255.0\n",
    "    array = np.reshape(array, (len(array), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "    return array\n",
    "\n",
    "def deprocess(array):\n",
    "    \"\"\"Denormalize images.\"\"\"\n",
    "    array = np.reshape(array, (len(array), IMG_HEIGHT, IMG_WIDTH))\n",
    "    array = array * 255.0\n",
    "    array = array.astype(\"uint8\")\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "x_test shape: (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()\n",
    "\n",
    "x_train = preprocess(x_train)\n",
    "x_test = preprocess(x_test)\n",
    "\n",
    "print(f\"x_train shape: {x_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if dataset is not evenly distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 6742, 7: 6265, 3: 6131, 2: 5958, 9: 5949, 0: 5923, 6: 5918, 8: 5851, 4: 5842, 5: 5421})\n",
      "{5: 0.09035, 0: 0.09871666666666666, 4: 0.09736666666666667, 1: 0.11236666666666667, 9: 0.09915, 2: 0.0993, 3: 0.10218333333333333, 6: 0.09863333333333334, 7: 0.10441666666666667, 8: 0.09751666666666667}\n",
      "Gini coefficient for class distribution of train images: 0.027326666666666676\n"
     ]
    }
   ],
   "source": [
    "class_distribution = Counter(y_train)\n",
    "print(class_distribution)\n",
    "\n",
    "norm_labels_distr = {k: v / len(y_train) for k, v in class_distribution.items()}\n",
    "print(norm_labels_distr)\n",
    "\n",
    "def gini_coefficient(probabilities):\n",
    "    probabilities = np.sort(probabilities)\n",
    "    n = len(probabilities)\n",
    "    index = np.arange(1, n + 1)\n",
    "    return (np.sum((2 * index - n - 1) * probabilities)) / (n * np.sum(probabilities))\n",
    "\n",
    "gini = gini_coefficient(list(norm_labels_distr.values()))\n",
    "print(f\"Gini coefficient for class distribution of train images: {gini}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Variational Auto-Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        mean, log_var = inputs\n",
    "        return tf.random.normal(tf.shape(log_var)) * tf.exp(log_var / 2) + mean "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_encoder(latent_dim):\n",
    "    encoder_inputs = Input(shape=INPUT_SHAPE, name=\"encoder_input\")\n",
    "    Z = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
    "    Z = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(Z)\n",
    "    Z = layers.Flatten()(Z)\n",
    "    # Intermediate dense layer\n",
    "    Z = layers.Dense(16, activation=\"relu\")(Z)\n",
    "    # Latent space parameters\n",
    "    codings_mean = layers.Dense(latent_dim, name=\"z_mean\")(Z)\n",
    "    codings_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(Z)\n",
    "    codings = Sampling()([codings_mean, codings_log_var])\n",
    "    # Instantiate Encoder model (useful separately)\n",
    "    variational_encoder = Model(\n",
    "        inputs=encoder_inputs, outputs=[codings_mean, codings_log_var, codings], name=\"encoder\")\n",
    "    return variational_encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_decoder(latent_dim):\n",
    "    decoder_inputs = Input(shape=(latent_dim,), name=\"decoder_input\")\n",
    "    # Map latent vector back to the shape before Flatten in encoder\n",
    "    # The shape before Flatten was (7, 7, 64) because 28 -> 14 (stride 2) -> 7 (stride 2)\n",
    "    Z = layers.Dense(7 * 7 * 64, activation=\"relu\")(decoder_inputs)\n",
    "    Z = layers.Reshape((7, 7, 64))(Z)\n",
    "    # Use Conv2DTranspose (deconvolution) to upsample\n",
    "    Z = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(Z)\n",
    "    Z = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(Z)\n",
    "    # Final layer to reconstruct the image\n",
    "    decoder_outputs = layers.Conv2DTranspose(IMG_CHANNELS, 3, activation=\"sigmoid\", padding=\"same\", name=\"decoder_output\")(Z)\n",
    "    # Instantiate Decoder model (useful separately for generation)\n",
    "    variational_decoder = Model(decoder_inputs, decoder_outputs, name=\"decoder\")\n",
    "    return variational_decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAELossLayer(layers.Layer):\n",
    "    def __init__(self, beta, **kwargs):\n",
    "        super(VAELossLayer, self).__init__(**kwargs)\n",
    "        self.beta = beta\n",
    "        self.reconstruction_loss_tracker = metrics.Mean(name=\"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def call(self, inputs, codings_mean, codings_log_var, reconstructions):\n",
    "        # 1. Reconstruction Loss\n",
    "        reconstruction_loss = tf.reduce_mean(\n",
    "            losses.binary_crossentropy(\n",
    "                tf.reshape(inputs, [-1, FLAT_SHAPE]),\n",
    "                tf.reshape(reconstructions, [-1, FLAT_SHAPE]),\n",
    "            )\n",
    "        )\n",
    "        reconstruction_loss *= tf.cast(tf.reduce_prod(inputs.shape[1:]), tf.float32) # Scale for pixel-wise loss\n",
    "\n",
    "        # 2. KL Divergence Loss\n",
    "        kl_loss = -0.5 * tf.reduce_sum(\n",
    "            1 + codings_log_var - tf.square(codings_mean) - tf.exp(codings_log_var),\n",
    "            axis=-1\n",
    "        )\n",
    "        kl_loss = tf.reduce_mean(kl_loss)  # Average over the batch\n",
    "\n",
    "        # 3. Total VAE Loss\n",
    "        total_loss = reconstruction_loss + self.beta * kl_loss\n",
    "\n",
    "        # Add the total loss to the model\n",
    "        self.add_loss(total_loss)\n",
    "\n",
    "        # Add loss values to metrics for monitoring\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "\n",
    "        return reconstructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational Auto-Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vae(hyperparams):\n",
    "    hp_latent_dims = hyperparams.Choice(\"latent_dim\", LATENT_DIM_OPTIONS)\n",
    "    variational_encoder = build_encoder(hp_latent_dims)\n",
    "    encoder_inputs = variational_encoder.input\n",
    "    variational_decoder = build_decoder(hp_latent_dims)\n",
    "\n",
    "    # Get the output of the decoder by passing the sampled `z` from the encoder\n",
    "    codings_mean, codings_log_var, codings = variational_encoder(encoder_inputs)\n",
    "    reconstructions = variational_decoder(codings)\n",
    "    \n",
    "    hp_kl_weight = hyperparams.Choice(\"kl_weight\", KL_WEIGHT_OPTIONS)\n",
    "    outputs = VAELossLayer(beta=hp_kl_weight)(\n",
    "        encoder_inputs, codings_mean, codings_log_var, reconstructions\n",
    "    )\n",
    "\n",
    "    variational_ae = Model(inputs=encoder_inputs, outputs=outputs)\n",
    "    hp_learning_rate = hyperparams.Choice(\"learning_rate\", LEARNING_RATE_OPTIONS)\n",
    "    variational_ae.compile(optimizer=optimizers.Adam(learning_rate=hp_learning_rate))\n",
    "\n",
    "    return variational_ae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 24 Complete [00h 03m 21s]\n",
      "val_loss: 165.30984497070312\n",
      "\n",
      "Best val_loss So Far: 104.67401885986328\n",
      "Total elapsed time: 01h 02m 06s\n",
      "\n",
      "Search: Running Trial #25\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "64                |64                |latent_dim\n",
      "0.1               |0.1               |kl_weight\n",
      "0.0001            |0.0001            |learning_rate\n",
      "25                |9                 |tuner/epochs\n",
      "9                 |0                 |tuner/initial_epoch\n",
      "1                 |1                 |tuner/bracket\n",
      "1                 |0                 |tuner/round\n",
      "0022              |None              |tuner/trial_id\n",
      "\n",
      "Epoch 10/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 18:00:53.146350: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m468/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - kl_loss: 89.8004 - loss: 105.4019 - reconstruction_loss: 96.4218"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 18:01:16.987728: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 47ms/step - kl_loss: 89.8001 - loss: 105.4001 - reconstruction_loss: 96.4201 - val_kl_loss: 90.9125 - val_loss: 103.6446 - val_reconstruction_loss: 94.5067\n",
      "Epoch 11/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 47ms/step - kl_loss: 89.3106 - loss: 104.3857 - reconstruction_loss: 95.4546 - val_kl_loss: 90.2468 - val_loss: 102.8180 - val_reconstruction_loss: 93.7380\n",
      "Epoch 12/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 45ms/step - kl_loss: 88.8199 - loss: 103.5497 - reconstruction_loss: 94.6678 - val_kl_loss: 90.4531 - val_loss: 102.1398 - val_reconstruction_loss: 93.0484\n",
      "Epoch 13/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 46ms/step - kl_loss: 88.2706 - loss: 102.7310 - reconstruction_loss: 93.9039 - val_kl_loss: 88.9372 - val_loss: 101.4218 - val_reconstruction_loss: 92.4765\n",
      "Epoch 14/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 47ms/step - kl_loss: 87.5616 - loss: 102.1084 - reconstruction_loss: 93.3523 - val_kl_loss: 88.3616 - val_loss: 100.8850 - val_reconstruction_loss: 91.9917\n",
      "Epoch 15/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 48ms/step - kl_loss: 86.9319 - loss: 101.4711 - reconstruction_loss: 92.7779 - val_kl_loss: 87.4394 - val_loss: 100.4782 - val_reconstruction_loss: 91.6765\n",
      "Epoch 16/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 48ms/step - kl_loss: 86.2121 - loss: 100.8948 - reconstruction_loss: 92.2736 - val_kl_loss: 86.9583 - val_loss: 99.8919 - val_reconstruction_loss: 91.1373\n",
      "Epoch 17/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 48ms/step - kl_loss: 85.7455 - loss: 100.3919 - reconstruction_loss: 91.8173 - val_kl_loss: 85.8249 - val_loss: 99.4364 - val_reconstruction_loss: 90.8032\n",
      "Epoch 18/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 46ms/step - kl_loss: 84.8871 - loss: 99.8886 - reconstruction_loss: 91.3999 - val_kl_loss: 85.3361 - val_loss: 99.0688 - val_reconstruction_loss: 90.4552\n",
      "Epoch 19/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 47ms/step - kl_loss: 84.3817 - loss: 99.4950 - reconstruction_loss: 91.0569 - val_kl_loss: 84.6626 - val_loss: 98.5881 - val_reconstruction_loss: 90.0649\n",
      "Epoch 20/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 48ms/step - kl_loss: 83.7591 - loss: 99.0875 - reconstruction_loss: 90.7116 - val_kl_loss: 84.2002 - val_loss: 98.2109 - val_reconstruction_loss: 89.7284\n",
      "Epoch 21/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 47ms/step - kl_loss: 82.9810 - loss: 98.6861 - reconstruction_loss: 90.3880 - val_kl_loss: 83.3741 - val_loss: 97.8742 - val_reconstruction_loss: 89.4642\n",
      "Epoch 22/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 48ms/step - kl_loss: 82.3391 - loss: 98.2789 - reconstruction_loss: 90.0450 - val_kl_loss: 82.9673 - val_loss: 97.4872 - val_reconstruction_loss: 89.1444\n",
      "Epoch 23/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 48ms/step - kl_loss: 81.7524 - loss: 97.9680 - reconstruction_loss: 89.7928 - val_kl_loss: 82.2320 - val_loss: 97.1962 - val_reconstruction_loss: 88.9080\n",
      "Epoch 24/25\n",
      "\u001b[1m111/469\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 44ms/step - kl_loss: 81.1512 - loss: 97.9591 - reconstruction_loss: 89.8440"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 13\u001b[0m\n\u001b[1;32m      1\u001b[0m tuner \u001b[38;5;241m=\u001b[39m kt\u001b[38;5;241m.\u001b[39mHyperband(\n\u001b[1;32m      2\u001b[0m     build_vae,\n\u001b[1;32m      3\u001b[0m     objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m     project_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvae_exercise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      9\u001b[0m early_stopping_cb \u001b[38;5;241m=\u001b[39m callbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(\n\u001b[1;32m     10\u001b[0m     patience\u001b[38;5;241m=\u001b[39mEARLY_STOPPING_PATIENCE, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     11\u001b[0m )\n\u001b[0;32m---> 13\u001b[0m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping_cb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Get the optimal hyperparameters\u001b[39;00m\n\u001b[1;32m     23\u001b[0m best_hps \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mget_best_hyperparameters(num_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:234\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_end(trial)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:274\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m         trial\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m trial_module\u001b[38;5;241m.\u001b[39mTrialStatus\u001b[38;5;241m.\u001b[39mCOMPLETED\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:239\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[0;32m--> 239\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_trial(trial\u001b[38;5;241m.\u001b[39mtrial_id)\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mexists(\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m    242\u001b[0m     ):\n\u001b[1;32m    243\u001b[0m         \u001b[38;5;66;03m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;66;03m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;66;03m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[1;32m    246\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe use case of calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    248\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    254\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    255\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/keras_tuner/src/tuners/hyperband.py:427\u001b[0m, in \u001b[0;36mHyperband.run_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    425\u001b[0m     fit_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m hp\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtuner/epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    426\u001b[0m     fit_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m hp\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtuner/initial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py:314\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(model_checkpoint)\n\u001b[1;32m    313\u001b[0m     copied_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m callbacks\n\u001b[0;32m--> 314\u001b[0m     obj_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_and_fit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcopied_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m     histories\u001b[38;5;241m.\u001b[39mappend(obj_value)\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py:233\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m hp \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39mhyperparameters\n\u001b[1;32m    232\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_build(hp)\n\u001b[0;32m--> 233\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhypermodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m# Save the build config for model loading later.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmulti_backend():\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/keras_tuner/src/engine/hypermodel.py:149\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    126\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:372\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    370\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m    371\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m--> 372\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/keras/src/callbacks/callback_list.py:172\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_async_dispatch(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_train_batch_end, batch, logs)\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_on_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/keras/src/callbacks/callback_list.py:194\u001b[0m, in \u001b[0;36mCallbackList._on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    192\u001b[0m logs \u001b[38;5;241m=\u001b[39m python_utils\u001b[38;5;241m.\u001b[39mpythonify_logs(logs)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m--> 194\u001b[0m     \u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/keras/src/callbacks/progbar_logger.py:58\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 58\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/keras/src/callbacks/progbar_logger.py:95\u001b[0m, in \u001b[0;36mProgbarLogger._update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m=\u001b[39m batch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# One-indexed.\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 95\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprogbar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/keras/src/utils/progbar.py:163\u001b[0m, in \u001b[0;36mProgbar.update\u001b[0;34m(self, current, values, finalize)\u001b[0m\n\u001b[1;32m    160\u001b[0m info \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[k], \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    162\u001b[0m     avg \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mconvert_to_numpy(\n\u001b[0;32m--> 163\u001b[0m         \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m     )\n\u001b[1;32m    167\u001b[0m     avg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(avg)\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(avg) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1e-3\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/keras/src/backend/tensorflow/numpy.py:657\u001b[0m, in \u001b[0;36mmean\u001b[0;34m(x, axis, keepdims)\u001b[0m\n\u001b[1;32m    651\u001b[0m         gather_indices \u001b[38;5;241m=\u001b[39m [i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(rank) \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m axis]\n\u001b[1;32m    652\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mIndexedSlices(\n\u001b[1;32m    653\u001b[0m             tf\u001b[38;5;241m.\u001b[39mreduce_mean(x\u001b[38;5;241m.\u001b[39mvalues, axis\u001b[38;5;241m=\u001b[39maxis),\n\u001b[1;32m    654\u001b[0m             x\u001b[38;5;241m.\u001b[39mindices,\n\u001b[1;32m    655\u001b[0m             tf\u001b[38;5;241m.\u001b[39mgather(x\u001b[38;5;241m.\u001b[39mdense_shape, gather_indices, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m    656\u001b[0m         )\n\u001b[0;32m--> 657\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    658\u001b[0m ori_dtype \u001b[38;5;241m=\u001b[39m standardize_dtype(x\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    659\u001b[0m compute_dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mresult_type(x\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/keras/src/backend/tensorflow/core.py:140\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(x, dtype, sparse, ragged)\u001b[0m\n\u001b[1;32m    138\u001b[0m         x \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x)\n\u001b[1;32m    139\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcast(x, dtype)\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m dtype:\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, tf\u001b[38;5;241m.\u001b[39mSparseTensor):\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/tensorflow/python/util/dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1262\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/tensorflow/python/framework/tensor_conversion.py:161\u001b[0m, in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m\u001b[38;5;241m.\u001b[39mtf_export(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvert_to_tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m     97\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39madd_dispatch_support\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_to_tensor_v2_with_dispatch\u001b[39m(\n\u001b[1;32m     99\u001b[0m     value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype_hint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    100\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m tensor_lib\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    101\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Converts the given `value` to a `Tensor`.\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m  This function converts Python objects of various types to `Tensor`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03m    ValueError: If the `value` is a tensor not of given `dtype` in graph mode.\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 161\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconvert_to_tensor_v2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_hint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/tensorflow/python/framework/tensor_conversion.py:171\u001b[0m, in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Converts the given `value` to a `Tensor`.\"\"\"\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# preferred_dtype = preferred_dtype or dtype_hint\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor_conversion_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreferred_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_hint\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:234\u001b[0m, in \u001b[0;36mconvert\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[1;32m    225\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    226\u001b[0m           _add_error_prefix(\n\u001b[1;32m    227\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversion_func\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    231\u001b[0m               name\u001b[38;5;241m=\u001b[39mname))\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 234\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m    237\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/tensorflow/python/framework/constant_tensor_conversion.py:29\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m constant_op  \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[1;32m     28\u001b[0m _ \u001b[38;5;241m=\u001b[39m as_ref\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/tensorflow/python/ops/weak_tensor_ops.py:142\u001b[0m, in \u001b[0;36mweak_tensor_binary_op_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    141\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    144\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/tensorflow/python/framework/constant_op.py:276\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(\n\u001b[1;32m    179\u001b[0m     value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    180\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[ops\u001b[38;5;241m.\u001b[39mOperation, ops\u001b[38;5;241m.\u001b[39m_EagerTensorBase]:\n\u001b[1;32m    181\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 276\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/tensorflow/python/framework/constant_op.py:289\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    288\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 289\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    291\u001b[0m const_tensor \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39m_create_graph_constant(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    292\u001b[0m     value, dtype, shape, name, verify_shape, allow_broadcast\n\u001b[1;32m    293\u001b[0m )\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m const_tensor\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/tensorflow/python/framework/constant_op.py:301\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_eager_impl\u001b[39m(\n\u001b[1;32m    298\u001b[0m     ctx, value, dtype, shape, verify_shape\n\u001b[1;32m    299\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ops\u001b[38;5;241m.\u001b[39m_EagerTensorBase:\n\u001b[1;32m    300\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 301\u001b[0m   t \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/tensorflow/python/framework/constant_op.py:108\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    106\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    107\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(\n",
    "    build_vae,\n",
    "    objective=\"val_loss\",\n",
    "    max_epochs=EPOCHS,\n",
    "    directory=\"hp_tuning\",\n",
    "    project_name=\"vae_exercise\",\n",
    ")\n",
    "\n",
    "early_stopping_cb = callbacks.EarlyStopping(\n",
    "    patience=EARLY_STOPPING_PATIENCE, restore_best_weights=True, mode=\"min\"\n",
    ")\n",
    "\n",
    "tuner.search(\n",
    "    x_train,\n",
    "    x_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(x_test, x_test),\n",
    "    callbacks=[early_stopping_cb],\n",
    ")\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(best_hps.get_config())\n",
    "\n",
    "LATENT_DIM = best_hps.get(\"latent_dim\")\n",
    "KL_WEIGHT = best_hps.get(\"kl_weight\")\n",
    "LEARNING_RATE = best_hps.get(\"learning_rate\")\n",
    "\n",
    "logs[\"LATENT_DIM\"] = LATENT_DIM\n",
    "logs[\"KL_WEIGHT\"] = KL_WEIGHT\n",
    "logs[\"LEARNING_RATE\"] = LEARNING_RATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model with the optimal hyperparameters and train it on the data for 100 epochs\n",
    "model = build_vae(best_hps)\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    x_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(x_test, x_test),\n",
    "    callbacks=[early_stopping_cb],\n",
    ")\n",
    "\n",
    "best_epoch = early_stopping_cb.best_epoch\n",
    "print(f\"Best epoch: {best_epoch + 1}\")\n",
    "\n",
    "best_loss = history.history[\"val_loss\"][best_epoch]\n",
    "best_reconstruction_loss = history.history[\"val_reconstruction_loss\"][best_epoch]\n",
    "best_kl_loss = history.history[\"val_kl_loss\"][best_epoch]\n",
    "\n",
    "print(f\"Best total loss: {best_loss}, reconstruction loss: {best_reconstruction_loss}, kl_loss: {best_kl_loss}\")\n",
    "\n",
    "logs[\"LOSS\"] = best_loss\n",
    "logs[\"RECONSTRUCTION\"] = best_reconstruction_loss\n",
    "logs[\"KL\"] = best_kl_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variational_ae = model\n",
    "variational_encoder = model.get_layer(name=\"encoder\")\n",
    "variational_decoder = model.get_layer(name=\"decoder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the losses after training\n",
    "total_loss = history.history['loss']\n",
    "reconstruction_loss = history.history['reconstruction_loss']\n",
    "kl_loss = history.history['kl_loss']\n",
    "val_loss = history.history.get('val_loss')\n",
    "val_reconstruction_loss = history.history.get('val_reconstruction_loss')\n",
    "val_kl_loss = history.history.get('val_kl_loss')\n",
    "\n",
    "epochs_range = range(1, len(total_loss) + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(epochs_range, total_loss, label='Training Loss')\n",
    "if val_loss:\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.title('Total Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(epochs_range, reconstruction_loss, label='Training Reconstruction Loss')\n",
    "if val_reconstruction_loss:\n",
    "    plt.plot(epochs_range, val_reconstruction_loss, label='Validation Reconstruction Loss')\n",
    "plt.title('Reconstruction Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(epochs_range, kl_loss, label='Training KL Loss')\n",
    "if val_kl_loss:\n",
    "    plt.plot(epochs_range, val_kl_loss, label='Validation KL Loss')\n",
    "plt.title('KL Divergence Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(current_logs_path, \"learning_curves.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a very basic classifier on real MNIST data\n",
    "\n",
    "It will help us with evaluating reconstructed and generated images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_simple_classifier():\n",
    "    classifier = Sequential(\n",
    "        [\n",
    "            layers.Input(shape=INPUT_SHAPE),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(64, activation=\"relu\"),\n",
    "            layers.Dense(10, activation=\"softmax\"),  # 10 classes for MNIST digits\n",
    "        ]\n",
    "    )\n",
    "    classifier.compile(\n",
    "        optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return classifier\n",
    "\n",
    "\n",
    "classifier = build_simple_classifier()\n",
    "# Train on a subset (with more data accuracy/confidence is high even for not that clear images)\n",
    "classifier.fit(x_train[:10000], y_train[:10000], epochs=5, batch_size=128, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nEvaluating Reconstruction Quality...\")\n",
    "reconstructed_sample = variational_ae.predict(x_test)\n",
    "\n",
    "# Calculate Reconstruction Error (Proxy for visual quality)\n",
    "reconstruction_mse = np.mean((x_test - reconstructed_sample)**2)\n",
    "print(f\"Mean Squared Error (MSE) on {len(x_test)} test samples: {reconstruction_mse:.6f}\")\n",
    "# Lower MSE generally means better reconstruction fidelity.\n",
    "logs[\"MSE\"] = reconstruction_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean True Confidence\n",
    "\n",
    "How big of a confidence we get when predicting true labels on reconstructed images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier.predict(reconstructed_sample)\n",
    "true_confidence = [pred[y] for pred, y in zip(predictions, y_test)]\n",
    "mean_true_confidence = np.mean(true_confidence)\n",
    "print(f\"Mean confidence of true labels on reconstructed images: {mean_true_confidence}\")\n",
    "logs[\"MTC\"] = mean_true_confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Structural Similarity Index Measure (SSIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nEvaluating the structural similarity index measure (SSIM)...\")\n",
    "\n",
    "ssim_scores = []\n",
    "for i in range(len(x_test)):\n",
    "    ssim = structural_similarity(x_test[i], reconstructed_sample[i], data_range=1, win_size=7, channel_axis=-1)\n",
    "    ssim_scores.append(ssim)\n",
    "mean_ssim = np.mean(ssim_scores)\n",
    "print(f\"The mean structural similarity index measure (SSIM) on {len(x_test)} test samples: {mean_ssim}\")\n",
    "logs[\"MSSIM\"] = mean_ssim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Peak Signal-to-Noise Ratio (PSNR)\n",
    "\n",
    "Make sure that both input and output are normalized to (0,1), since we specify max_val as 1.0.\n",
    "\n",
    "E.g. without Sigmoid function, output was exceeding these bounds.\n",
    "\n",
    "- High PSNR (e.g., 40 dB or more)\n",
    "- Good PSNR (e.g., 30-40 dB)\n",
    "- Fair PSNR (e.g., 20-30 dB)\n",
    "- Low PSNR (e.g., below 20 dB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_value = np.max(x_test)\n",
    "min_value = np.min(x_test)\n",
    "\n",
    "print(f\"Max value: {max_value}\")\n",
    "print(f\"Min value: {min_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_value = np.max(reconstructed_sample)\n",
    "min_value = np.min(reconstructed_sample)\n",
    "\n",
    "print(f\"Max value: {max_value}\")\n",
    "print(f\"Min value: {min_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case reconstructed sample exceeds (0, 1) bounds\n",
    "cliped_reconstructed_sample = np.clip(reconstructed_sample, 0, 1)\n",
    "\n",
    "psnr = np.mean(tf.image.psnr(x_test, cliped_reconstructed_sample, max_val=1.0).numpy())\n",
    "print(f\"Peak Signal-to-Noise Ratio (PSNR) on {len(x_test)} test samples: {psnr}\")\n",
    "logs[\"PSNR\"] = psnr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot reconstructions for visual inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_reconstructions(model, images, labels, n_images=10):\n",
    "    reconstructions = np.clip(model.predict(images[:n_images]), 0, 1)\n",
    "    fig = plt.figure(figsize=(n_images * 1.5, 3))\n",
    "    for image_index in range(n_images):\n",
    "\n",
    "        plt.subplot(3, n_images, 1 + image_index)\n",
    "        sample_prediction = classifier.predict(np.expand_dims(reconstructions[image_index], axis=0))\n",
    "        sample_confidence = sample_prediction[0][labels[image_index]]\n",
    "        plt.text(0.15, 0, \"Conf: {:.4f}\".format(sample_confidence))\n",
    "\n",
    "        sample_ssmi = structural_similarity(images[image_index], reconstructions[image_index], data_range=1, channel_axis=-1)\n",
    "        plt.text(0.15, 0.5, \"SSIM: {:.4f}\".format(sample_ssmi))\n",
    "\n",
    "        sample_loss, _ = classifier.evaluate(\n",
    "            np.expand_dims(reconstructions[image_index], axis=0),\n",
    "            np.expand_dims(labels[image_index], axis=0),\n",
    "            verbose=0\n",
    "        )\n",
    "        plt.text(0.15, 1.0, \"Loss: {:.4f}\".format(sample_loss))\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(3, n_images, 1 + n_images + image_index)\n",
    "        plt.imshow(images[image_index], cmap=\"binary\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(3, n_images, 1 + 2 * n_images + image_index)\n",
    "        plt.imshow(reconstructions[image_index], cmap=\"binary\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "plot_reconstructions(variational_ae, images=x_test, labels=y_test)\n",
    "plt.savefig(os.path.join(current_logs_path, \"reconstructions.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Per-Class Reconstruction\n",
    "\n",
    "Analyze which digits reconstruct well vs. poorly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def analyze_per_class_reconstruction(encoder, decoder, data, labels, n_samples_per_class=10):\n",
    "\n",
    "encoder, decoder, data, labels, n_samples_per_class = variational_encoder, variational_decoder, x_test, y_test, 10\n",
    "\n",
    "\"\"\"Analyze reconstruction quality per class\"\"\"\n",
    "# Get unique labels\n",
    "unique_labels = np.unique(labels)\n",
    "\n",
    "# Create a figure\n",
    "fig, axes = plt.subplots(len(unique_labels), n_samples_per_class * 2, \n",
    "                        figsize=(n_samples_per_class * 3, len(unique_labels) * 3))\n",
    "\n",
    "# Track metrics per class\n",
    "mse_per_class = {label: [] for label in unique_labels}\n",
    "ssim_per_class = {label: [] for label in unique_labels}\n",
    "\n",
    "# For each class\n",
    "for i, label in enumerate(unique_labels):\n",
    "    # Get indices for this class\n",
    "    indices = np.where(labels == label)[0]\n",
    "    \n",
    "    # Sample a few examples\n",
    "    if len(indices) > n_samples_per_class:\n",
    "        sample_indices = np.random.choice(indices, n_samples_per_class, replace=False)\n",
    "    else:\n",
    "        sample_indices = indices\n",
    "    \n",
    "    # For each sample\n",
    "    for j, idx in enumerate(sample_indices):\n",
    "        # Get the original image\n",
    "        original = data[idx]\n",
    "        \n",
    "        # Reconstruct the image\n",
    "        z_mean, z_log_var, z = encoder.predict(np.expand_dims(original, axis=0), verbose=0)\n",
    "        reconstructed = decoder.predict(z_mean, verbose=0)[0]\n",
    "        \n",
    "        # Calculate metrics\n",
    "        mse = np.mean((original - reconstructed) ** 2)\n",
    "        mse_per_class[label].append(mse)\n",
    "        \n",
    "        orig_img = original.reshape(28, 28)\n",
    "        recon_img = reconstructed.reshape(28, 28)\n",
    "        ssim_val = structural_similarity(orig_img, recon_img, data_range=1.)\n",
    "        ssim_per_class[label].append(ssim_val)\n",
    "        \n",
    "        # Plot original and reconstruction\n",
    "        axes[i, j*2].imshow(original.reshape(28, 28), cmap='gray')\n",
    "        axes[i, j*2].axis('off')\n",
    "        if j == 0:\n",
    "            axes[i, j*2].set_title(f'Original (Class {label})')\n",
    "        \n",
    "        axes[i, j*2+1].imshow(reconstructed.reshape(28, 28), cmap='gray')\n",
    "        axes[i, j*2+1].set_title(f'MSE: {mse:.4f}\\nSSIM: {ssim_val:.4f}')\n",
    "        axes[i, j*2+1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(f\"{create_diagnostics_folder()}/per_class_reconstruction.png\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Compute average metrics per class\n",
    "avg_mse_per_class = {label: np.mean(values) for label, values in mse_per_class.items()}\n",
    "avg_ssim_per_class = {label: np.mean(values) for label, values in ssim_per_class.items()}\n",
    "\n",
    "# Plot metrics per class\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(avg_mse_per_class.keys(), avg_mse_per_class.values())\n",
    "plt.title('Average MSE per Class')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('MSE')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(avg_ssim_per_class.keys(), avg_ssim_per_class.values())\n",
    "plt.title('Average SSIM per Class')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('SSIM')\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(f\"{create_diagnostics_folder()}/metrics_per_class.png\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "avg_mse_per_class, avg_ssim_per_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pixel-wise Error Maps\n",
    "\n",
    "Visualize which parts of images have highest reconstruction error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_pixel_error_maps(encoder, decoder, data, n_samples=10):\n",
    "\n",
    "    \"\"\"Visualize where in the image reconstruction errors occur\"\"\"\n",
    "    # Sample data points\n",
    "    if len(data) > n_samples:\n",
    "        idx = np.random.choice(len(data), n_samples, replace=False)\n",
    "        data_sample = data[idx]\n",
    "    else:\n",
    "        data_sample = data\n",
    "\n",
    "    plt.figure(figsize=(15, 5 * n_samples))\n",
    "\n",
    "    for i, original in enumerate(data_sample):\n",
    "        # Reconstruct the image\n",
    "        z_mean, z_log_var, z = encoder.predict(np.expand_dims(original, axis=0), verbose=0)\n",
    "        reconstructed = decoder.predict(z_mean, verbose=0)[0]\n",
    "        \n",
    "        # Calculate error map\n",
    "        error_map = np.abs(original - reconstructed).reshape(28, 28)\n",
    "        \n",
    "        # Plot\n",
    "        plt.subplot(n_samples, 3, i*3 + 1)\n",
    "        plt.imshow(original.reshape(28, 28), cmap='gray')\n",
    "        plt.title(f'Original #{i+1}')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(n_samples, 3, i*3 + 2)\n",
    "        plt.imshow(reconstructed.reshape(28, 28), cmap='gray')\n",
    "        plt.title(f'Reconstructed #{i+1}')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(n_samples, 3, i*3 + 3)\n",
    "        plt.imshow(error_map, cmap='hot')\n",
    "        plt.colorbar()\n",
    "        plt.title(f'Error Map #{i+1} (MSE: {np.mean(error_map):.4f})')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(f\"{create_diagnostics_folder()}/pixel_error_maps.png\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # Calculate average error map\n",
    "    all_error_maps = []\n",
    "    for original in data_sample:\n",
    "        z_mean, z_log_var, z = encoder.predict(np.expand_dims(original, axis=0))\n",
    "        reconstructed = decoder.predict(z_mean)[0]\n",
    "        error_map = np.abs(original - reconstructed).reshape(28, 28)\n",
    "        all_error_maps.append(error_map)\n",
    "\n",
    "    avg_error_map = np.mean(all_error_maps, axis=0)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(avg_error_map, cmap='hot')\n",
    "    plt.colorbar()\n",
    "    plt.title(f'Average Error Map (Mean: {np.mean(avg_error_map):.4f})')\n",
    "    # plt.savefig(f\"{create_diagnostics_folder()}/average_error_map.png\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    return avg_error_map\n",
    "\n",
    "visualize_pixel_error_maps(variational_encoder, variational_decoder, x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogram of Errors\n",
    "\n",
    "Check if errors are normally distributed or skewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error_distribution(encoder, decoder, data, n_samples=1000):\n",
    "\n",
    "    \"\"\"Plot histogram of pixel-wise reconstruction errors\"\"\"\n",
    "    # Sample data points\n",
    "    if len(data) > n_samples:\n",
    "        idx = np.random.choice(len(data), n_samples, replace=False)\n",
    "        data_sample = data[idx]\n",
    "    else:\n",
    "        data_sample = data\n",
    "\n",
    "    all_errors = []\n",
    "\n",
    "    # Calculate errors for all samples\n",
    "    for original in data_sample:\n",
    "        z_mean, z_log_var, z = encoder.predict(np.expand_dims(original, axis=0), verbose=0)\n",
    "        reconstructed = decoder.predict(z_mean, verbose=0)[0]\n",
    "        error = (original - reconstructed)\n",
    "        all_errors.extend(error)\n",
    "\n",
    "    all_errors = np.array(all_errors)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(all_errors.flatten(), bins=50, alpha=0.7, color='blue')\n",
    "    plt.title('Distribution of Reconstruction Errors')\n",
    "    plt.xlabel('Error Value')\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    stats.probplot(all_errors.flatten(), plot=plt)\n",
    "    plt.title('Q-Q Plot of Errors')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(f\"{create_diagnostics_folder()}/error_distribution.png\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # Check for normality with Shapiro-Wilk test\n",
    "    # (sampling a subset because Shapiro-Wilk can't handle large samples)\n",
    "    error_sample = np.random.choice(all_errors.flatten(), size=min(5000, len(all_errors)), replace=False)\n",
    "    shapiro_test = stats.shapiro(error_sample)\n",
    "    print(f\"Shapiro-Wilk test for normality: W={shapiro_test[0]:.4f}, p-value={shapiro_test[1]:.4f}\")\n",
    "    \n",
    "    return shapiro_test\n",
    "\n",
    "# Doesn't change that much so not very useful\n",
    "# plot_error_distribution(variational_encoder, variational_decoder, x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codings = tf.random.normal(shape=[3 * 7, LATENT_DIM])\n",
    "images = variational_decoder(codings).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multiple_images(images, n_cols=None):\n",
    "    n_cols = n_cols or len(images)\n",
    "    n_rows = (len(images) - 1) // n_cols + 1\n",
    "    if images.shape[-1] == 1:\n",
    "        images = images.squeeze(axis=-1)\n",
    "    plt.figure(figsize=(n_cols, n_rows))\n",
    "    for index, image in enumerate(images):\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(image, cmap=\"binary\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "plot_multiple_images(images, 7)\n",
    "plt.savefig(os.path.join(current_logs_path, \"image_generation.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate based on Simple Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate classifier on REAL test data (as a baseline)\n",
    "_, real_accuracy = classifier.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Simple classifier accuracy on REAL test data: {real_accuracy:.4f}\")\n",
    "\n",
    "# Generate a large batch of images\n",
    "n_generated_for_eval = 5000\n",
    "random_latent_vectors_eval = np.random.normal(size=(n_generated_for_eval, LATENT_DIM))\n",
    "generated_images_eval = variational_decoder.predict(random_latent_vectors_eval)\n",
    "\n",
    "# Predict labels for generated images\n",
    "generated_predictions = classifier.predict(generated_images_eval)\n",
    "generated_labels = np.argmax(generated_predictions, axis=1)\n",
    "generated_confidence = np.mean(np.max(generated_predictions, axis=1))\n",
    "\n",
    "# Score: Average confidence of the classifier on generated images.\n",
    "# Higher confidence suggests the classifier \"recognizes\" the generated images better.\n",
    "print(f\"Average classifier confidence on {n_generated_for_eval} GENERATED images: {generated_confidence:.4f}\")\n",
    "\n",
    "# Mean classifier confidence\n",
    "logs[\"MCC\"] = generated_confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution of predicted labels for generated images\n",
    "\n",
    "A good generator should produce all digits somewhat evenly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Distribution of predicted labels for generated images:\")\n",
    "generated_labels_distr = dict(zip(np.histogram(generated_labels, bins=np.arange(11))[1], np.histogram(generated_labels, bins=np.arange(11))[0]))\n",
    "print(generated_labels_distr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_generated_labels_distr = {k: v / n_generated_for_eval for k, v in generated_labels_distr.items()}\n",
    "\n",
    "gini = gini_coefficient(list(norm_generated_labels_distr.values()))\n",
    "print(f\"Gini coefficient for class distribution of generated images: {gini}\")\n",
    "logs[\"GINI\"] = gini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent space exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot latent space (dimensionality reduced to 2)\n",
    "\n",
    "Visualize how your latent space is organized and if similar digits cluster together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 2000\n",
    "\n",
    "samples = x_test[:n_samples]\n",
    "labels = y_test[:n_samples]\n",
    "\n",
    "# Encode to latent space\n",
    "codings_mean, codings_log_var, codings = variational_encoder(samples)\n",
    "\n",
    "# Dimensionality reduction with t-SNE\n",
    "tsne = TSNE(n_components=2, perplexity=30, learning_rate=200)\n",
    "z_tsne = tsne.fit_transform(codings_mean)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 10))\n",
    "scatter = plt.scatter(z_tsne[:, 0], z_tsne[:, 1], c=labels,\n",
    "            cmap='tab10', s=10, alpha=0.8)\n",
    "plt.colorbar(scatter, ticks=range(10))\n",
    "plt.title(\"t-SNE Visualization of Latent Space\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(current_logs_path, \"latent_space.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Latent Traversals\n",
    "\n",
    "Interpolate between points in latent space to see if transitions are smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_latent_traversal(decoder, latent_dim, start=-3, end=3, steps=10, digit_shape=(28, 28)):\n",
    "    \"\"\"\n",
    "    Generate latent space traversals to visualize continuity and feature control\n",
    "    \"\"\"\n",
    "    # Create a grid to hold the generated images\n",
    "    figure = np.zeros((digit_shape[0] * latent_dim, digit_shape[1] * steps))\n",
    "    \n",
    "    # Values to traverse for each dimension\n",
    "    values = np.linspace(start, end, steps)\n",
    "    \n",
    "    # For each latent dimension\n",
    "    for i in range(latent_dim):\n",
    "        # For each value along the traversal\n",
    "        for j, v in enumerate(values):\n",
    "            # Create a latent vector with zeros\n",
    "            z_sample = np.zeros((1, latent_dim))\n",
    "            # Set the current dimension to the current value\n",
    "            z_sample[0, i] = v\n",
    "            \n",
    "            # Decode the latent vector\n",
    "            x_decoded = decoder.predict(z_sample, verbose=0)\n",
    "            digit = x_decoded[0].reshape(digit_shape)\n",
    "            \n",
    "            # Add the digit to the grid\n",
    "            figure[i * digit_shape[0]:(i + 1) * digit_shape[0],\n",
    "                   j * digit_shape[1]:(j + 1) * digit_shape[1]] = digit\n",
    "    \n",
    "    # Display the grid\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.imshow(figure, cmap='gray')\n",
    "    plt.title('Latent Space Traversal (each row = one latent dimension)')\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(f\"{create_diagnostics_folder()}/latent_traversal.png\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "plot_latent_traversal(variational_decoder, LATENT_DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Latent Grid\n",
    "\n",
    "Generate a grid by varying two latent dimensions while keeping others fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_latent_grid(decoder, digit_shape=(28, 28), n=20, dimensions=(0, 1)):\n",
    "    \"\"\"\n",
    "    Create a grid of images by varying two dimensions of the latent space\n",
    "    \"\"\"\n",
    "    # Create a grid of latent values\n",
    "    grid_x = np.linspace(-3, 3, n)\n",
    "    grid_y = np.linspace(-3, 3, n)[::-1]\n",
    "    \n",
    "    figure = np.zeros((digit_shape[0] * n, digit_shape[1] * n))\n",
    "    \n",
    "    # Dimensions to vary\n",
    "    dim1, dim2 = dimensions\n",
    "    latent_dim = decoder.input_shape[1]\n",
    "    \n",
    "    # Generate images for each grid point\n",
    "    for i, yi in enumerate(grid_y):\n",
    "        for j, xi in enumerate(grid_x):\n",
    "            # Create a latent vector with zeros\n",
    "            z_sample = np.zeros((1, latent_dim))\n",
    "            # Set the two dimensions we're varying\n",
    "            z_sample[0, dim1] = xi\n",
    "            z_sample[0, dim2] = yi\n",
    "            \n",
    "            # Decode the latent vector\n",
    "            x_decoded = decoder.predict(z_sample, verbose=0)\n",
    "            digit = x_decoded[0].reshape(digit_shape)\n",
    "            \n",
    "            # Add the digit to the grid\n",
    "            figure[i * digit_shape[0]:(i + 1) * digit_shape[0],\n",
    "                   j * digit_shape[1]:(j + 1) * digit_shape[1]] = digit\n",
    "    \n",
    "    # Display the grid\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.imshow(figure, cmap='gray')\n",
    "    plt.title(f'Latent Grid (Dimensions {dim1} vs {dim2})')\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(f\"{create_diagnostics_folder()}/latent_grid_dim{dim1}_{dim2}.png\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "plot_latent_grid(variational_decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA on Latent Space\n",
    "\n",
    "Check if a few dimensions capture most variance or if it's evenly distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_latent_pca(encoder, data, n_samples=2000):\n",
    "    \"\"\"Analyze the latent space using PCA to check for dominant dimensions\"\"\"\n",
    "    # Sample data points\n",
    "    if len(data) > n_samples:\n",
    "        idx = np.random.choice(len(data), n_samples, replace=False)\n",
    "        data_sample = data[idx]\n",
    "    else:\n",
    "        data_sample = data\n",
    "    \n",
    "    # Encode data\n",
    "    z_mean, z_log_var, z = encoder.predict(data_sample, verbose=0)\n",
    "    \n",
    "    # Apply PCA\n",
    "    pca = PCA()\n",
    "    pca.fit(z_mean)\n",
    "    \n",
    "    # Plot explained variance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(np.cumsum(pca.explained_variance_ratio_), '-o')\n",
    "    plt.axhline(y=0.95, color='r', linestyle='--', alpha=0.5)\n",
    "    plt.grid(True)\n",
    "    plt.title('Cumulative Explained Variance by Latent Dimensions')\n",
    "    plt.xlabel('Number of Latent Dimensions')\n",
    "    plt.ylabel('Cumulative Explained Variance Ratio')\n",
    "    # plt.savefig(f\"{create_diagnostics_folder()}/latent_pca_variance.png\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot top principal components\n",
    "    n_components = min(5, z_mean.shape[1])\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for i in range(n_components):\n",
    "        plt.subplot(n_components, 1, i+1)\n",
    "        plt.bar(range(z_mean.shape[1]), pca.components_[i])\n",
    "        plt.title(f'PCA Component {i+1} (Variance: {pca.explained_variance_ratio_[i]:.4f})')\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(f\"{create_diagnostics_folder()}/latent_pca_components.png\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # Return the number of dimensions needed to explain 95% variance\n",
    "    n_dims_95 = np.argmax(np.cumsum(pca.explained_variance_ratio_) >= 0.95) + 1\n",
    "    print(f\"Number of dimensions needed for 95% variance: {n_dims_95}\")\n",
    "    return n_dims_95, pca.explained_variance_ratio_\n",
    "\n",
    "analyze_latent_pca(variational_encoder, x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average Variances per Latent Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variances = np.exp(codings_log_var.numpy())\n",
    "\n",
    "average_variances = np.mean(variances, axis=0)\n",
    "\n",
    "print(\"Average Variances per Latent Dimension:\")\n",
    "for i, avg_var in enumerate(average_variances):\n",
    "    print(f\"Dimension {i}: {avg_var:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 1e-3  # Adjust this threshold as needed\n",
    "unused_dimensions = np.where(average_variances < threshold)[0]\n",
    "print(f\"\\nPotentially Unused Dimensions (below threshold {threshold}): {unused_dimensions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjusted Rand Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform clustering on the latent space\n",
    "n_clusters = len(np.unique(y_test))  # Assuming the number of clusters equals the number of classes\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "cluster_labels = kmeans.fit_predict(codings_mean)\n",
    "\n",
    "# Compute the ARI\n",
    "ari_score = adjusted_rand_score(labels, cluster_labels)\n",
    "print(f\"Adjusted Rand Index (ARI): {ari_score}\")\n",
    "\n",
    "logs[\"ARI\"] = ari_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze KL Divergence Components\n",
    "\n",
    "Break down KL divergence by dimension to see if certain dimensions contribute disproportionately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_kl_divergence_components(encoder, data, n_samples=1000):\n",
    "    \"\"\"Analyze which dimensions contribute most to KL divergence\"\"\"\n",
    "    # Sample data points\n",
    "    if len(data) > n_samples:\n",
    "        idx = np.random.choice(len(data), n_samples, replace=False)\n",
    "        data_sample = data[idx]\n",
    "    else:\n",
    "        data_sample = data\n",
    "    \n",
    "    # Encode data\n",
    "    z_mean, z_log_var, z = encoder.predict(data_sample)\n",
    "    \n",
    "    # Calculate KL divergence for each dimension\n",
    "    kl_per_dim = -0.5 * np.mean(1 + z_log_var - np.square(z_mean) - np.exp(z_log_var), axis=0)\n",
    "    \n",
    "    # Plot KL divergence per dimension\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(range(len(kl_per_dim)), kl_per_dim)\n",
    "    plt.title('KL Divergence per Latent Dimension')\n",
    "    plt.xlabel('Latent Dimension')\n",
    "    plt.ylabel('KL Divergence')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    # plt.savefig(f\"{create_diagnostics_folder()}/kl_per_dimension.png\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot the mean and variance of the approximate posterior\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    \n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.bar(range(z_mean.shape[1]), np.mean(z_mean, axis=0))\n",
    "    plt.title('Mean of Latent Dimensions')\n",
    "    plt.xlabel('Latent Dimension')\n",
    "    plt.ylabel('Mean Value')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.bar(range(z_log_var.shape[1]), np.mean(np.exp(z_log_var), axis=0))\n",
    "    plt.title('Variance of Latent Dimensions')\n",
    "    plt.xlabel('Latent Dimension')\n",
    "    plt.ylabel('Variance Value')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(f\"{create_diagnostics_folder()}/latent_stats.png\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    return kl_per_dim\n",
    "\n",
    "analyze_kl_divergence_components(variational_encoder, x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check posterior collapse\n",
    "\n",
    "Check if some latent dimensions are ignored (mean≈0, var≈1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_posterior_collapse(encoder, data, n_samples=1000, threshold=0.1):\n",
    "    \"\"\"Check for posterior collapse (when latent dimensions are ignored)\"\"\"\n",
    "    # Sample data points\n",
    "    if len(data) > n_samples:\n",
    "        idx = np.random.choice(len(data), n_samples, replace=False)\n",
    "        data_sample = data[idx]\n",
    "    else:\n",
    "        data_sample = data\n",
    "    \n",
    "    # Encode data\n",
    "    z_mean, z_log_var, z = encoder.predict(data_sample)\n",
    "    \n",
    "    # Calculate standard deviation of means across samples\n",
    "    mean_std = np.std(z_mean, axis=0)\n",
    "    \n",
    "    # Calculate mean of variances across samples\n",
    "    var_mean = np.mean(np.exp(z_log_var), axis=0)\n",
    "    \n",
    "    # Identify potentially collapsed dimensions\n",
    "    collapsed_dims = []\n",
    "    for i in range(len(mean_std)):\n",
    "        if mean_std[i] < threshold and abs(var_mean[i] - 1.0) < threshold:\n",
    "            collapsed_dims.append(i)\n",
    "    \n",
    "    # Plot diagnostics\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.bar(range(len(mean_std)), mean_std)\n",
    "    plt.axhline(y=threshold, color='r', linestyle='--', alpha=0.7, label=f'Threshold ({threshold})')\n",
    "    plt.title('Standard Deviation of Mean Values across Samples')\n",
    "    plt.xlabel('Latent Dimension')\n",
    "    plt.ylabel('Std Dev')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.bar(range(len(var_mean)), var_mean)\n",
    "    plt.axhline(y=1.0, color='g', linestyle='-', alpha=0.7, label='Prior Variance (1.0)')\n",
    "    plt.axhline(y=1.0+threshold, color='r', linestyle='--', alpha=0.7, label=f'Threshold ({1.0+threshold})')\n",
    "    plt.axhline(y=1.0-threshold, color='r', linestyle='--', alpha=0.7)\n",
    "    plt.title('Mean of Variance Values across Samples')\n",
    "    plt.xlabel('Latent Dimension')\n",
    "    plt.ylabel('Mean Variance')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(f\"{create_diagnostics_folder()}/posterior_collapse.png\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Potentially collapsed dimensions: {collapsed_dims}\")\n",
    "    print(f\"Number of potentially collapsed dimensions: {len(collapsed_dims)}\")\n",
    "    \n",
    "    return collapsed_dims, mean_std, var_mean\n",
    "\n",
    "check_posterior_collapse(variational_encoder, x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Q-Q Plots\n",
    "\n",
    "Compare your approximate posterior against the prior distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_qq_distributions(encoder, data, n_samples=1000, n_dims=5):\n",
    "    \"\"\"Plot Q-Q plots comparing latent distributions to standard normal\"\"\"\n",
    "    # Sample data points\n",
    "    if len(data) > n_samples:\n",
    "        idx = np.random.choice(len(data), n_samples, replace=False)\n",
    "        data_sample = data[idx]\n",
    "    else:\n",
    "        data_sample = data\n",
    "    \n",
    "    # Encode data\n",
    "    z_mean, z_log_var, z = encoder.predict(data_sample)\n",
    "    \n",
    "    # Prepare figure\n",
    "    fig = plt.figure(figsize=(15, 3 * min(n_dims, z.shape[1])))\n",
    "    \n",
    "    # Plot Q-Q plots for first n_dims dimensions\n",
    "    for i in range(min(n_dims, z.shape[1])):\n",
    "        plt.subplot(min(n_dims, z.shape[1]), 1, i+1)\n",
    "        stats.probplot(z[:, i], dist=\"norm\", plot=plt)\n",
    "        plt.title(f'Q-Q Plot for Dimension {i+1}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(f\"{create_diagnostics_folder()}/qq_plots.png\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # Calculate Wasserstein distance between each dimension and standard normal\n",
    "    w_distances = []\n",
    "    normal_samples = np.random.normal(0, 1, len(z))\n",
    "    \n",
    "    for i in range(z.shape[1]):\n",
    "        w_dist = stats.wasserstein_distance(z[:, i], normal_samples)\n",
    "        w_distances.append(w_dist)\n",
    "    \n",
    "    # Plot Wasserstein distances\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(range(len(w_distances)), w_distances)\n",
    "    plt.title('Wasserstein Distance to Normal Distribution')\n",
    "    plt.xlabel('Latent Dimension')\n",
    "    plt.ylabel('Wasserstein Distance')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    # plt.savefig(f\"{create_diagnostics_folder()}/wasserstein_distances.png\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    return w_distances\n",
    "\n",
    "plot_qq_distributions(variational_encoder, x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic interpolation between 2 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codings = np.zeros([7, LATENT_DIM])\n",
    "codings[:, 0] = np.linspace(-0.8, 0.8, 7) \n",
    "images = variational_decoder(codings).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_multiple_images(images)\n",
    "plt.savefig(os.path.join(current_logs_path, \"sem_interpolation.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert numpy types to native Python types for JSON serialization\n",
    "def convert_numpy_types(obj):\n",
    "    if isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, (np.float32, np.float64)):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, (np.int32, np.int64)):\n",
    "        return int(obj)\n",
    "    return obj\n",
    "\n",
    "logs_serializable = {k: convert_numpy_types(v) for k, v in logs.items()}\n",
    "\n",
    "with open(os.path.join(current_logs_path, \"logs.json\"), \"w\", encoding=\"utf-8\") as file:\n",
    "    json.dump(logs_serializable, file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display all logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_folders = [folder for folder in os.listdir(PARENT_LOGS_PATH) if os.path.isdir(os.path.join(PARENT_LOGS_PATH, folder))]\n",
    "log_file_paths = [os.path.join(PARENT_LOGS_PATH, folder, \"logs.json\") for folder in log_folders]\n",
    "\n",
    "all_logs = []\n",
    "for log_file_path in log_file_paths:\n",
    "    file = open(log_file_path)\n",
    "    json_logs = json.loads(file.read())\n",
    "    df_logs = pd.DataFrame([json_logs])\n",
    "    all_logs.append(df_logs)\n",
    "\n",
    "df = pd.concat(all_logs).sort_values(\"iteration\")\n",
    "df.to_csv(os.path.join(PARENT_LOGS_PATH, \"logs.csv\"), encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
